<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Introduction_and_Word_Vectors</title>
    <url>/article/fd8e5887.html</url>
    <content><![CDATA[<h1 id="Task1-Introduction-and-Word-Vectors"><a href="#Task1-Introduction-and-Word-Vectors" class="headerlink" title="Task1: Introduction and Word Vectors"></a>Task1: Introduction and Word Vectors</h1><p>理论部分</p>
<ul>
<li>介绍NLP研究的对象</li>
<li>如何表示单词的含义</li>
<li>Word2Vec方法的基本原理</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>2数理统计与描述性统计</title>
    <url>/article/83114b11.html</url>
    <content><![CDATA[<h1 id="一、数理统计概念"><a href="#一、数理统计概念" class="headerlink" title="一、数理统计概念"></a>一、数理统计概念</h1><h2 id="1-基本概念释义"><a href="#1-基本概念释义" class="headerlink" title="1.基本概念释义"></a>1.基本概念释义</h2><font color="blue">总体</font>：

研究对象的全体，通常用一个随机变量表示。

<font color="blue">个体</font>：

组成总体的每个基本单元。<a id="more"></a>

从总体$X$中随机抽取一部分个体$X_1,X_2,...,X_n$，称$X_1,X_2,...,X_n$为取自$X$的容量为$n$的样本。实际上，数理统计学中的总体是指与总体相联系的某个(某几个)数量指标$X$取值的全体。

<font color="red">样本具有两重性，在一次具体抽样后是一组确定的数值。一般叙述中由于采取随机抽样，样本是一组随机变量(结果未知)。</font>

<p>一般地，用$X_1,X_2,…,X_n$，表示随机样本，取到的值记为$x_1,x_2,…,x_n$称为样本观测值。$n$为样本容量。</p>
<font color="blue">样本分布</font>：样本作为随机变量的概率分布。显然，样本分布取决于总体的性质和样本的性质。

## 2.统计量与抽样

数理统计的任务是采集和处理带有随机影响的数据，或者说收集样本并对之进行加工，在此基础上对研究的问题进行分析并作出一定的结论，这一过程称为<font color="blue">统计推断</font>。在统计推断过程中，对样本进行加工整理，实际上就是根据样本计算出一些量，把研究问题相关的信息集中起来。这种根据样本计算出的量就是<font color="blue">统计量</font>。因此，统计量是样本的某种函数。

定义：设 $X_1,X_2,...,X_n $ 是总体 $X$ 的一个简单随机样本， $T(X_1, X_2,...,X_n)$ 为一个 $n$ 元连续函数，且 $T$ 中不包含任何关于总体的未知参数，则称 $T(X_1, X_2,...,X_n)$ 是一个统计量，称统计量的分布为抽样分布。

### 常用的统计量

<font color="blue">样本均值</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，称$\overline X =  \frac{1} {n} {\sum_{i=1}^{n}X_i}$为样本均值。通常用样本均值来估计总体分布的均值和对有关总体分布均值的假设作检验。</p>
<font color="blue">样本方差</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，$\overline X$ 为样本均值，称$S^2 =  \frac{1} {n-1} {\sum_{i=1}^{n}(X_i-\overline X)^2}$为样本方差。</p>
<p>通常用样本方差来估计总体分布的方差和对有关总体分布均值或方差的假设作检验。</p>
<font color="blue">k阶样本原点矩</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，称$A_k =  \frac{1} {n} {\sum_{i=1}^{n}X_i^k}$</p>
<p>为样本的 $k$ 阶原点矩（可以看到 $k=1$ 时，相当于样本均值），通常用样本的无阶原点矩来估计总体分布的 $k$ 阶原点矩。（可以看到 $k=1$ 时，相当于样本均值）</p>
<p>通常用样本的无阶原点矩来估计总体分布的 $k$ 阶原点矩。</p>
<font color="blue">k阶样本中心矩</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，$\overline X$ 为样本均值，称$M_k =  \frac{1} {n} {\sum_{i=1}^{n}(X_i-\overline X)^k}$为样本的 $k$ 阶中心矩。</p>
<p>通常用样本的 $k$ 阶中心矩来估计总体分布的 $k$ 阶中心矩。</p>
<font color="blue">顺序统计量</font>

<p>设 $X_1,X_2,…,X_n $ 是抽自总体 $X$ 的样本，$x_1,x_2,…，x_n$  为样本观测值。将 $x_1,x_2,…，x_n$  按照从小到大的顺序排列为$x_{(1)}&lt;=x_{(2)}&lt;=…&lt;=x_{(n)}$。</p>
<p>当样本 $X_1,X_2,…,X_n $ 取值 $x_1,x_2,…，x_n$  时，定义 $X_{(k)}$ 取值 $X_{(k)}(k=1,2，…,n)$，称  $X_{(1)},X_{(2)},…,X_{(n)} $ 为 $X_1,X_2,…,X_n $ 的顺序统计量。</p>
<p>显然，$X_{(1)} =min {X_i}$ 是样本观察中最小的一个，称为最小顺序统计量。$X_{(n)} =max {X_i}$ 是样本观测值中取值最大的一个，成为最大顺序统计量。称$X_{（r）}$ 为第 $r$ 个顺序统计量。</p>
<h1 id="二、描述性统计"><a href="#二、描述性统计" class="headerlink" title="二、描述性统计"></a>二、描述性统计</h1><h2 id="1-数据集中趋势的度量"><a href="#1-数据集中趋势的度量" class="headerlink" title="1.数据集中趋势的度量"></a>1.数据集中趋势的度量</h2><font color="blue">平均数</font>

<p>是表示一组数据集中趋势的量数，是指在一组数据中所有数据之和再除以这组数据的个数。</p>
<script type="math/tex; mode=display">
\overline X =  \frac{1} {n} {\sum_{i=1}^{n}X_i}</script><font color="blue">中位数</font>

<p>是指在一组数据，按顺序排列后，居于中间位置的数。中位数描述数据中心位置的数字特征。</p>
<p>对于对称分布的数据，均值与中位数比较接近；对于偏态分布的数据，均值与中位数不同。中位数不受异常值的影响，具有稳健性。</p>
<script type="math/tex; mode=display">
m_p=\left\{
\begin{array}{lcl}
x_{[np]+1},       &      & {当np不是整数}\\
\frac{1}{2}(x_{(np)}+x_{(np+1)})     &      & {当np是整数时}\\
\end{array} \right.</script><font color="blue">频数</font>

<p>同一观测值在一组数据中出现的次数（掷骰子中，一共掷了20次，出现数字5的次数）。</p>
<font color="blue">众数</font>

<p>就是一组数据中，出现次数最多的那个数（几个数）。</p>
<font color="blue">均值 vs 中位数 vs 众数</font>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">均值</td>
<td style="text-align:center">充分利用所有数据，适用性强</td>
<td style="text-align:center">容易受极端值影响</td>
</tr>
<tr>
<td style="text-align:center">中位数</td>
<td style="text-align:center">不受极端值影响</td>
<td style="text-align:center">缺乏敏感性</td>
</tr>
<tr>
<td style="text-align:center">众数</td>
<td style="text-align:center">不受极端值影响；当数据具有明显的集中趋势时，代表性好</td>
<td style="text-align:center">缺乏唯一性</td>
</tr>
</tbody>
</table>
</div>
<font color="blue">百分位数</font>

<p>百分位数是中位数的推广，将数据按从小到大排列后，对于$0 \leq p &lt; 1$，它的p分位点定义为</p>
<script type="math/tex; mode=display">
m_p=\left\{
\begin{array}{lcl}
x_{[np]+1},       &      & {当np不是整数}\\
\frac{1}{2}(x_{(np)}+x_{(np+1)})     &      & {当np是整数时}\\
\end{array} \right.</script><p>其中，<strong>[np]</strong>表示<strong>np</strong>的整数部分。所以，0.5分位数（第50百分位数）就是中位数。</p>
<p><img src="/article/83114b11/百分位数图.png" alt></p>
<h3 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h3><p><img src="/article/83114b11/image1" alt="image-20200624144415651"></p>
<h2 id="2-数据离散趋势的度量"><a href="#2-数据离散趋势的度量" class="headerlink" title="2.数据离散趋势的度量"></a>2.数据离散趋势的度量</h2><p>表示数据分散（离散，差异）程度的特征量有方差，标准差，极差以及变异系数等。</p>
<font color="blue">方差</font>

<p>用来计算每一个变量（观察值）与总体均数之间的差异。实际工作中，总体均数难以得到时，应用样本统计量代替总体参数，经校正后，样本方差计算公式:</p>
<script type="math/tex; mode=display">
s^2 = \frac{1}{n-1}\sum_{i=1}^{n}{(x_i-\overline{x})}^2</script><font color="blue">标准差</font>

<p>样本方差的开平方成为样本标准差。</p>
<script type="math/tex; mode=display">
s=\sqrt{s^2}=\sqrt{\frac{1}{n-1}\sum_{1}^{n-1}{(x_i-\overline{x})}^2}</script><font color="blue">极差</font>
$$
R=X_{(n)}-x_{(1)}=\max(x)-\min(x)
$$
数据越分散，极差越大。

<font color="blue">变异系数</font>

<ul>
<li>是刻画数据相对分散性的一种度量。变异系数只在平均值不为零时有定义，而且一般适用于平均值大于零的情况。变异系数也被称为<strong>标准离差率</strong>或<strong>单位风险</strong>。</li>
<li>当需要比较两组数据离散程度大小的时候，如果两组数据的测量尺度相差太大，或者数据量纲的不同，变异系数可以消除测量尺度和量纲的影响。</li>
</ul>
<script type="math/tex; mode=display">
CV=100\times\frac{s}{x}(\%)</script><font color="blue">四分位差</font>

<p>样本上、下四分位数之差称为四分位差(或半极差)。</p>
<script type="math/tex; mode=display">
R_1 = Q_3 - Q_1</script><p>它也是度量样本分散性的重要数字特征，特别对于具有异常值的数据，它作为分散性具有稳健性<font color="red">  <strong>（见百分位数示意图）</strong></font>。</p>
<h3 id="python实现-1"><a href="#python实现-1" class="headerlink" title="python实现"></a>python实现</h3><p><img src="/article/83114b11/image2.PNG" alt="image2" style="zoom:80%;"></p>
<h2 id="3-分布特征"><a href="#3-分布特征" class="headerlink" title="3.分布特征"></a>3.分布特征</h2><p> <strong>引言：</strong>描述一个随机变量，不仅要说明它能够取那些值，而且还要关心它取这些值的概率（可能性）。</p>
<font color="blue">离散变量和连续变量</font>

<ul>
<li><font color="blue">离散型随机变量</font>：其数值只能用<strong>自然数或整数</strong>单位表示。例如，<font color="red">  班级人数，电脑台数等，</font>只能按计量单位数计数，这种变量的数值一般用计数方法取得。</li>
<li><font color="blue">连续变量</font>：在一定区间内可以任意取值的变量。例如，<font color="red">人体测量的身高，体重等。</font>

</li>
</ul>
<font color="blue">概率函数</font>：用函数的形式来表达概率。

- **连续型随机变量**的概率函数就叫做**概率密度函数**。
- **离散型随机变量**的概率函数就叫做**概率质量函数**。

<font color="blue">分布函数</font>

<p>设$X$是一个随机变量，对任意的实数$x$，令$F(x)=P(X&lt;=x),x \in (-\infty,+\infty)$，则称$F(x)$是随机变量$X$的分布函数(概率累积函数)。</p>
<p><img src="/article/83114b11/分布函数与密度函数的关系.png" alt></p>
<p><font color="red">密度函数与分布函数关系&lt;/font &gt; </font></p>
<p><font color="blue">正态分布</font>：也称高斯分布，是一个非常常见的连续概率分布，概率密度函数为</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp{\{- \frac{(x-u)^2}{2\sigma^2} \}}, \qquad -\infty<x<+\infty</script><p>则称$X$服从$N(u,\sigma^2)$分布。</p>
<p><img src="/article/83114b11/uniform2.png" alt="uniform2"></p>
<p><font color="red">正态分布的概率密度函数曲线&lt;/font &gt; </font></p>
<p><img src="/article/83114b11/标准正态分布.png" alt="标准正态分布"></p>
<p>​              <font color="red">标准正态分布和对应区间上积分（面积）的百分比&lt;/font &gt; </font></p>
<p>这个概念可以推广到一般正态分布。$[u-3\sigma,u+3\sigma]$的概率密度曲线之下的面积占总面积的99.7%，是著名的$3\sigma$原则。</p>
<h2 id="4-偏度与峰度"><a href="#4-偏度与峰度" class="headerlink" title="4. 偏度与峰度"></a>4. 偏度与峰度</h2><p><font color="blue">偏度（skewness）</font>：也称为偏态，是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。直观看来就是密度函数曲线尾部的相对长度。<strong>偏度刻画的是分布函数（数据）的对称性。</strong></p>
<p>关于均值对称的数据其偏度系数为0，右侧更分散的数据偏度系数为正，左侧更分散的数据偏度系数为负.</p>
<ul>
<li><p><strong>正态分布的偏度为0，两侧尾部长度对称。</strong></p>
</li>
<li><p><strong>左偏:</strong>   </p>
<p>1）若以$b_s$表示偏度。$b_s&lt;0$称分布具有<strong>负偏离</strong>，也称左偏态；</p>
<p>2）此时数据位于均值左边的比位于右边的少，直观表现为左边的尾部相对于与右边的尾部要长；</p>
<p>3）<strong>因为有少数变量值很小，使曲线左侧尾部拖得很长；</strong></p>
</li>
<li><p><strong>右偏：</strong></p>
<p>1）$b_s&gt;0$称分布具有<strong>正偏离</strong>，也称右偏态；</p>
<p>2）此时数据位于均值右边的比位于左边的少，直观表现为右边的尾部相对于与左边的尾部要长；</p>
<p>3）<strong>因为有少数变量值很大，使曲线右侧尾部拖得很长；</strong></p>
</li>
</ul>
<p><font color="blue">峰度(peakedness;kurtosis)</font>：说明的是分布曲线在平均值处峰值高低的特征数。直观看来，峰度反映了峰部的尖度。样本的峰度是和正态分布相比较而言统计量，如果峰度大于正态分布峰度，峰的形状比较尖，比正态分布峰要陡峭。反之亦然。<strong>峰度刻画的是分布函数的集中和分散程度。</strong></p>
<p><img src="/article/83114b11/偏态与峰度.png" alt></p>
<h3 id="公式与python实现"><a href="#公式与python实现" class="headerlink" title="公式与python实现"></a>公式与python实现</h3><p><font color="blue">样本偏度系数</font>：</p>
<script type="math/tex; mode=display">
g_1 = \frac{n}{(n-1)(n-2)s^3}\sum_{i=1}^{n}{(x_i-\overline{x})}^3=\frac{n^2 u_3}{(n-1)(n-2)s^3}</script><p><font color="blue">样本峰度系数</font>：</p>
<script type="math/tex; mode=display">
g_2 = \frac{n(n+1)}{(n-1)(n-2)(n-3)s^4}\sum_{i=1}^{n}{(x_i-\overline{x})}^4-3\frac{(n-1)^2}{(n-2)(n-3)}</script><p><img src="/article/83114b11/image3.PNG" style="zoom:80%;"></p>
]]></content>
      <categories>
        <category>概率统计</category>
      </categories>
      <tags>
        <tag>概率统计</tag>
      </tags>
  </entry>
  <entry>
    <title>Task02-LBP特征描述算子-人脸检测</title>
    <url>/article/50afbda.html</url>
    <content><![CDATA[<p>学习任务：</p>
<ul>
<li><strong>理论部分</strong>：掌握LBP特征描述算子原理</li>
<li><strong>练习部分</strong>：使用OpenCV的LBP检测器完成人脸检测任务</li>
</ul>
]]></content>
      <categories>
        <category>图像处理下</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>文本数据</title>
    <url>/article/8eab7353.html</url>
    <content><![CDATA[<p><img src="/article/8eab7353/文本数据.png" alt></p>
<h1 id="六、问题与练习"><a href="#六、问题与练习" class="headerlink" title="六、问题与练习"></a>六、问题与练习</h1><h2 id="1-问题"><a href="#1-问题" class="headerlink" title="1.问题"></a>1.问题</h2><p>【问题一】 str对象方法和df/Series对象方法有什么区别?</p>
<ul>
<li><p>str对象方法有很多针对字符串的方法</p>
</li>
<li><p>在replace方法上，二者有较大差异：</p>
<p>1）str.replace针对object类型或string类型，默认操作：正则表达式</p>
<p>​      replace针对任意类型的序列或数据框，正则表达式替换：regex=True。使用字典可以支持      多列替换。</p>
<p>2）str.replace类型赋值参数不能是pd.NA。</p>
<p>3）对于string类型Series，使用replace函数不能使用正则表达式替换。</p>
</li>
</ul>
<p>【问题二】 给出一列string类型，如何判断单元格是否是数值型数据？</p>
<ul>
<li>正则表达式进行匹配。</li>
<li>str.isnumeric有一定的局限性。</li>
</ul>
<p>【问题三】str.split方法的作用是什么？在什么场合下使用？</p>
<ul>
<li>使用分隔符对每个字符串进行分割并返回列表。</li>
<li>可以使用str方法进行元素选择。</li>
</ul>
<p>【问题四】在本章的第二到第四节分别介绍了字符串类型的5类操作，请思考这些操作的应用场景？</p>
<ul>
<li>拆分：</li>
<li>拼接</li>
<li>替换</li>
<li>字符匹配</li>
<li>字符提取</li>
</ul>
<h2 id="2-练习"><a href="#2-练习" class="headerlink" title="2.练习"></a>2.练习</h2><p>【练习一】现有一份关于字符串的数据集，请解决以下问题：</p>
<p>（a）先对字符串编码存储人员信息（在编号后添加ID列），使用如下格式：”xxx(名字)：x国人，性别x，生于x年x月x日“</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/String_data_one.csv'</span>,index_col=<span class="string">'人员编号'</span>, dtype=<span class="string">'string'</span>)</span><br><span class="line">df[<span class="string">'ID'</span>] = df[<span class="string">'姓名'</span>].str.cat([<span class="string">': '</span>+df[<span class="string">'国籍'</span>]+<span class="string">'国人,'</span>,<span class="string">'性别'</span>+df[<span class="string">'性别'</span>]+<span class="string">','</span>,<span class="string">'生于'</span>+df[<span class="string">'出生年'</span>]+<span class="string">'年'</span>],na_rep=<span class="string">'*'</span>)</span><br><span class="line">df[<span class="string">'ID'</span>].head()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/8eab7353/image-1.png" alt="image-20200626233534845"></p>
<p>（b）将（a）中的人员生日信息部分修改为用中文表示（如一九七四年十月二十三日），其余返回格式不变。</p>
<p>（c）将（b）中的ID列结果拆分为原列表相应的5列，并使用equals检验是否一致。</p>
<p>【练习二】现有一份半虚拟的数据集，第一列包含了新型冠状病毒的一些新闻标题，请解决以下问题：</p>
<p>（a）选出所有关于北京市和上海市新闻标题的所在行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/String_data_two.csv'</span>)</span><br><span class="line">df[<span class="string">'col1'</span>].str.extract(<span class="string">r'(?P&lt;name_1&gt;北京|上海)'</span>).dropna().index</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/8eab7353/image-2.png" alt="image-20200626233841173"></p>
<p>（b）求col2的均值。</p>
<p>（c）求col3的均值。</p>
]]></content>
      <categories>
        <category>pandas下</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>第7章 文本数据</title>
    <url>/article/88685a55.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Task01 Harris特征点检测器-兴趣点检测</title>
    <url>/article/8b3bd9dd.html</url>
    <content><![CDATA[<h1 id="Harris特征点检测器-兴趣点检测"><a href="#Harris特征点检测器-兴趣点检测" class="headerlink" title="Harris特征点检测器-兴趣点检测"></a>Harris特征点检测器-兴趣点检测</h1><p><strong>特则点</strong>又称为兴趣点或角点，通常具有旋转不变性和光照不变性和视角不变性等优点，是图像的重要特征之一，常被应用到目标匹配、目标跟踪、三维重建等应用中。</p>
<p><strong>点特征</strong>主要是指图像中的明显点，如突出的角点、边缘端点、权值点等等。</p>
<p><strong>兴趣点提取(检测)算子</strong>是用于点特征提取的算子<a id="more"></a>，常用的有</p>
<ul>
<li>Harris角点检测：用于检测角点</li>
<li>FAST特征检测：用于检测角点</li>
<li>SIFT特征检测：用于检测斑点</li>
<li>SURF特征检测：用于检测角点</li>
<li>BRIEF特征检测：用于检测斑点</li>
<li>ORB：该算法代表带方向的FAST算法和具有旋转不变性的BRIEF算法</li>
</ul>
<p><strong>特征匹配</strong>：</p>
<ul>
<li>暴力(Brute-Force)匹配法</li>
<li>基于FLANN匹配法</li>
</ul>
<h2 id="一、Harris特征点检测算法的思想和数学原理"><a href="#一、Harris特征点检测算法的思想和数学原理" class="headerlink" title="一、Harris特征点检测算法的思想和数学原理"></a>一、Harris特征点检测算法的思想和数学原理</h2><h2 id="1-1-基础知识"><a href="#1-1-基础知识" class="headerlink" title="1.1 基础知识"></a>1.1 基础知识</h2><ul>
<li><p><strong>角点</strong></p>
<p>左图表示一个平坦区域，在各个方向移动，窗口内像素值均没有太大变化；</p>
<p>中图表示一个边缘特征(Edges)，若沿着水平方向移动(梯度方向)，像素值会发生跳变；若沿着边缘移动(平行于边缘)，像素值不变发生变化；</p>
<p>右图表示一个角(Corners)，它朝哪个方向移动，像素值都会发生很大变化。即为<font color="red">角点</font>。</p>
</li>
</ul>
<p><img src="https://camo.githubusercontent.com/460ac04994bec25117ee2724563058da99e5bf1e/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303630393230343234393231392e706e673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c33646c61586870626c38304d4459304e7a67784f513d3d2c73697a655f312c636f6c6f725f4646464646462c745f3730237069635f63656e746572" alt="在这里插入图片描述"></p>
<ul>
<li><strong>图像梯度</strong>:图像局部内，图像梯度越大表示该局部内像素值变化越大。图形梯度在数学上可用微分或者积分表示,使用差分来近似导数：$G_x(x,y)=H(x+1,y)-H(x-1,y)$,</li>
<li><strong>补充</strong>：对图像求梯度通常是考虑图像的每个像素的某个领域内的灰度变化，因此通常对原始图像中像素某个领域设置梯度算子，然后采用小区域模板进行卷积计算，常用的有Prewitt算子、Sobel算子、Robinson算子、Laplace算子等。</li>
</ul>
<h2 id="1-2-Harris角点检测算法原理"><a href="#1-2-Harris角点检测算法原理" class="headerlink" title="1.2 Harris角点检测算法原理"></a>1.2 Harris角点检测算法原理</h2><h3 id="1-2-1-计算窗口内部的像素值变化量-E-x-y"><a href="#1-2-1-计算窗口内部的像素值变化量-E-x-y" class="headerlink" title="1.2.1 计算窗口内部的像素值变化量$E(x,y)$"></a>1.2.1 计算窗口内部的像素值变化量$E(x,y)$</h3><p><strong>建立数学模型，确定哪些窗口会引起较大的灰度值变化</strong></p>
<p>窗口$W$对应的像素坐标位置$(x,y)$，窗口的大小决定了有多少位置。</p>
<p>像素位置坐标$(x,y)$对应的像素灰度值为$I(x,y)$，窗口分别向$x$和$y$方向上移动$(u,v)$，到达$(x+u,y+v)$上，对应的像素灰度值$I(x+u,y+v)$。</p>
<p>窗口移动引起的灰度值的变化量为$I(x+u,y+v)-I(x,y)$。</p>
<p>$(x,y)$位置的窗口函数为$w(x,y)$。即为窗口内各像素的权重。</p>
<p><img src="/article/8b3bd9dd/image1-2.png" alt="image-20200623143300133"></p>
<p><strong>窗口移动(u,v)引起的灰度值的加权变化量</strong>：</p>
<script type="math/tex; mode=display">
E(u,v) = \sum_{x,y}{w(x,y){[I(x+u,y+v)-I(x,y)]}^{2}}</script><p>根据二维泰勒公式展开：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
E(u,v) &\approx \sum_{x,y \in W}{w(x,y){[I(x,y)+uI_x+vI_y-I(x,y)]}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y){(uI_x+vI_y)}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y){(u^2I_x^2+vI_y^2+2uvI_xI_y)}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y)\begin{bmatrix}u&v\end{bmatrix}\begin{bmatrix}I_x^2 & I_xI_y\\
                                       I_xI_y & I_y^2\end{bmatrix} \begin{bmatrix}u\\v\end{bmatrix}} \\
  &= \begin{bmatrix}u&v\end{bmatrix}(\sum_{x,y\in W}{w(x,y) \begin{bmatrix}I_x^2 & I_xI_y\\                                     I_xI_y & I_y^2\end{bmatrix} })\begin{bmatrix}u\\v\end{bmatrix}                                      \\
  &= \begin{bmatrix}u&v\end{bmatrix}M\begin{bmatrix}u\\v\end{bmatrix}
\end{aligned}
\end{equation}</script><p>其中$I_x,I_y$分别为窗口内像素点$(x,y)$在$x$方向上和$y$方向上的梯度值。矩阵$M$为：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
M &= \sum_{(x,y)\in W}{w(x,y) \begin{bmatrix}I_x^2 & I_xI_y\\
                                       I_xI_y & I_y^2\end{bmatrix}}\\
  &=R^{-1}\begin{bmatrix}\lambda_1 & 0\\0 & \lambda_2\end{bmatrix}R
\end{aligned}
\end{equation}</script><p>最后使用实对称矩阵对角化处理后得到我们想要的结果。</p>
<h3 id="1-2-2-计算对应的角点响应函数-R"><a href="#1-2-2-计算对应的角点响应函数-R" class="headerlink" title="1.2.2 计算对应的角点响应函数$R$"></a>1.2.2 计算对应的角点响应函数$R$</h3><p>通过矩阵的梯度变化可以得到协方差矩阵M，协方差矩阵M决定了灰度值的加权变化量。因此通过计算<strong>角点响应函数R</strong>得到每个窗口对应的得分:</p>
<script type="math/tex; mode=display">
R = det(M)-k(trace(M))^2</script><p>其中$det(M)=\lambda_1\lambda_2$为矩阵的行列式，$trace(M)=\lambda_1+\lambda_2$为矩阵的迹。</p>
<p>$k$是一个经验常数，需要经验确定它的合适大小，通常在(0.04,0.06)之间取值。</p>
<h3 id="1-2-3-角点判定"><a href="#1-2-3-角点判定" class="headerlink" title="1.2.3 角点判定"></a>1.2.3 角点判定</h3><p>根据R值判断窗口是平面、边缘还是角点：</p>
<ul>
<li>平面：$|R|$值非常小，$\lambda_1$和$\lambda_2$都较小，窗口区域的像素点的梯度变化小。</li>
<li>边缘：$|R|$值为负数，$\lambda_1 \gg \lambda_2$或$\lambda_2 \gg \lambda_1$，像素点的某个方向的梯度幅值变化比较明显，另一个方向上的梯度变化比较弱。</li>
<li>角点：$|R|$值很大，$(I_x,I_y)$对应的$\lambda_1$和$\lambda_2$都很大。像素点的梯度分布比较散，梯度变化程度比较大。</li>
</ul>
<p>如下图所示：</p>
<p><img src="https://camo.githubusercontent.com/c6eef9fa98b4f1e099bc722b21536c73c6b9bf9f/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c7939706257466e5a584d794d4445314c6d4e75596d78765a334d75593239744c324a73623263764e4455784e6a59774c7a49774d5459774e4338304e5445324e6a41744d6a41784e6a41304d6a45784d5441314e4455354f5445744e4451304e6a6b314e5445344c6e42755a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67237069635f63656e746572" alt="在这里插入图片描述"></p>
<p>Harris角点检测：设定一个阈值，高于阈值的像素对应角点。</p>
<ul>
<li>补充：角点的非极大值原理—在一个窗口内，如果有很多角点则用值最大的那个角点，其他的角点都删除。</li>
</ul>
<h2 id="1-3-Shi-Tomasi角点检测器"><a href="#1-3-Shi-Tomasi角点检测器" class="headerlink" title="1.3 Shi-Tomasi角点检测器"></a>1.3 Shi-Tomasi角点检测器</h2><p><strong>Shi-Tomasi 角点检测</strong>：《Good_Features_to_Track》论文提出的Harris改进版。</p>
<p>Harris角点检测中每个窗口的分数公式：$R=\lambda_1\lambda_2 - k(\lambda_1+\lambda_2)^2$</p>
<p>缺陷：Harris角点检测算法的稳定性和k值有关，但k是经验值，不好设定最佳值。</p>
<p>改进：角点稳定性与矩阵$M$的较小特征值有关，Shi-Tomasi 直接采用较小的特征值作为分数。(如此一来就不用调整k值啦)</p>
<p>Shi-Tomasi角点检测中每个窗口的分数公式：$R=min(\lambda_1,\lambda_2)$</p>
<p>判定角点的方式不变：分数大于设定的阈值，即为角点。</p>
<h2 id="二、OpenCV的Harris算子进行兴趣点检测"><a href="#二、OpenCV的Harris算子进行兴趣点检测" class="headerlink" title="二、OpenCV的Harris算子进行兴趣点检测"></a>二、OpenCV的Harris算子进行兴趣点检测</h2><h2 id="2-1-Harris角点检测"><a href="#2-1-Harris角点检测" class="headerlink" title="2.1 Harris角点检测"></a>2.1 Harris角点检测</h2><p><strong>opencv</strong>提供了实现<strong>Harris</strong>角点检测函数：<a href="https://link.zhihu.com/?target=https%3A//docs.opencv.org/master/dd/d1a/group__imgproc__feature.html%23gac1fc3598018010880e370e2f709b4345">cv2.cornerHarris</a>，下面调用该接口进行<strong>Harris</strong>特征点检测。</p>
<p>函数：<strong>cv2.cornerHarris(src, blockSize, ksize, k[, dst[, borderType]])​</strong></p>
<p>函数功能：对于每一个像素 $(x,y)$，在 ($blockSize$ x $blockSize$) 邻域内，计算梯度图的协方差矩阵$M(x,y)$，通过计算角点响应函数得到结果图。该结果图的局部最大值即图像中的角点。</p>
<p>函数参数：</p>
<ul>
<li><strong>src</strong>:待检测的灰度图像(float32类型)</li>
<li><strong>blockSize</strong>:用于角点检测的领域大小，即窗口尺寸</li>
<li><strong>ksize</strong>:用于计算梯度图的Sobel算子的尺寸</li>
<li><strong>k</strong>:用于计算角点响应函数的参数k，取值范围在0.04~0.06之间</li>
</ul>
<p>待检测的图片：</p>
<p><img src="/article/8b3bd9dd/image1.jpg" alt="image1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测参数</span></span><br><span class="line">block_size = <span class="number">3</span></span><br><span class="line">sobel_size = <span class="number">3</span></span><br><span class="line">k = <span class="number">0.06</span></span><br><span class="line"></span><br><span class="line">image = cv.imread(<span class="string">'image1.jpg'</span>)</span><br><span class="line">print(image.shape)</span><br><span class="line">height = image.shape[<span class="number">0</span>]</span><br><span class="line">width = image.shape[<span class="number">1</span>]</span><br><span class="line">channels = image.shape[<span class="number">2</span>]</span><br><span class="line">print(<span class="string">"width: %s height: %s channel: %s"</span>%(width, height, channels))</span><br><span class="line"><span class="comment"># 将图像转换为灰度图</span></span><br><span class="line">gray_img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 将数据格式转换为32位浮点数</span></span><br><span class="line">gray_img = np.float32(gray_img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用合适值作为输入参数检测角点，得到的结果图用来标出角点</span></span><br><span class="line">corners_img = cv.cornerHarris(gray_img, block_size, sobel_size, k)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">(225, 225, 3)</span><br><span class="line">width: 225 height: 225 channel: 3</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kernel = cv.getStructuringElement(cv.MORPH_RECT,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">dst = cv.dilate(corners_img, kernel)</span><br><span class="line"><span class="comment"># dst = cv.dilate(corners_img,None)</span></span><br><span class="line"><span class="comment"># image[dst&gt;0.05*dst.max()] = [255,0,0]</span></span><br><span class="line"><span class="comment"># num = dst &gt; 0.05 * dst.max()</span></span><br><span class="line"><span class="comment"># count = np.sum(num)</span></span><br><span class="line"><span class="comment"># print(count)</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(height):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(width):</span><br><span class="line">        pix = dst[r,c]</span><br><span class="line">        <span class="comment"># 阈值，蓝色标记角点</span></span><br><span class="line">        <span class="keyword">if</span> pix &gt; <span class="number">0.05</span> * dst.max():</span><br><span class="line">            cv.circle(image,(c,r),<span class="number">2</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">print(count)</span><br><span class="line">cv.imwrite(<span class="string">'harris_img1.jpg'</span>,image)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">741</span><br></pre></td></tr></table></figure>
<p>处理后图片如下：</p>
<p><img src="/article/8b3bd9dd/harris_img1.jpg" alt="harris_img1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用点画图，点小一点，好看一丢丢把。。。</span></span><br><span class="line">image[dst&gt;<span class="number">0.05</span>*dst.max()] = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/article/8b3bd9dd/harris_img2.jpg" alt="harris_img1"></p>
<h2 id="2-2-Shi-Tomasi角点检测"><a href="#2-2-Shi-Tomasi角点检测" class="headerlink" title="2.2 Shi-Tomasi角点检测"></a>2.2 Shi-Tomasi角点检测</h2><p>opencv提供了实现Shi-Tomasi 角点检测函数：<strong>cv2.goodFeaturesToTrack()</strong>，下面调用该接口进行Harris特征点检测。</p>
<p>函数：<strong>goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]])</strong></p>
<p>函数功能：流程大体与Harris相似。不同之处在于窗口分数计算公式不同。在检测到的角点中，所有低于质量水平的角点都会被忽略，合格角点按角点质量进行降序排列，保留质量最高的一个角点，将它附近（最小距离之内）的角点都删掉（类似于非极大值抑制），按这样的方式最后得到 N 个最佳角点。</p>
<p>函数参数：</p>
<ul>
<li><strong>image</strong>：输入灰度图像，float32类型</li>
<li><strong>maxCorners</strong>：返回角点的最大数目，值为0表表示不设置最大值限制，返回所有检测到的角点。</li>
<li><strong>qualityLevel</strong>：质量系数（小于1.0的正数，一般在0.01-0.1之间），表示可接受角点的最低质量水平。该系数乘以最好的角点分数（也就是上面较小的那个特征值），作为可接受的最小分数；例如，如果最好的角点分数值为1500且质量系数为0.01，那么所有质量分数小于15的角都将被忽略。</li>
<li><strong>minDistance</strong>：角之间最小欧式距离，忽略小于此距离的点。</li>
<li><strong>corners</strong>：输出角点坐标</li>
<li><strong>mask</strong>：可选的感兴趣区域，指定想要检测角点的区域。</li>
<li><strong>blockSize</strong>：默认为3，角点检测的邻域大小（窗口尺寸）</li>
<li><strong>useHarrisDetector</strong>：用于指定角点检测的方法，如果是true则使用Harris角点检测，false则使用Shi Tomasi算法。默认为False。</li>
<li><strong>k</strong>：默认为0.04，Harris角点检测时使用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">maxCorners = <span class="number">600</span></span><br><span class="line">qualityLevel = <span class="number">0.01</span></span><br><span class="line">minDistance = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'image1.jpg'</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">corners = cv2.goodFeaturesToTrack(gray, maxCorners, qualityLevel, minDistance)</span><br><span class="line">corners = np.int0(corners)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corners:</span><br><span class="line">    x,y = i.ravel()</span><br><span class="line">    cv2.circle(img,(x,y), <span class="number">2</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># img[y,x] = [255,0,0]</span></span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">cv.imwrite(<span class="string">'Shi-Tomasi.jpg'</span>,img)</span><br><span class="line">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">print(count)</span><br></pre></td></tr></table></figure>
<p><img src="Task01-Harris特征点检测器-兴趣点检测//Tomasi.jpg" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Harris和Shi-Tomasi都是基于梯度计算的角点检测方式。</p>
<p>Harris角点检测的性质：</p>
<ul>
<li><p>阈值界定角点数量</p>
</li>
<li><p>Harris角点算子对亮度和对比度的变化不敏感</p>
<p>因为在进行Harris角点检测时，使用了微分算子对图像进行微分运算，而微分运算对图像密度的拉升或收缩和对亮度的抬高或下降不敏感。换言之，对亮度和对比度的仿射变换并不改变Harris响应的极值点出现的位置，但是，由于阈值的选择，可能会影响角点检测的数量。</p>
<p><img src="/article/8b3bd9dd/image1-3.png" alt="image-20200623145505861"></p>
<p>左图表示亮度变化，右图表示对比度变化。</p>
</li>
<li><p>Harris角点检测算子具有旋转不变性</p>
<p>Harris角点检测算子使用的是角点附近的区域灰度二阶矩矩阵。而二阶矩矩阵可以表示成一个椭圆，椭圆的长短轴正是二阶矩矩阵特征值平方根的倒数。当特征椭圆转动时，特征值并不发生变化，所以判断角点响应值RR也不发生变化，由此说明Harris角点检测算子具有旋转不变性。</p>
</li>
<li><p>Harris角点检测算子不具有尺度不变性</p>
<p><img src="/article/8b3bd9dd/image1-1.png" alt="image-20200623003833148"></p>
<p>如上图所示，当图像被缩小时，在检测窗口尺寸不变的前提下，在窗口内所包含图像的内容是完全不同的。左侧的图像可能被检测为边缘或曲线，而右侧的图像则可能被检测为一个角点。</p>
</li>
</ul>
<p>基于梯度的角点检测器的缺点：计算复杂度高、图像中的噪声阻碍梯度计算。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task01%20Harris%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.md" target="_blank" rel="noopener">Task01 Harris特征点检测器-兴趣点检测</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/83064609" target="_blank" rel="noopener">角点检测：Harris 与 Shi-Tomasi</a></p>
<p><a href="https://www.cnblogs.com/zyly/p/9508131.html" target="_blank" rel="noopener">Harris角点检测原理(赋源码)</a></p>
]]></content>
      <categories>
        <category>图像处理下</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
