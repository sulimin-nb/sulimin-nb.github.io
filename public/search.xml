<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2数理统计与描述性统计</title>
    <url>/article/83114b11.html</url>
    <content><![CDATA[<h1 id="一、数理统计概念"><a href="#一、数理统计概念" class="headerlink" title="一、数理统计概念"></a>一、数理统计概念</h1><h2 id="1-基本概念释义"><a href="#1-基本概念释义" class="headerlink" title="1.基本概念释义"></a>1.基本概念释义</h2><font color="blue">总体</font>：

研究对象的全体，通常用一个随机变量表示。

<font color="blue">个体</font>：

组成总体的每个基本单元。<a id="more"></a>

从总体$X$中随机抽取一部分个体$X_1,X_2,...,X_n$，称$X_1,X_2,...,X_n$为取自$X$的容量为$n$的样本。实际上，数理统计学中的总体是指与总体相联系的某个(某几个)数量指标$X$取值的全体。

<font color="red">样本具有两重性，在一次具体抽样后是一组确定的数值。一般叙述中由于采取随机抽样，样本是一组随机变量(结果未知)。</font>

<p>一般地，用$X_1,X_2,…,X_n$，表示随机样本，取到的值记为$x_1,x_2,…,x_n$称为样本观测值。$n$为样本容量。</p>
<font color="blue">样本分布</font>：样本作为随机变量的概率分布。显然，样本分布取决于总体的性质和样本的性质。

## 2.统计量与抽样

数理统计的任务是采集和处理带有随机影响的数据，或者说收集样本并对之进行加工，在此基础上对研究的问题进行分析并作出一定的结论，这一过程称为<font color="blue">统计推断</font>。在统计推断过程中，对样本进行加工整理，实际上就是根据样本计算出一些量，把研究问题相关的信息集中起来。这种根据样本计算出的量就是<font color="blue">统计量</font>。因此，统计量是样本的某种函数。

定义：设 $X_1,X_2,...,X_n $ 是总体 $X$ 的一个简单随机样本， $T(X_1, X_2,...,X_n)$ 为一个 $n$ 元连续函数，且 $T$ 中不包含任何关于总体的未知参数，则称 $T(X_1, X_2,...,X_n)$ 是一个统计量，称统计量的分布为抽样分布。

### 常用的统计量

<font color="blue">样本均值</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，称$\overline X =  \frac{1} {n} {\sum_{i=1}^{n}X_i}$为样本均值。通常用样本均值来估计总体分布的均值和对有关总体分布均值的假设作检验。</p>
<font color="blue">样本方差</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，$\overline X$ 为样本均值，称$S^2 =  \frac{1} {n-1} {\sum_{i=1}^{n}(X_i-\overline X)^2}$为样本方差。</p>
<p>通常用样本方差来估计总体分布的方差和对有关总体分布均值或方差的假设作检验。</p>
<font color="blue">k阶样本原点矩</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，称$A_k =  \frac{1} {n} {\sum_{i=1}^{n}X_i^k}$</p>
<p>为样本的 $k$ 阶原点矩（可以看到 $k=1$ 时，相当于样本均值），通常用样本的无阶原点矩来估计总体分布的 $k$ 阶原点矩。（可以看到 $k=1$ 时，相当于样本均值）</p>
<p>通常用样本的无阶原点矩来估计总体分布的 $k$ 阶原点矩。</p>
<font color="blue">k阶样本中心矩</font>

<p>设 $X_1,X_2,…,X_n $ 是总体 $X$ 的一个简单随机样本，$\overline X$ 为样本均值，称$M_k =  \frac{1} {n} {\sum_{i=1}^{n}(X_i-\overline X)^k}$为样本的 $k$ 阶中心矩。</p>
<p>通常用样本的 $k$ 阶中心矩来估计总体分布的 $k$ 阶中心矩。</p>
<font color="blue">顺序统计量</font>

<p>设 $X_1,X_2,…,X_n $ 是抽自总体 $X$ 的样本，$x_1,x_2,…，x_n$  为样本观测值。将 $x_1,x_2,…，x_n$  按照从小到大的顺序排列为$x_{(1)}&lt;=x_{(2)}&lt;=…&lt;=x_{(n)}$。</p>
<p>当样本 $X_1,X_2,…,X_n $ 取值 $x_1,x_2,…，x_n$  时，定义 $X_{(k)}$ 取值 $X_{(k)}(k=1,2，…,n)$，称  $X_{(1)},X_{(2)},…,X_{(n)} $ 为 $X_1,X_2,…,X_n $ 的顺序统计量。</p>
<p>显然，$X_{(1)} =min {X_i}$ 是样本观察中最小的一个，称为最小顺序统计量。$X_{(n)} =max {X_i}$ 是样本观测值中取值最大的一个，成为最大顺序统计量。称$X_{（r）}$ 为第 $r$ 个顺序统计量。</p>
<h1 id="二、描述性统计"><a href="#二、描述性统计" class="headerlink" title="二、描述性统计"></a>二、描述性统计</h1><h2 id="1-数据集中趋势的度量"><a href="#1-数据集中趋势的度量" class="headerlink" title="1.数据集中趋势的度量"></a>1.数据集中趋势的度量</h2><font color="blue">平均数</font>

<p>是表示一组数据集中趋势的量数，是指在一组数据中所有数据之和再除以这组数据的个数。</p>
<script type="math/tex; mode=display">
\overline X =  \frac{1} {n} {\sum_{i=1}^{n}X_i}</script><font color="blue">中位数</font>

<p>是指在一组数据，按顺序排列后，居于中间位置的数。中位数描述数据中心位置的数字特征。</p>
<p>对于对称分布的数据，均值与中位数比较接近；对于偏态分布的数据，均值与中位数不同。中位数不受异常值的影响，具有稳健性。</p>
<script type="math/tex; mode=display">
m_p=\left\{
\begin{array}{lcl}
x_{[np]+1},       &      & {当np不是整数}\\
\frac{1}{2}(x_{(np)}+x_{(np+1)})     &      & {当np是整数时}\\
\end{array} \right.</script><font color="blue">频数</font>

<p>同一观测值在一组数据中出现的次数（掷骰子中，一共掷了20次，出现数字5的次数）。</p>
<font color="blue">众数</font>

<p>就是一组数据中，出现次数最多的那个数（几个数）。</p>
<font color="blue">均值 vs 中位数 vs 众数</font>

<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">优点</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">均值</td>
<td style="text-align:center">充分利用所有数据，适用性强</td>
<td style="text-align:center">容易受极端值影响</td>
</tr>
<tr>
<td style="text-align:center">中位数</td>
<td style="text-align:center">不受极端值影响</td>
<td style="text-align:center">缺乏敏感性</td>
</tr>
<tr>
<td style="text-align:center">众数</td>
<td style="text-align:center">不受极端值影响；当数据具有明显的集中趋势时，代表性好</td>
<td style="text-align:center">缺乏唯一性</td>
</tr>
</tbody>
</table>
</div>
<font color="blue">百分位数</font>

<p>百分位数是中位数的推广，将数据按从小到大排列后，对于$0 \leq p &lt; 1$，它的p分位点定义为</p>
<script type="math/tex; mode=display">
m_p=\left\{
\begin{array}{lcl}
x_{[np]+1},       &      & {当np不是整数}\\
\frac{1}{2}(x_{(np)}+x_{(np+1)})     &      & {当np是整数时}\\
\end{array} \right.</script><p>其中，<strong>[np]</strong>表示<strong>np</strong>的整数部分。所以，0.5分位数（第50百分位数）就是中位数。</p>
<p><img src="/article/83114b11/百分位数图.png" alt></p>
<h3 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h3><p><img src="/article/83114b11/image1" alt="image-20200624144415651"></p>
<h2 id="2-数据离散趋势的度量"><a href="#2-数据离散趋势的度量" class="headerlink" title="2.数据离散趋势的度量"></a>2.数据离散趋势的度量</h2><p>表示数据分散（离散，差异）程度的特征量有方差，标准差，极差以及变异系数等。</p>
<font color="blue">方差</font>

<p>用来计算每一个变量（观察值）与总体均数之间的差异。实际工作中，总体均数难以得到时，应用样本统计量代替总体参数，经校正后，样本方差计算公式:</p>
<script type="math/tex; mode=display">
s^2 = \frac{1}{n-1}\sum_{i=1}^{n}{(x_i-\overline{x})}^2</script><font color="blue">标准差</font>

<p>样本方差的开平方成为样本标准差。</p>
<script type="math/tex; mode=display">
s=\sqrt{s^2}=\sqrt{\frac{1}{n-1}\sum_{1}^{n-1}{(x_i-\overline{x})}^2}</script><font color="blue">极差</font>
$$
R=X_{(n)}-x_{(1)}=\max(x)-\min(x)
$$
数据越分散，极差越大。

<font color="blue">变异系数</font>

<ul>
<li>是刻画数据相对分散性的一种度量。变异系数只在平均值不为零时有定义，而且一般适用于平均值大于零的情况。变异系数也被称为<strong>标准离差率</strong>或<strong>单位风险</strong>。</li>
<li>当需要比较两组数据离散程度大小的时候，如果两组数据的测量尺度相差太大，或者数据量纲的不同，变异系数可以消除测量尺度和量纲的影响。</li>
</ul>
<script type="math/tex; mode=display">
CV=100\times\frac{s}{x}(\%)</script><font color="blue">四分位差</font>

<p>样本上、下四分位数之差称为四分位差(或半极差)。</p>
<script type="math/tex; mode=display">
R_1 = Q_3 - Q_1</script><p>它也是度量样本分散性的重要数字特征，特别对于具有异常值的数据，它作为分散性具有稳健性<font color="red">  <strong>（见百分位数示意图）</strong></font>。</p>
<h3 id="python实现-1"><a href="#python实现-1" class="headerlink" title="python实现"></a>python实现</h3><p><img src="/article/83114b11/image2.PNG" alt="image2" style="zoom:80%;"></p>
<h2 id="3-分布特征"><a href="#3-分布特征" class="headerlink" title="3.分布特征"></a>3.分布特征</h2><p> <strong>引言：</strong>描述一个随机变量，不仅要说明它能够取那些值，而且还要关心它取这些值的概率（可能性）。</p>
<font color="blue">离散变量和连续变量</font>

<ul>
<li><font color="blue">离散型随机变量</font>：其数值只能用<strong>自然数或整数</strong>单位表示。例如，<font color="red">  班级人数，电脑台数等，</font>只能按计量单位数计数，这种变量的数值一般用计数方法取得。</li>
<li><font color="blue">连续变量</font>：在一定区间内可以任意取值的变量。例如，<font color="red">人体测量的身高，体重等。</font>

</li>
</ul>
<font color="blue">概率函数</font>：用函数的形式来表达概率。

- **连续型随机变量**的概率函数就叫做**概率密度函数**。
- **离散型随机变量**的概率函数就叫做**概率质量函数**。

<font color="blue">分布函数</font>

<p>设$X$是一个随机变量，对任意的实数$x$，令$F(x)=P(X&lt;=x),x \in (-\infty,+\infty)$，则称$F(x)$是随机变量$X$的分布函数(概率累积函数)。</p>
<p><img src="/article/83114b11/分布函数与密度函数的关系.png" alt></p>
<p><font color="red">密度函数与分布函数关系&lt;/font &gt; </font></p>
<p><font color="blue">正态分布</font>：也称高斯分布，是一个非常常见的连续概率分布，概率密度函数为</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp{\{- \frac{(x-u)^2}{2\sigma^2} \}}, \qquad -\infty<x<+\infty</script><p>则称$X$服从$N(u,\sigma^2)$分布。</p>
<p><img src="/article/83114b11/uniform2.png" alt="uniform2"></p>
<p><font color="red">正态分布的概率密度函数曲线&lt;/font &gt; </font></p>
<p><img src="/article/83114b11/标准正态分布.png" alt="标准正态分布"></p>
<p>​              <font color="red">标准正态分布和对应区间上积分（面积）的百分比&lt;/font &gt; </font></p>
<p>这个概念可以推广到一般正态分布。$[u-3\sigma,u+3\sigma]$的概率密度曲线之下的面积占总面积的99.7%，是著名的$3\sigma$原则。</p>
<h2 id="4-偏度与峰度"><a href="#4-偏度与峰度" class="headerlink" title="4. 偏度与峰度"></a>4. 偏度与峰度</h2><p><font color="blue">偏度（skewness）</font>：也称为偏态，是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。直观看来就是密度函数曲线尾部的相对长度。<strong>偏度刻画的是分布函数（数据）的对称性。</strong></p>
<p>关于均值对称的数据其偏度系数为0，右侧更分散的数据偏度系数为正，左侧更分散的数据偏度系数为负.</p>
<ul>
<li><p><strong>正态分布的偏度为0，两侧尾部长度对称。</strong></p>
</li>
<li><p><strong>左偏:</strong>   </p>
<p>1）若以$b_s$表示偏度。$b_s&lt;0$称分布具有<strong>负偏离</strong>，也称左偏态；</p>
<p>2）此时数据位于均值左边的比位于右边的少，直观表现为左边的尾部相对于与右边的尾部要长；</p>
<p>3）<strong>因为有少数变量值很小，使曲线左侧尾部拖得很长；</strong></p>
</li>
<li><p><strong>右偏：</strong></p>
<p>1）$b_s&gt;0$称分布具有<strong>正偏离</strong>，也称右偏态；</p>
<p>2）此时数据位于均值右边的比位于左边的少，直观表现为右边的尾部相对于与左边的尾部要长；</p>
<p>3）<strong>因为有少数变量值很大，使曲线右侧尾部拖得很长；</strong></p>
</li>
</ul>
<p><font color="blue">峰度(peakedness;kurtosis)</font>：说明的是分布曲线在平均值处峰值高低的特征数。直观看来，峰度反映了峰部的尖度。样本的峰度是和正态分布相比较而言统计量，如果峰度大于正态分布峰度，峰的形状比较尖，比正态分布峰要陡峭。反之亦然。<strong>峰度刻画的是分布函数的集中和分散程度。</strong></p>
<p><img src="/article/83114b11/偏态与峰度.png" alt></p>
<h3 id="公式与python实现"><a href="#公式与python实现" class="headerlink" title="公式与python实现"></a>公式与python实现</h3><p><font color="blue">样本偏度系数</font>：</p>
<script type="math/tex; mode=display">
g_1 = \frac{n}{(n-1)(n-2)s^3}\sum_{i=1}^{n}{(x_i-\overline{x})}^3=\frac{n^2 u_3}{(n-1)(n-2)s^3}</script><p><font color="blue">样本峰度系数</font>：</p>
<script type="math/tex; mode=display">
g_2 = \frac{n(n+1)}{(n-1)(n-2)(n-3)s^4}\sum_{i=1}^{n}{(x_i-\overline{x})}^4-3\frac{(n-1)^2}{(n-2)(n-3)}</script><p><img src="/article/83114b11/image3.PNG" style="zoom:80%;"></p>
]]></content>
      <categories>
        <category>概率统计</category>
      </categories>
      <tags>
        <tag>概率统计</tag>
      </tags>
  </entry>
  <entry>
    <title>3常见分布与假设检验</title>
    <url>/article/7c20a36d.html</url>
    <content><![CDATA[<h2 id="1-一般随机变量"><a href="#1-一般随机变量" class="headerlink" title="1 一般随机变量"></a>1 一般随机变量</h2><h3 id="1-1-随机变量的两种类型"><a href="#1-1-随机变量的两种类型" class="headerlink" title="1.1 随机变量的两种类型"></a>1.1 随机变量的两种类型</h3><p>根据随机变量可能取值的个数分为离散型（取值有限）和连续型（取值无限）两类。</p>
<h3 id="1-2-离散型随机变量"><a href="#1-2-离散型随机变量" class="headerlink" title="1.2 离散型随机变量"></a>1.2 离散型随机变量</h3><p>对于离散型随机变量，使用概率质量函数（probability mass function），简称PMF，来描述其分布律。</p>
<p>假定离散型随机变量X，共有n个取值，$X_1$, $X_2$, ……, $X_n$, 那么</p>
<script type="math/tex; mode=display">
P(X=X_n) \geq 0</script><script type="math/tex; mode=display">
\Sigma_{1}^{n} P(X=X_n) =1</script><p>用到PMF的例子：二项分布，泊松分布<a id="more"></a></p>
<h3 id="1-3-连续型随机变量"><a href="#1-3-连续型随机变量" class="headerlink" title="1.3 连续型随机变量"></a>1.3 连续型随机变量</h3><p>对于连续型随机变量，使用概率密度函数（probability density function），简称PDF，来描述其分布情况。</p>
<p>连续型随机变量的特点在于取任何固定值的概率都为0，因此讨论其在特定值上的概率是没有意义的，应当讨论其在某一个区间范围内的概率，这就用到了概率密度函数的概念。</p>
<p>假定连续型随机变量X，f(x)为概率密度函数， 对于任意实数范围如[a,b]，有</p>
<script type="math/tex; mode=display">
P \lbrace a\leq X \leq b\rbrace = \int ^b_a f(x) {\rm d}x</script><p>用到PDF的例子：均匀分布，正态分布，指数分布</p>
<p>对于连续型随机变量，通常还会用到累积分布函数 (cumulative distribution function)，简称CDF，来描述其性质，在数学上CDF是PDF的积分形式。</p>
<p>分布函数F(x)在点x处的函数值表示X落在区间(−∞,x]内的概率，所以分布函数就是定义域为R的一个普通函数，因此我们可以把概率问题转化为函数问题，从而可以利用普通的函数知识来研究概率问题，增大了概率的研究范围。</p>
<h2 id="2-常见分布"><a href="#2-常见分布" class="headerlink" title="2 常见分布"></a>2 常见分布</h2><p>本节通过一些实际例子来认识各种不同的分布及其应用场景</p>
<h3 id="2-1-离散型分布"><a href="#2-1-离散型分布" class="headerlink" title="2.1 离散型分布"></a>2.1 离散型分布</h3><h4 id="2-1-1-二项分布（Binomial-distribution）"><a href="#2-1-1-二项分布（Binomial-distribution）" class="headerlink" title="2.1.1 二项分布（Binomial distribution）"></a>2.1.1 二项分布（Binomial distribution）</h4><p>二项分布可以认为是一种只有两种结果（成功/失败)的单次试验重复多次后成功次数的分布概率。</p>
<p>二项分布需要满足以下条件：</p>
<ul>
<li>试验次数是固定的</li>
<li>每次试验都是独立的</li>
<li>对于每次试验成功的概率都是一样的</li>
</ul>
<p>一些二项分布的例子：</p>
<ul>
<li>销售电话成功的次数</li>
<li>一批产品中有缺陷的产品数量</li>
<li>掷硬币正面朝上的次数</li>
<li>在一袋糖果中取糖果吃，拿到红色包装的次数</li>
</ul>
<p>在n次试验中，单次试验成功率为p，失败率q=1-p，则出现成功次数的概率为</p>
<script type="math/tex; mode=display">
P(X=x) = C_n^x p^x q^{n-x}</script><h4 id="2-1-2-泊松分布（Poisson-distribution）"><a href="#2-1-2-泊松分布（Poisson-distribution）" class="headerlink" title="2.1.2 泊松分布（Poisson distribution）"></a>2.1.2 泊松分布（Poisson distribution）</h4><p>泊松分布是用来描述泊松试验的一种分布，满足以下两个特征的试验可以认为是泊松试验：</p>
<ul>
<li>所考察的事件在任意两个长度相等的区间里发生一次的机会均等</li>
<li>所考察的事件在任何一个区间里发生与否和在其他区间里发生与否没有相互影响，即是独立的</li>
</ul>
<p>泊松分布需要满足一些条件：</p>
<ul>
<li>试验次数n趋向于无穷大</li>
<li>单次事件发生的概率p趋向于0</li>
<li>np是一个有限的数值</li>
</ul>
<p>泊松分布的一些例子：</p>
<ul>
<li>一定时间段内，某航空公司接到的订票电话数</li>
<li>一定时间内，到车站等候公交汽车的人数</li>
<li>一匹布上发现的瑕疵点的个数</li>
<li>一定页数的书刊上出现的错别字个数</li>
</ul>
<p>一个服从泊松分布的随机变量X，在具有比率参数（rate parameter）λ （λ=np）的一段固定时间间隔内，事件发生次数为i的概率为</p>
<script type="math/tex; mode=display">
P\lbrace X= i \rbrace = e^{-λ} \frac{λ^i}{i!}</script><h4 id="2-1-3-二项分布，泊松分布，正态分布的关系"><a href="#2-1-3-二项分布，泊松分布，正态分布的关系" class="headerlink" title="2.1.3 二项分布，泊松分布，正态分布的关系"></a>2.1.3 二项分布，泊松分布，正态分布的关系</h4><p>这三个分布之间具有非常微妙的关联。</p>
<p>当n很大，p很小时，如<em>n</em> ≥ 100 and <em>np</em> ≤ 10时，二项分布可以近似为泊松分布。</p>
<p>当λ很大时，如λ≥1000时，泊松分布可以近似为正态分布。</p>
<p>当n很大时，np和n(1-p)都足够大时，如n ≥ 100 , np  ≥10，n(1-p) ≥10时，二项分布可以近似为正态分布。</p>
<h4 id="2-1-4-其他离散型随机分布"><a href="#2-1-4-其他离散型随机分布" class="headerlink" title="2.1.4 其他离散型随机分布"></a>2.1.4 其他离散型随机分布</h4><p>除了二项分布和泊松分布以外，还有其他一些不太常用的离散型分布。</p>
<h5 id="几何分布（Geometric-distribution）"><a href="#几何分布（Geometric-distribution）" class="headerlink" title="几何分布（Geometric distribution）"></a>几何分布（Geometric distribution）</h5><p>考虑独立重复试验，几何分布描述的是经过k次试验才首次获得成功的概率，假定每次成功率为p，</p>
<script type="math/tex; mode=display">
P\lbrace X= n \rbrace = {(1-p)}^{n-1} p</script><h5 id="负二项分布（Negative-binomial-distribution）"><a href="#负二项分布（Negative-binomial-distribution）" class="headerlink" title="负二项分布（Negative binomial distribution）"></a>负二项分布（Negative binomial distribution）</h5><p>考虑独立重复试验，负二项分布描述的是试验一直进行到成功r次的概率，假定每次成功率为p，</p>
<script type="math/tex; mode=display">
P\lbrace X= n \rbrace = C_{n-1}^{r-1} p^r {(1-p)}^{n-r}</script><h5 id="超几何分布（Hypergeometric-Distribution）"><a href="#超几何分布（Hypergeometric-Distribution）" class="headerlink" title="超几何分布（Hypergeometric Distribution）"></a>超几何分布（Hypergeometric Distribution）</h5><p>超几何分布描述的是在一个总数为N的总体中进行有放回地抽样，其中在总体中k个元素属于一组，剩余N-k个元素属于另一组，假定从总体中抽取n次，其中包含x个第一组的概率为</p>
<script type="math/tex; mode=display">
P\lbrace X= n \rbrace = \frac {C_{k}^{x} C_{N-k}^{n-x}} {C_{N}^{n}}</script><h3 id="2-2-连续型分布"><a href="#2-2-连续型分布" class="headerlink" title="2.2 连续型分布"></a>2.2 连续型分布</h3><h4 id="2-2-1-均匀分布-（Uniform-distribution）"><a href="#2-2-1-均匀分布-（Uniform-distribution）" class="headerlink" title="2.2.1 均匀分布 （Uniform distribution）"></a>2.2.1 均匀分布 （Uniform distribution）</h4><p>均匀分布指的是一类在定义域内概率密度函数处处相等的统计分布。</p>
<p>若X是服从区间[a,b]上的均匀分布，则记作X~U[a,b]。</p>
<p>均匀分布X的概率密度函数为</p>
<script type="math/tex; mode=display">
f(x)=
\begin{cases}
\frac {1} {b-a} ,  &  a \leq x  \leq b \\
0, & others
\end{cases}</script><p>分布函数为</p>
<script type="math/tex; mode=display">
F(x)=\begin{cases}
0 ,  &  x< a \\
(x-a)(b-a), & a \leq x  \leq b \\
1, & x>b
\end{cases}</script><p>均匀分布的一些例子：</p>
<ul>
<li>一个理想的随机数生成器</li>
<li>一个理想的圆盘以一定力度旋转后静止时的角度</li>
</ul>
<h4 id="2-2-2-正态分布-（Normal-distribution）"><a href="#2-2-2-正态分布-（Normal-distribution）" class="headerlink" title="2.2.2 正态分布 （Normal distribution）"></a>2.2.2 正态分布 （Normal distribution）</h4><p>正态分布，也叫做高斯分布，是最为常见的统计分布之一，是一种对称的分布，概率密度呈现钟摆的形状，其概率密度函数为</p>
<script type="math/tex; mode=display">
f(x)=\frac{1}{\sqrt{2π}\sigma}e^{\frac{-(x-u)^2}{2\sigma^2}}</script><p>记为X ~ N(μ, $σ^2$) , 其中μ为正态分布的均值，σ为正态分布的标准差</p>
<p>有了一般正态分布后，可以通过公式变换将其转变为标准正态分布 Z ~ N(0,1)，</p>
<script type="math/tex; mode=display">
Z=\frac {X-μ} {σ}</script><p>正态分布的一些例子：</p>
<ul>
<li>成人的身高</li>
<li>不同方向的气体分子的运动速度</li>
<li>测量物体质量时的误差</li>
</ul>
<p>正态分布在现实生活有着非常多的例子，这一点可以从中心极限定理来解释，中心极限定理说的是一组独立同分布的随机样本的平均值近似为正态分布，无论随机变量的总体符合何种分布。</p>
<h4 id="2-2-3-指数分布-（Exponential-distribution）"><a href="#2-2-3-指数分布-（Exponential-distribution）" class="headerlink" title="2.2.3 指数分布 （Exponential distribution）"></a>2.2.3 指数分布 （Exponential distribution）</h4><p>指数分布通常被广泛用在描述一个特定事件发生所需要的时间，在指数分布随机变量的分布中，有着很少的大数值和非常多的小数值。</p>
<p>指数分布的概率密度函数为</p>
<script type="math/tex; mode=display">
f(x)=
\begin{cases}
λe^{-λx} ,  &   x  \geq 0 \\
0, & x < 0
\end{cases}</script><p>记为 X~E（λ),   其中λ被称为率参数（rate parameter），表示每单位时间发生该事件的次数。</p>
<p>分布函数为</p>
<script type="math/tex; mode=display">
F(a) = P\{X \leq a\} = 1-e^{-λa},  a\geq 0</script><p>指数分布的一些例子：</p>
<ul>
<li>顾客到达一家店铺的时间间隔</li>
<li>从现在开始到发生地震的时间间隔</li>
<li>在产线上收到一个问题产品的时间间隔</li>
</ul>
<p>关于指数分布还有一个有趣的性质的是指数分布是无记忆性的，假定在等候事件发生的过程中已经过了一些时间，此时距离下一次事件发生的时间间隔的分布情况和最开始是完全一样的，就好像中间等候的那一段时间完全没有发生一样，也不会对结果有任何影响，用数学语言来表述是</p>
<script type="math/tex; mode=display">
P\{X>s+t | X> t\} =P\{X>s\}</script><h4 id="2-2-4-其他连续分布"><a href="#2-2-4-其他连续分布" class="headerlink" title="2.2.4 其他连续分布"></a>2.2.4 其他连续分布</h4><p><strong>$\Gamma$分布</strong></p>
<p>常用来描述某个事件总共要发生n次的等待时间的分布</p>
<p><strong>威布尔分布 （Weibull distribution）</strong></p>
<p>常用来描述在工程领域中某类具有“最弱链”对象的寿命</p>
<h3 id="2-3-常见分布的均值和方差汇总"><a href="#2-3-常见分布的均值和方差汇总" class="headerlink" title="2.3 常见分布的均值和方差汇总"></a>2.3 常见分布的均值和方差汇总</h3><p>离散型分布</p>
<p><img src="/article/7c20a36d/discreteoverall.PNG" alt="discreteoverall"></p>
<p>连续型分布</p>
<p><img src="/article/7c20a36d/continuousoverall.PNG" alt="continuousoverall"></p>
<p>图片来自于 [Statistical Inference by Casella and Berger]</p>
<h3 id="2-4-Python-代码实战"><a href="#2-4-Python-代码实战" class="headerlink" title="2.4 Python 代码实战"></a>2.4 Python 代码实战</h3><h4 id="2-4-1-生成一组符合特定分布的随机数"><a href="#2-4-1-生成一组符合特定分布的随机数" class="headerlink" title="2.4.1 生成一组符合特定分布的随机数"></a>2.4.1 生成一组符合特定分布的随机数</h4><p>在Numpy库中，提供了一组random类可以生成特定分布的随机数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成大小为1000的符合b(10,0.5)二项分布的样本集</span></span><br><span class="line">s = numpy.random.binomial(n=<span class="number">10</span>,p=<span class="number">0.5</span>,size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成大小为1000的符合P(1)的泊松分布的样本集</span></span><br><span class="line">s = numpy.random.poisson(lam=<span class="number">1</span>,size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成大小为1000的符合U(0,1)均匀分布的样本集，注意在此方法中边界值为左闭右开区间</span></span><br><span class="line">s = numpy.random.uniform(low=<span class="number">0</span>,high=<span class="number">1</span>,size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成大小为1000的符合N(0,1)正态分布的样本集，可以用normal函数自定义均值，标准差，也可以直接使用standard_normal函数</span></span><br><span class="line">s = numpy.random.normal(loc=<span class="number">0</span>,scale=<span class="number">1</span>,size=<span class="number">1000</span>)</span><br><span class="line">s = numpy.random.standard_normal(size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成大小为1000的符合E(1/2)指数分布的样本集，注意该方法中的参数为指数分布参数λ的倒数</span></span><br><span class="line">s = numpy.random.exponential(scale=<span class="number">2</span>,size=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>除了Numpy，Scipy也提供了一组生成特定分布随机数的方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以均匀分布为例，rvs可用来生成一组随机变量的值</span></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line">stats.uniform.rvs(size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-4-2-计算统计分布的PMF和PDF"><a href="#2-4-2-计算统计分布的PMF和PDF" class="headerlink" title="2.4.2 计算统计分布的PMF和PDF"></a>2.4.2 计算统计分布的PMF和PDF</h4><p>Scipy库提供了一组用于计算离散型随机变量PMF和连续型随机变量PDF的方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算二项分布B(10,0.5)的PMF</span></span><br><span class="line">x=range(<span class="number">11</span>)</span><br><span class="line">p=stats.binom.pmf(x, n=<span class="number">10</span>, p=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算泊松分布P(1)的PMF</span></span><br><span class="line">x=range(<span class="number">11</span>)</span><br><span class="line">p=stats.poisson.pmf(x, mu=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均匀分布U(0,1)的PDF</span></span><br><span class="line">x = numpy.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">p= stats.uniform.pdf(x,loc=<span class="number">0</span>, scale=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算正态分布N(0,1)的PDF</span></span><br><span class="line">x = numpy.linspace(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">1000</span>)</span><br><span class="line">p= stats.norm.pdf(x,loc=<span class="number">0</span>, scale=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算指数分布E(1)的PDF</span></span><br><span class="line">x = numpy.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">1000</span>)</span><br><span class="line">p= stats.expon.pdf(x,loc=<span class="number">0</span>,scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-4-3-计算统计分布的CDF"><a href="#2-4-3-计算统计分布的CDF" class="headerlink" title="2.4.3 计算统计分布的CDF"></a>2.4.3 计算统计分布的CDF</h4><p>类似计算概率质量/密度函数的方法，只需将上节中的pmf或pdf替换为cdf，即可得到分布函数的值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以正态分布为例，计算正态分布N(0,1)的CDF</span></span><br><span class="line">x = numpy.linspace(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">1000</span>)</span><br><span class="line">p = stats.norm.cdf(x,loc=<span class="number">0</span>, scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-4-4-统计分布可视化"><a href="#2-4-4-统计分布可视化" class="headerlink" title="2.4.4 统计分布可视化"></a>2.4.4 统计分布可视化</h4><h5 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a><strong>二项分布</strong></h5><p>比较n=10，p=0.5的二项分布的真实概率质量和10000次随机抽样的结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">x = range(<span class="number">11</span>)  <span class="comment"># 二项分布成功的次数（X轴）</span></span><br><span class="line">t = stats.binom.rvs(<span class="number">10</span>,<span class="number">0.5</span>,size=<span class="number">10000</span>) <span class="comment"># B(10,0.5)随机抽样10000次</span></span><br><span class="line">p = stats.binom.pmf(x, <span class="number">10</span>, <span class="number">0.5</span>) <span class="comment"># B(10,0.5)真实概率质量</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sns.distplot(t,bins=<span class="number">10</span>,hist_kws=&#123;<span class="string">'density'</span>:<span class="literal">True</span>&#125;, kde=<span class="literal">False</span>,label = <span class="string">'Distplot from 10000 samples'</span>)</span><br><span class="line">sns.scatterplot(x,p,color=<span class="string">'purple'</span>)</span><br><span class="line">sns.lineplot(x,p,color=<span class="string">'purple'</span>,label=<span class="string">'True mass density'</span>)</span><br><span class="line">plt.title(<span class="string">'Binomial distribution'</span>)</span><br><span class="line">plt.legend(bbox_to_anchor=(<span class="number">1.05</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/binomial.png" alt="binomial"></p>
<h5 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a><strong>泊松分布</strong></h5><p>比较λ=2的泊松分布的真实概率质量和10000次随机抽样的结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">x=range(<span class="number">11</span>)</span><br><span class="line">t= stats.poisson.rvs(<span class="number">2</span>,size=<span class="number">10000</span>)</span><br><span class="line">p=stats.poisson.pmf(x, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sns.distplot(t,bins=<span class="number">10</span>,hist_kws=&#123;<span class="string">'density'</span>:<span class="literal">True</span>&#125;, kde=<span class="literal">False</span>,label = <span class="string">'Distplot from 10000 samples'</span>)</span><br><span class="line">sns.scatterplot(x,p,color=<span class="string">'purple'</span>)</span><br><span class="line">sns.lineplot(x,p,color=<span class="string">'purple'</span>,label=<span class="string">'True mass density'</span>)</span><br><span class="line">plt.title(<span class="string">'Poisson distribution'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/poisson.png" alt="poisson"></p>
<p>比较不同参数λ对应的概率质量函数，可以验证随着参数增大，泊松分布开始逐渐变得对称，分布也越来越均匀，趋近于正态分布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=range(<span class="number">50</span>)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="keyword">for</span>  lam <span class="keyword">in</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>] :</span><br><span class="line">        p=stats.poisson.pmf(x, lam)</span><br><span class="line">        sns.lineplot(x,p,label=<span class="string">'lamda= '</span>+ str(lam))</span><br><span class="line">plt.title(<span class="string">'Poisson distribution'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/poisson2.png" alt="poisson2"></p>
<h5 id="均匀分布"><a href="#均匀分布" class="headerlink" title="均匀分布"></a><strong>均匀分布</strong></h5><p>比较U(0,1)的均匀分布的真实概率密度和10000次随机抽样的结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">x=numpy.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">t= stats.uniform.rvs(<span class="number">0</span>,<span class="number">1</span>,size=<span class="number">10000</span>)</span><br><span class="line">p=stats.uniform.pdf(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sns.distplot(t,bins=<span class="number">10</span>,hist_kws=&#123;<span class="string">'density'</span>:<span class="literal">True</span>&#125;, kde=<span class="literal">False</span>,label = <span class="string">'Distplot from 10000 samples'</span>)</span><br><span class="line"></span><br><span class="line">sns.lineplot(x,p,color=<span class="string">'purple'</span>,label=<span class="string">'True mass density'</span>)</span><br><span class="line">plt.title(<span class="string">'Uniforml distribution'</span>)</span><br><span class="line">plt.legend(bbox_to_anchor=(<span class="number">1.05</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/uniform.png" alt="uniform"></p>
<h5 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a><strong>正态分布</strong></h5><p>比较N(0,1)的正态分布的真实概率密度和10000次随机抽样的结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">x=numpy.linspace(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">100</span>)</span><br><span class="line">t= stats.norm.rvs(<span class="number">0</span>,<span class="number">1</span>,size=<span class="number">10000</span>)</span><br><span class="line">p=stats.norm.pdf(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sns.distplot(t,bins=<span class="number">100</span>,hist_kws=&#123;<span class="string">'density'</span>:<span class="literal">True</span>&#125;, kde=<span class="literal">False</span>,label = <span class="string">'Distplot from 10000 samples'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.lineplot(x,p,color=<span class="string">'purple'</span>,label=<span class="string">'True mass density'</span>)</span><br><span class="line">plt.title(<span class="string">'Normal distribution'</span>)</span><br><span class="line">plt.legend(bbox_to_anchor=(<span class="number">1.05</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/normal.png" alt="normal"></p>
<p>比较不同均值和标准差组合的正态分布的概率密度函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=numpy.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">100</span>)</span><br><span class="line">p=stats.norm.pdf(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="keyword">for</span>  mean, std <span class="keyword">in</span> [(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">1</span>)]: </span><br><span class="line">        p=stats.norm.pdf(x, mean, std)</span><br><span class="line">        sns.lineplot(x,p,label=<span class="string">'Mean: '</span>+ str(mean) + <span class="string">', std: '</span>+ str(std))</span><br><span class="line">plt.title(<span class="string">'Normal distribution'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/uniform2.png" alt="uniform2"></p>
<h5 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a><strong>指数分布</strong></h5><p>比较E(1)的指数分布的真实概率密度和10000次随机抽样的结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">x=numpy.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">t= stats.expon.rvs(<span class="number">0</span>,<span class="number">1</span>,size=<span class="number">10000</span>)</span><br><span class="line">p=stats.expon.pdf(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sns.distplot(t,bins=<span class="number">100</span>,hist_kws=&#123;<span class="string">'density'</span>:<span class="literal">True</span>&#125;, kde=<span class="literal">False</span>,label = <span class="string">'Distplot from 10000 samples'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.lineplot(x,p,color=<span class="string">'purple'</span>,label=<span class="string">'True mass density'</span>)</span><br><span class="line">plt.title(<span class="string">'Exponential distribution'</span>)</span><br><span class="line">plt.legend(bbox_to_anchor=(<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/expo.png" alt="expo"></p>
<p>比较不同参数的指数分布的概率密度函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=numpy.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="keyword">for</span>  scale <span class="keyword">in</span> [<span class="number">0.2</span>,<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>] :</span><br><span class="line">        p=stats.expon.pdf(x, scale=scale)</span><br><span class="line">        sns.lineplot(x,p,label=<span class="string">'lamda= '</span>+ str(<span class="number">1</span>/scale))</span><br><span class="line">plt.title(<span class="string">'Exponential distribution'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/article/7c20a36d/expo2.png" alt="expo2"></p>
<h2 id="3-假设检验"><a href="#3-假设检验" class="headerlink" title="3 假设检验"></a>3 假设检验</h2><h3 id="3-1-基本概念"><a href="#3-1-基本概念" class="headerlink" title="3.1 基本概念"></a>3.1 基本概念</h3><p>假设检验问题是统计推断中的一类重要问题，在总体的分布函数完全未知或只知其形式，不知其参数的情况，为了推断总体的某些未知特性，提出某些关于总体的假设，这类问题被称为假设检验。</p>
<h3 id="3-2-基本步骤"><a href="#3-2-基本步骤" class="headerlink" title="3.2 基本步骤"></a>3.2 基本步骤</h3><p>一个假设检验问题可以分为5步，无论细节如果变化，都一定会遵循这5个步骤。</p>
<ol>
<li>陈述研究假设，包含原假设（null hypothesis）和备择假设（alternate hypothesis）</li>
<li>为验证假设收集数据</li>
<li>构造合适的统计测试量并测试</li>
<li>决定是接受还是拒绝原假设</li>
<li>展示结论</li>
</ol>
<p>步骤1：</p>
<p>通常来说，我们会把原假设的描述写成变量之间不存在某种差异，或不存在某种关联，备择假设则为存在某种差异或关联。</p>
<p>例如，原假设：男人和女人的平均身高没有差别， 备择假设男人和女人的平均身高存在显著差别。</p>
<p>步骤2:</p>
<p>为了统计检验的结果真实可靠，需要根据实际的假设命题从总体中抽取样本，要求抽样的数据要具有代表性，例如在上述男女平均身高的命题中，抽取的样本要能覆盖到各类社会阶级，各个国家等所有可能影响到身高的因素。</p>
<p>步骤3：</p>
<p>统计检验量有很多种类，但是所有的统计检验都是基于组内方差和组间方差的比较，如果组间方差足够大，使得不同组之间几乎没有重叠，那么统计量会反映出一个非常小的P值，意味着不同组之间的差异不可能是由偶然性导致的。</p>
<p>步骤4：</p>
<p>基于统计量的结果做出接受或拒绝原假设的判断，通常我们会以P=0.05作为临界值（单侧检验）。</p>
<p>步骤5：</p>
<p>展示结论。</p>
<h3 id="3-3-统计量的选择"><a href="#3-3-统计量的选择" class="headerlink" title="3.3 统计量的选择"></a>3.3 统计量的选择</h3><p>选择合适的统计量是进行假设检验的关键步骤，最常用的统计检验包括回归检验(regression test)，比较检验(comparison test)和关联检验(correlation test)三类。</p>
<p><strong>回归检验</strong></p>
<p>回归检验适用于预测变量是数值型的情况，根据预测变量的数量和结果变量的类型又分为以下几种。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">预测变量</th>
<th style="text-align:center">结果变量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">简单线性回归</td>
<td style="text-align:center">单个，连续数值</td>
<td style="text-align:center">连续数值</td>
</tr>
<tr>
<td style="text-align:center">多重线性回归</td>
<td style="text-align:center">多个，连续数值</td>
<td style="text-align:center">连续数值</td>
</tr>
<tr>
<td style="text-align:center">Logistic回归</td>
<td style="text-align:center">连续数值</td>
<td style="text-align:center">二元类别</td>
</tr>
</tbody>
</table>
</div>
<p><strong>比较检验</strong></p>
<p>比较检验适用于预测变量是类别型，结果变量是数值型的情况，根据预测变量的分组数量和结果变量的数量又可以分为以下几种。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">预测变量</th>
<th style="text-align:center">结果变量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Paired t-test</td>
<td style="text-align:center">两组，类别</td>
<td style="text-align:center">组来自同一总体，数值</td>
</tr>
<tr>
<td style="text-align:center">Independent t-test</td>
<td style="text-align:center">两组，类别</td>
<td style="text-align:center">组来自不同总体，数值</td>
</tr>
<tr>
<td style="text-align:center">ANOVA</td>
<td style="text-align:center">两组及以上，类别</td>
<td style="text-align:center">单个，数值</td>
</tr>
<tr>
<td style="text-align:center">MANOVA</td>
<td style="text-align:center">两组及以上，类别</td>
<td style="text-align:center">两个及以上，数值</td>
</tr>
</tbody>
</table>
</div>
<p><strong>关联检验</strong></p>
<p>关联检验常用的只有卡方检验一种，适用于预测变量和结果变量均为类别型的情况。</p>
<p><strong>非参数检验</strong></p>
<p>此外，由于一般来说上述参数检验都需满足一些前提条件，样本之间独立，不同组的组内方差近似和数据满足正态性，所以当这些条件不满足的时候，我们可以尝试用非参数检验来代替参数检验。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">非参数检验</th>
<th style="text-align:center">用于替代的参数检验</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Spearman</td>
<td style="text-align:center">回归和关联检验</td>
</tr>
<tr>
<td style="text-align:center">Sign test</td>
<td style="text-align:center">T-test</td>
</tr>
<tr>
<td style="text-align:center">Kruskal–Wallis</td>
<td style="text-align:center">ANOVA</td>
</tr>
<tr>
<td style="text-align:center">ANOSIM</td>
<td style="text-align:center">MANOVA</td>
</tr>
<tr>
<td style="text-align:center">Wilcoxon Rank-Sum test</td>
<td style="text-align:center">Independent t-test</td>
</tr>
<tr>
<td style="text-align:center">Wilcoxon Signed-rank test</td>
<td style="text-align:center">Paired t-test</td>
</tr>
<tr>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-4-两类错误"><a href="#3-4-两类错误" class="headerlink" title="3.4 两类错误"></a>3.4 两类错误</h3><p>事实上当我们进行假设检验的过程中是存在犯错误的可能的，并且理论上来说错误是无法完全避免的。根据定义，错误分为两类，一类错误（type I error）和二类错误（type II error）。</p>
<ul>
<li><p>一类错误：拒绝真的原假设</p>
</li>
<li><p>二类错误：接受错误的原假设</p>
</li>
</ul>
<p>一类错误可以通过α值来控制，在假设检验中选择的 α（显著性水平）对一类错误有着直接影响。α可以认为是我们犯一类错误的最大可能性。以95%的置信水平为例，a=0.05，这意味着我们拒绝一个真的原假设的可能性是5%。从长期来看，每做20次假设检验会有一次犯一类错误的事件发生。</p>
<p>二类错误通常是由小样本或高样本方差导致的，二类错误的概率可以用β来表示，和一类错误不同的是，此类错误是不能通过设置一个错误率来直接控制的。对于二类错误，可以从功效的角度来估计，首先进行功效分析（power analysis）计算出功效值1-β，进而得到二类错误的估计值β。</p>
<p>一般来说这两类错误是无法同时降低的，在降低犯一类错误的前提下会增加犯二类错误的可能性，在实际案例中如何平衡这两类错误取决于我们更能接受一类错误还是二类错误。</p>
<h3 id="3-5-Python代码实战"><a href="#3-5-Python代码实战" class="headerlink" title="3.5 Python代码实战"></a>3.5 Python代码实战</h3><p>本节通过一些例子来讲解如何使用python进行假设检验。</p>
<h4 id="3-5-1-正态检验"><a href="#3-5-1-正态检验" class="headerlink" title="3.5.1 正态检验"></a>3.5.1 正态检验</h4><p>Shapiro-Wilk Test是一种经典的正态检验方法。</p>
<p>H0: 样本总体服从正态分布</p>
<p>H1: 样本总体不服从正态分布 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> shapiro</span><br><span class="line">data_nonnormal = np.random.exponential(size=<span class="number">100</span>)</span><br><span class="line">data_normal = np.random.normal(size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_judge</span><span class="params">(data)</span>:</span></span><br><span class="line">	stat, p = shapiro(data)</span><br><span class="line">	<span class="keyword">if</span> p &gt; <span class="number">0.05</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">'stat=&#123;:.3f&#125;, p = &#123;:.3f&#125;, probably gaussian'</span>.format(stat,p)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">'stat=&#123;:.3f&#125;, p = &#123;:.3f&#125;, probably not gaussian'</span>.format(stat,p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">normal_judge(data_nonnormal)</span><br><span class="line"><span class="comment"># 'stat=0.850, p = 0.000, probably not gaussian'</span></span><br><span class="line">normal_judge(data_normal)</span><br><span class="line"><span class="comment"># 'stat=0.987, p = 0.415, probably gaussian'</span></span><br></pre></td></tr></table></figure>
<h4 id="3-5-2-卡方检验"><a href="#3-5-2-卡方检验" class="headerlink" title="3.5.2 卡方检验"></a>3.5.2 卡方检验</h4><p>目的：检验两组类别变量是相关的还是独立的</p>
<p>H0: 两个样本是独立的</p>
<p>H1: 两组样本不是独立的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> chi2_contingency</span><br><span class="line">table = [[<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>],[<span class="number">6</span>,  <span class="number">9</span>,  <span class="number">17</span>]]</span><br><span class="line">stat, p, dof, expected = chi2_contingency(table)</span><br><span class="line">print(<span class="string">'stat=%.3f, p=%.3f'</span> % (stat, p))</span><br><span class="line"><span class="keyword">if</span> p &gt; <span class="number">0.05</span>:</span><br><span class="line">	print(<span class="string">'Probably independent'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	print(<span class="string">'Probably dependent'</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># output</span></span><br><span class="line"><span class="comment">#stat=0.272, p=0.873</span></span><br><span class="line"><span class="comment">#Probably independent</span></span><br></pre></td></tr></table></figure>
<h4 id="3-5-3-T-test"><a href="#3-5-3-T-test" class="headerlink" title="3.5.3 T-test"></a>3.5.3 T-test</h4><p>目的：检验两个独立样本集的均值是否具有显著差异</p>
<p>H0: 均值是相等的</p>
<p>H1: 均值是不等的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> ttest_ind</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data1 = np.random.normal(size=<span class="number">10</span>)</span><br><span class="line">data2 = np.random.normal(size=<span class="number">10</span>)</span><br><span class="line">stat, p = ttest_ind(data1, data2)</span><br><span class="line">print(<span class="string">'stat=%.3f, p=%.3f'</span> % (stat, p))</span><br><span class="line"><span class="keyword">if</span> p &gt; <span class="number">0.05</span>:</span><br><span class="line">	print(<span class="string">'Probably the same distribution'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	print(<span class="string">'Probably different distributions'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># stat=-1.382, p=0.184</span></span><br><span class="line"><span class="comment"># Probably the same distribution</span></span><br></pre></td></tr></table></figure>
<h4 id="3-5-4-ANOVA"><a href="#3-5-4-ANOVA" class="headerlink" title="3.5.4 ANOVA"></a>3.5.4 ANOVA</h4><p>目的：与t-test类似，ANOVA可以检验两组及以上独立样本集的均值是否具有显著差异</p>
<p>H0: 均值是相等的</p>
<p>H1: 均值是不等的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> f_oneway</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data1 = np.random.normal(size=<span class="number">10</span>)</span><br><span class="line">data2 = np.random.normal(size=<span class="number">10</span>)</span><br><span class="line">data3 = np.random.normal(size=<span class="number">10</span>)</span><br><span class="line">stat, p = f_oneway(data1, data2, data3)</span><br><span class="line">print(<span class="string">'stat=%.3f, p=%.3f'</span> % (stat, p))</span><br><span class="line"><span class="keyword">if</span> p &gt; <span class="number">0.05</span>:</span><br><span class="line">	print(<span class="string">'Probably the same distribution'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	print(<span class="string">'Probably different distributions'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># stat=0.189, p=0.829</span></span><br><span class="line"><span class="comment"># Probably the same distribution</span></span><br></pre></td></tr></table></figure>
<h4 id="3-5-5-Mann-Whitney-U-Test"><a href="#3-5-5-Mann-Whitney-U-Test" class="headerlink" title="3.5.5 Mann-Whitney U Test"></a>3.5.5 Mann-Whitney U Test</h4><p>目的：检验两个样本集的分布是否相同</p>
<p>H0: 两个样本集的分布相同</p>
<p>H1: 两个样本集的分布不同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> mannwhitneyu</span><br><span class="line">data1 = [<span class="number">0.873</span>, <span class="number">2.817</span>, <span class="number">0.121</span>, <span class="number">-0.945</span>, <span class="number">-0.055</span>, <span class="number">-1.436</span>, <span class="number">0.360</span>, <span class="number">-1.478</span>, <span class="number">-1.637</span>, <span class="number">-1.869</span>]</span><br><span class="line">data2 = [<span class="number">1.142</span>, <span class="number">-0.432</span>, <span class="number">-0.938</span>, <span class="number">-0.729</span>, <span class="number">-0.846</span>, <span class="number">-0.157</span>, <span class="number">0.500</span>, <span class="number">1.183</span>, <span class="number">-1.075</span>, <span class="number">-0.169</span>]</span><br><span class="line">stat, p = mannwhitneyu(data1, data2)</span><br><span class="line">print(<span class="string">'stat=%.3f, p=%.3f'</span> % (stat, p))</span><br><span class="line"><span class="keyword">if</span> p &gt; <span class="number">0.05</span>:</span><br><span class="line">	print(<span class="string">'Probably the same distribution'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	print(<span class="string">'Probably different distributions'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># stat=40.000, p=0.236</span></span><br><span class="line"><span class="comment"># Probably the same distribution</span></span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>Ross S . 概率论基础教程[M]. 人民邮电出版社, 2007.</li>
<li>盛骤, 谢式千, 潘承毅, 等. 概率论与数理统计 (第四版)[J]. 2008.</li>
<li><a href="https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/" target="_blank" rel="noopener">https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/</a></li>
<li><a href="https://www.scipy.org/" target="_blank" rel="noopener">https://www.scipy.org/</a></li>
<li><a href="https://www.thoughtco.com/difference-between-type-i-and-type-ii-errors-3126414" target="_blank" rel="noopener">https://www.thoughtco.com/difference-between-type-i-and-type-ii-errors-3126414</a></li>
</ol>
]]></content>
      <categories>
        <category>概率统计</category>
      </categories>
      <tags>
        <tag>概率统计</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction_and_Word_Vectors</title>
    <url>/article/fd8e5887.html</url>
    <content><![CDATA[<h1 id="Task1-Introduction-and-Word-Vectors"><a href="#Task1-Introduction-and-Word-Vectors" class="headerlink" title="Task1: Introduction and Word Vectors"></a>Task1: Introduction and Word Vectors</h1><p>理论部分</p>
<ul>
<li>介绍NLP研究的对象</li>
<li>如何表示单词的含义</li>
<li>Word2Vec方法的基本原理</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Task02-LBP特征描述算子-人脸检测</title>
    <url>/article/50afbda.html</url>
    <content><![CDATA[<p>学习任务：</p>
<p><strong>本文主要包含以下两部分</strong>：</p>
<ul>
<li><strong>理论部分</strong>：掌握LBP特征描述算子原理</li>
<li><strong>练习部分</strong>：使用OpenCV的LBP检测器完成人脸检测任务</li>
</ul>
<p>LBP是指局部二值模式(Local Binary Pattern)，是一种用来描述图像局部特征的算子，具有灰<br>度不变性和旋转不变性等显著优点。<a id="more"></a></p>
<h1 id="2-1-算法理论"><a href="#2-1-算法理论" class="headerlink" title="2.1 算法理论"></a>2.1 算法理论</h1><h2 id="LBP概念"><a href="#LBP概念" class="headerlink" title="LBP概念"></a>LBP概念</h2><p>LBP指的是局部二值模式，英文全称：Local Binary Pattern，是一种用来描述图像局部特征的算子。<br>LBP特征比较出名的应用是人脸识别和目标检测中。<br>计算机视觉开源库OpenCV：</p>
<ul>
<li>使用LBP特征实现人脸识别的接口。</li>
<li>使用LBP特征实现目标检测分类器的接口。</li>
</ul>
<p>本文将会对上述第一点做简单实现。</p>
<h2 id="基本LBP-纹理特征"><a href="#基本LBP-纹理特征" class="headerlink" title="基本LBP:纹理特征"></a>基本LBP:纹理特征</h2><p>基本LBP特征描述</p>
<ol>
<li>基本的LBP算子定义在像素3*3的领域内；</li>
<li>以领域中文像素为阈值，相邻8个像素的灰度值与中心像素的灰度值比较，若周围像素大于中心像素，标记为1，否则标记为0；</li>
<li>3*3领域内的8个点经过第二步后产生8个二进制数，依次排列为一个二进制序列。</li>
<li>8位二进制序列共有$2^8$即256种LBP值。中心像素的LBP值反映了该像素周围区域的纹理信息。中心像素的灰度值决定了局部区域的整体亮度。</li>
</ol>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://img-blog.csdnimg.cn/20200605193831589.png#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.1 LBP计算示意图</div>
</center>

<p>​        中心像素坐标$(x_0,y_0)$局部领域中像素个数为$P(P&gt;1)$，$g_c$表示中心像素的灰度值，$g_p$ 表示领域像素的灰度值。</p>
<p>​        基本LBP表示为：$LBP(x_0,y_0)=\sum_{p=0}^{P-1} s(g_{p}-g_{c}) 2^{p}$<br>​        s是示性函数：$s(x)=\left\{\begin{array}{l}1, x \geq 0 \\<br>0, x&lt;0<br>\end{array}\right.$</p>
<p>&emsp;&emsp; <font color="blue">基本LBP具有灰度不变性。</font>对光照变化是鲁棒的。</p>
<h2 id="圆形LBP算子"><a href="#圆形LBP算子" class="headerlink" title="圆形LBP算子"></a>圆形LBP算子</h2><p>&emsp;基本LBP算子的缺陷：只覆盖了固定半径范围的小区域，不能适应不同尺度和频率纹理的变化。<br>&emsp;圆形LBP(Circular LBP or Extended LBP)：<strong>将局部领域扩展到任意领域，用圆形领域代替正方形领域。</strong><br>&emsp;改进后的LBP算子允许半径为R的圆形领域有任意多个像素点。<br>    使用可变半径的圆对近邻像素进行编码，可得到如下近邻：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/article/50afbda/20190527221543821.png">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.2 五种编码对应的LBP</div>
</center>

<p>​    半径为R的圆形区域内含有P个采样点的LBP算子，表示为$LBP^{R}_P$；</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://img-blog.csdnimg.cn/20200605202407325.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTk0MDUxMg==,size_16,color_FFFFFF,t_70#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.2 圆形LBP示意图</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/article/50afbda/20190527221655965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTk0MDUxMg==,size_16,color_FFFFFF,t_70#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.2 LBP扩展与多尺度表达</div>
</center>

<p>​        对于给定中心点$(x_c,y_c)$,其邻域像素位置为$(x_p,y_p)$，$p∈P$，其采样点$(x_p,y_p)$用如下公式计算：</p>
<script type="math/tex; mode=display">
{x}_{p}=x_{c}+\operatorname{Rcos}\left(\frac{2 \pi p}{P}\right) \\
y_{p}=y_{c}+\operatorname{Rsin}\left(\frac{2 \pi p}{P}\right)</script><p>​    &emsp;R是采样半径，p是第p个采样点，P是采样数目。如果近邻点不在整数位置上，就需要进行插值运算，然后使用计算出的插值点。OpenCV使用的是双线性插值。</p>
<h2 id="旋转不变性LBP"><a href="#旋转不变性LBP" class="headerlink" title="旋转不变性LBP"></a>旋转不变性LBP</h2><p>实现：<strong>不断旋转圆形邻域得到一系列初始定义的LPB值，取最小值作为中心像素点的LBP特征。</strong></p>
<script type="math/tex; mode=display">L B P_{P R}^{ri}=\min \left(R O R\left(L B P_{P, R}, i\right) | i=0,1, \ldots, P-1\right)\tag{2-7}</script><p>&emsp;其中$L B P_{P R}^{ri}$表示具有旋转不变性的LBP特征。$ROR(x, i)$为旋转函数，表示将P-bit​数右循环i位。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://img-blog.csdnimg.cn/20200606135438907.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTk0MDUxMg==,size_16,color_FFFFFF,t_70#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.3 求取旋转不变的LBP特征示意图
</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/article/50afbda/v55RgEh.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTk0MDUxMg==,size_16,color_FFFFFF,t_70#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.3 36种不同的旋转不变性LBP特征(P=8)
</div>
</center>

<h2 id="Uniform-Pattern-LBP特征"><a href="#Uniform-Pattern-LBP特征" class="headerlink" title="Uniform Pattern LBP特征"></a>Uniform Pattern LBP特征</h2><p>Uniform Pattern，也被称为等价模式或均匀模式。<br>        将LBP算子用于纹理分类或人脸识别时，常用于LBP模式的统计直方图来表达图像的信息，较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP进行降维，使得数据量减少的情况下更好地表达图像信息。<br>        为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“<strong>等价模式</strong>”(Uniform Pattern)来对LBP算子的模式种类<strong>进行降维</strong>。<br>        <strong>在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。</strong></p>
<ul>
<li>将<strong>等价模式</strong>定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。<strong>如00000000(0次跳变)，00000111(只含一次从0到1的跳变)，10001111(先由1跳到0，再由0跳到1，共两次跳变)</strong>,都是等价模式类。</li>
<li>除等价模式类以外的模式都归为另一类，称为<strong>混合模式类</strong>。<strong>例如10010111(共四次跳变)</strong>。</li>
</ul>
<p>&emsp;&emsp;<strong>检查某种模式是否是等价模式</strong>：$U\left(G_{p}\right)=\left|s\left(g_{p_{-1}}-g_{c}\right)-s\left(g_{0}-g_{c}\right)\right|+\sum_{p=1}^{P_{-1}}\left|s\left(g_{p}-g_{c}\right)-s\left(g_{P-1}-g_{c}\right)\right|$<br>&emsp;&emsp;将当前位置和移动一位后的二进制模式按位相减。并绝对值求和。若U$\left(G_{p}\right)$ 小于等于2，则为等价模式。<br>&emsp;&emsp;二进制模式数量由原来的$2^P$种减少为了$P(P-1)+2+1$种。其中等价模式类为$P(P-1)+2$种，在LBP特征图的灰度值为$1-[P(P-1)+2]$，混合模式类为1种，灰度值为0。因此等价模式LBP特征图像整体偏暗。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/article/50afbda/image-20200628174535833.png">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.3 LBP等价模式类(P=8)
</div>
</center>



<h1 id="2-2-基于OpenCV的LBP人脸检测"><a href="#2-2-基于OpenCV的LBP人脸检测" class="headerlink" title="2.2 基于OpenCV的LBP人脸检测"></a>2.2 基于OpenCV的LBP人脸检测</h1><h2 id="多级级联对人脸图像进行检测："><a href="#多级级联对人脸图像进行检测：" class="headerlink" title="多级级联对人脸图像进行检测："></a>多级级联对人脸图像进行检测：</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://img-blog.csdnimg.cn/20200606145525679.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTk0MDUxMg==,size_16,color_FFFFFF,t_70#pic_center">
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 2.3.5 人脸检测流程图
</div>
</center>

<h2 id="基于OpenCV的实现"><a href="#基于OpenCV的实现" class="headerlink" title="基于OpenCV的实现"></a>基于OpenCV的实现</h2><ul>
<li>使用OpenCV预训练模型</li>
<li>将haarcascade_frontalface_default.xml下载至本地以方便调用，下载链接：<a href="https://github.com/opencv/opencv/blob/master/data/lbpcascades/lbpcascade_frontalface_improved.xml" target="_blank" rel="noopener">https://github.com/opencv/opencv/blob/master/data/lbpcascades/lbpcascade_frontalface_improved.xml</a>   </li>
</ul>
<p>函数：<br>detectMultiScale(self, image, scaleFactor=None, minNeighbors=None, flags=None, minSize=None, maxSize=None)<br>参数:<br>1）scaleFactor: 图像缩放比例<br>2）minNeighbors: 每个候选矩形保留的邻居个数，值越大-&gt;精度越大<br>3）minSize：检测到的最小矩形大小<br>4）maxSize: 检测到的最大矩形大小</p>
<p>待测人脸图像(网上随意摘取一张)：</p>
<p><img src="/article/50afbda/image2.jpg" alt="image2"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用LBP进行人脸检测</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">'image2.jpg'</span>)</span><br><span class="line"><span class="comment"># cv2.imshow('test', img)</span></span><br><span class="line">face_detect = cv2.CascadeClassifier(<span class="string">'lbpcascade_frontalface_improved.xml'</span>)</span><br><span class="line"><span class="comment"># ======================检测人脸==============================</span></span><br><span class="line"><span class="comment"># 灰度处理</span></span><br><span class="line">gray = cv2.cvtColor(img, code=cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 检测人脸 按照1.1倍放到 周围最小像素为5</span></span><br><span class="line">face_zone = face_detect.detectMultiScale(gray, scaleFactor=<span class="number">1.1</span>, minNeighbors=<span class="number">2</span>)</span><br><span class="line">print(face_zone)</span><br><span class="line"><span class="comment"># 绘制矩形检测人脸</span></span><br><span class="line"><span class="keyword">for</span> (x, y, w, h) <span class="keyword">in</span> face_zone:</span><br><span class="line">    <span class="comment"># 绘制矩形人脸区域</span></span><br><span class="line">    print(x,y,w,h)</span><br><span class="line">    cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=[<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>], thickness=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 显示图片</span></span><br><span class="line">cv2.imshow(<span class="string">"output"</span>, img)</span><br><span class="line"><span class="comment"># 等待显示，设置任意键退出程序</span></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>检测结果：</p>
<p><img src="/article/50afbda/output.jpg" alt="output"></p>
<h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><p><a href="https://blog.csdn.net/qq_34246778/article/details/90613779?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">LBP(Local Binary Patterns特征)</a></p>
<p><a href="https://blog.csdn.net/YhL_Leo/article/details/52120195" target="_blank" rel="noopener">局部二值模式（Local Binary Patterns）纹理灰度与旋转不变性</a></p>
<p><a href="[https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task02%20LBP%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E7%AE%97%E5%AD%90.md](https://github.com/datawhalechina/team-learning/blob/master/03 计算机视觉/计算机视觉基础：图像处理（下）/Task02 LBP特征描述算子.md">Task02 LBP特征描述算子</a>)</p>
]]></content>
      <categories>
        <category>图像处理下</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Task01 Harris特征点检测器-兴趣点检测</title>
    <url>/article/8b3bd9dd.html</url>
    <content><![CDATA[<h1 id="Harris特征点检测器-兴趣点检测"><a href="#Harris特征点检测器-兴趣点检测" class="headerlink" title="Harris特征点检测器-兴趣点检测"></a>Harris特征点检测器-兴趣点检测</h1><p><strong>特则点</strong>又称为兴趣点或角点，通常具有旋转不变性和光照不变性和视角不变性等优点，是图像的重要特征之一，常被应用到目标匹配、目标跟踪、三维重建等应用中。</p>
<p><strong>点特征</strong>主要是指图像中的明显点，如突出的角点、边缘端点、权值点等等。</p>
<p><strong>兴趣点提取(检测)算子</strong>是用于点特征提取的算子<a id="more"></a>，常用的有</p>
<ul>
<li>Harris角点检测：用于检测角点</li>
<li>FAST特征检测：用于检测角点</li>
<li>SIFT特征检测：用于检测斑点</li>
<li>SURF特征检测：用于检测角点</li>
<li>BRIEF特征检测：用于检测斑点</li>
<li>ORB：该算法代表带方向的FAST算法和具有旋转不变性的BRIEF算法</li>
</ul>
<p><strong>特征匹配</strong>：</p>
<ul>
<li>暴力(Brute-Force)匹配法</li>
<li>基于FLANN匹配法</li>
</ul>
<h2 id="一、Harris特征点检测算法的思想和数学原理"><a href="#一、Harris特征点检测算法的思想和数学原理" class="headerlink" title="一、Harris特征点检测算法的思想和数学原理"></a>一、Harris特征点检测算法的思想和数学原理</h2><h2 id="1-1-基础知识"><a href="#1-1-基础知识" class="headerlink" title="1.1 基础知识"></a>1.1 基础知识</h2><ul>
<li><p><strong>角点</strong></p>
<p>左图表示一个平坦区域，在各个方向移动，窗口内像素值均没有太大变化；</p>
<p>中图表示一个边缘特征(Edges)，若沿着水平方向移动(梯度方向)，像素值会发生跳变；若沿着边缘移动(平行于边缘)，像素值不变发生变化；</p>
<p>右图表示一个角(Corners)，它朝哪个方向移动，像素值都会发生很大变化。即为<font color="red">角点</font>。</p>
</li>
</ul>
<p><img src="https://camo.githubusercontent.com/460ac04994bec25117ee2724563058da99e5bf1e/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303230303630393230343234393231392e706e673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c33646c61586870626c38304d4459304e7a67784f513d3d2c73697a655f312c636f6c6f725f4646464646462c745f3730237069635f63656e746572" alt="在这里插入图片描述"></p>
<ul>
<li><strong>图像梯度</strong>:图像局部内，图像梯度越大表示该局部内像素值变化越大。图形梯度在数学上可用微分或者积分表示,使用差分来近似导数：$G_x(x,y)=H(x+1,y)-H(x-1,y)$,</li>
<li><strong>补充</strong>：对图像求梯度通常是考虑图像的每个像素的某个领域内的灰度变化，因此通常对原始图像中像素某个领域设置梯度算子，然后采用小区域模板进行卷积计算，常用的有Prewitt算子、Sobel算子、Robinson算子、Laplace算子等。</li>
</ul>
<h2 id="1-2-Harris角点检测算法原理"><a href="#1-2-Harris角点检测算法原理" class="headerlink" title="1.2 Harris角点检测算法原理"></a>1.2 Harris角点检测算法原理</h2><h3 id="1-2-1-计算窗口内部的像素值变化量-E-x-y"><a href="#1-2-1-计算窗口内部的像素值变化量-E-x-y" class="headerlink" title="1.2.1 计算窗口内部的像素值变化量$E(x,y)$"></a>1.2.1 计算窗口内部的像素值变化量$E(x,y)$</h3><p><strong>建立数学模型，确定哪些窗口会引起较大的灰度值变化</strong></p>
<p>窗口$W$对应的像素坐标位置$(x,y)$，窗口的大小决定了有多少位置。</p>
<p>像素位置坐标$(x,y)$对应的像素灰度值为$I(x,y)$，窗口分别向$x$和$y$方向上移动$(u,v)$，到达$(x+u,y+v)$上，对应的像素灰度值$I(x+u,y+v)$。</p>
<p>窗口移动引起的灰度值的变化量为$I(x+u,y+v)-I(x,y)$。</p>
<p>$(x,y)$位置的窗口函数为$w(x,y)$。即为窗口内各像素的权重。</p>
<p><img src="/article/8b3bd9dd/image1-2.png" alt="image-20200623143300133"></p>
<p><strong>窗口移动(u,v)引起的灰度值的加权变化量</strong>：</p>
<script type="math/tex; mode=display">
E(u,v) = \sum_{x,y}{w(x,y){[I(x+u,y+v)-I(x,y)]}^{2}}</script><p>根据二维泰勒公式展开：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
E(u,v) &\approx \sum_{x,y \in W}{w(x,y){[I(x,y)+uI_x+vI_y-I(x,y)]}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y){(uI_x+vI_y)}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y){(u^2I_x^2+vI_y^2+2uvI_xI_y)}^{2}} \\
  &= \sum_{x,y\in W}{w(x,y)\begin{bmatrix}u&v\end{bmatrix}\begin{bmatrix}I_x^2 & I_xI_y\\
                                       I_xI_y & I_y^2\end{bmatrix} \begin{bmatrix}u\\v\end{bmatrix}} \\
  &= \begin{bmatrix}u&v\end{bmatrix}(\sum_{x,y\in W}{w(x,y) \begin{bmatrix}I_x^2 & I_xI_y\\                                     I_xI_y & I_y^2\end{bmatrix} })\begin{bmatrix}u\\v\end{bmatrix}                                      \\
  &= \begin{bmatrix}u&v\end{bmatrix}M\begin{bmatrix}u\\v\end{bmatrix}
\end{aligned}
\end{equation}</script><p>其中$I_x,I_y$分别为窗口内像素点$(x,y)$在$x$方向上和$y$方向上的梯度值。矩阵$M$为：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
M &= \sum_{(x,y)\in W}{w(x,y) \begin{bmatrix}I_x^2 & I_xI_y\\
                                       I_xI_y & I_y^2\end{bmatrix}}\\
  &=R^{-1}\begin{bmatrix}\lambda_1 & 0\\0 & \lambda_2\end{bmatrix}R
\end{aligned}
\end{equation}</script><p>最后使用实对称矩阵对角化处理后得到我们想要的结果。</p>
<h3 id="1-2-2-计算对应的角点响应函数-R"><a href="#1-2-2-计算对应的角点响应函数-R" class="headerlink" title="1.2.2 计算对应的角点响应函数$R$"></a>1.2.2 计算对应的角点响应函数$R$</h3><p>通过矩阵的梯度变化可以得到协方差矩阵M，协方差矩阵M决定了灰度值的加权变化量。因此通过计算<strong>角点响应函数R</strong>得到每个窗口对应的得分:</p>
<script type="math/tex; mode=display">
R = det(M)-k(trace(M))^2</script><p>其中$det(M)=\lambda_1\lambda_2$为矩阵的行列式，$trace(M)=\lambda_1+\lambda_2$为矩阵的迹。</p>
<p>$k$是一个经验常数，需要经验确定它的合适大小，通常在(0.04,0.06)之间取值。</p>
<h3 id="1-2-3-角点判定"><a href="#1-2-3-角点判定" class="headerlink" title="1.2.3 角点判定"></a>1.2.3 角点判定</h3><p>根据R值判断窗口是平面、边缘还是角点：</p>
<ul>
<li>平面：$|R|$值非常小，$\lambda_1$和$\lambda_2$都较小，窗口区域的像素点的梯度变化小。</li>
<li>边缘：$|R|$值为负数，$\lambda_1 \gg \lambda_2$或$\lambda_2 \gg \lambda_1$，像素点的某个方向的梯度幅值变化比较明显，另一个方向上的梯度变化比较弱。</li>
<li>角点：$|R|$值很大，$(I_x,I_y)$对应的$\lambda_1$和$\lambda_2$都很大。像素点的梯度分布比较散，梯度变化程度比较大。</li>
</ul>
<p>如下图所示：</p>
<p><img src="https://camo.githubusercontent.com/c6eef9fa98b4f1e099bc722b21536c73c6b9bf9f/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c7939706257466e5a584d794d4445314c6d4e75596d78765a334d75593239744c324a73623263764e4455784e6a59774c7a49774d5459774e4338304e5445324e6a41744d6a41784e6a41304d6a45784d5441314e4455354f5445744e4451304e6a6b314e5445344c6e42755a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67237069635f63656e746572" alt="在这里插入图片描述"></p>
<p>Harris角点检测：设定一个阈值，高于阈值的像素对应角点。</p>
<ul>
<li>补充：角点的非极大值原理—在一个窗口内，如果有很多角点则用值最大的那个角点，其他的角点都删除。</li>
</ul>
<h2 id="1-3-Shi-Tomasi角点检测器"><a href="#1-3-Shi-Tomasi角点检测器" class="headerlink" title="1.3 Shi-Tomasi角点检测器"></a>1.3 Shi-Tomasi角点检测器</h2><p><strong>Shi-Tomasi 角点检测</strong>：《Good_Features_to_Track》论文提出的Harris改进版。</p>
<p>Harris角点检测中每个窗口的分数公式：$R=\lambda_1\lambda_2 - k(\lambda_1+\lambda_2)^2$</p>
<p>缺陷：Harris角点检测算法的稳定性和k值有关，但k是经验值，不好设定最佳值。</p>
<p>改进：角点稳定性与矩阵$M$的较小特征值有关，Shi-Tomasi 直接采用较小的特征值作为分数。(如此一来就不用调整k值啦)</p>
<p>Shi-Tomasi角点检测中每个窗口的分数公式：$R=min(\lambda_1,\lambda_2)$</p>
<p>判定角点的方式不变：分数大于设定的阈值，即为角点。</p>
<h2 id="二、OpenCV的Harris算子进行兴趣点检测"><a href="#二、OpenCV的Harris算子进行兴趣点检测" class="headerlink" title="二、OpenCV的Harris算子进行兴趣点检测"></a>二、OpenCV的Harris算子进行兴趣点检测</h2><h2 id="2-1-Harris角点检测"><a href="#2-1-Harris角点检测" class="headerlink" title="2.1 Harris角点检测"></a>2.1 Harris角点检测</h2><p><strong>opencv</strong>提供了实现<strong>Harris</strong>角点检测函数：<a href="https://link.zhihu.com/?target=https%3A//docs.opencv.org/master/dd/d1a/group__imgproc__feature.html%23gac1fc3598018010880e370e2f709b4345">cv2.cornerHarris</a>，下面调用该接口进行<strong>Harris</strong>特征点检测。</p>
<p>函数：<strong>cv2.cornerHarris(src, blockSize, ksize, k[, dst[, borderType]])​</strong></p>
<p>函数功能：对于每一个像素 $(x,y)$，在 ($blockSize$ x $blockSize$) 邻域内，计算梯度图的协方差矩阵$M(x,y)$，通过计算角点响应函数得到结果图。该结果图的局部最大值即图像中的角点。</p>
<p>函数参数：</p>
<ul>
<li><strong>src</strong>:待检测的灰度图像(float32类型)</li>
<li><strong>blockSize</strong>:用于角点检测的领域大小，即窗口尺寸</li>
<li><strong>ksize</strong>:用于计算梯度图的Sobel算子的尺寸</li>
<li><strong>k</strong>:用于计算角点响应函数的参数k，取值范围在0.04~0.06之间</li>
</ul>
<p>待检测的图片：</p>
<p><img src="/article/8b3bd9dd/image1.jpg" alt="image1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测参数</span></span><br><span class="line">block_size = <span class="number">3</span></span><br><span class="line">sobel_size = <span class="number">3</span></span><br><span class="line">k = <span class="number">0.06</span></span><br><span class="line"></span><br><span class="line">image = cv.imread(<span class="string">'image1.jpg'</span>)</span><br><span class="line">print(image.shape)</span><br><span class="line">height = image.shape[<span class="number">0</span>]</span><br><span class="line">width = image.shape[<span class="number">1</span>]</span><br><span class="line">channels = image.shape[<span class="number">2</span>]</span><br><span class="line">print(<span class="string">"width: %s height: %s channel: %s"</span>%(width, height, channels))</span><br><span class="line"><span class="comment"># 将图像转换为灰度图</span></span><br><span class="line">gray_img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 将数据格式转换为32位浮点数</span></span><br><span class="line">gray_img = np.float32(gray_img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用合适值作为输入参数检测角点，得到的结果图用来标出角点</span></span><br><span class="line">corners_img = cv.cornerHarris(gray_img, block_size, sobel_size, k)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">(225, 225, 3)</span><br><span class="line">width: 225 height: 225 channel: 3</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kernel = cv.getStructuringElement(cv.MORPH_RECT,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">dst = cv.dilate(corners_img, kernel)</span><br><span class="line"><span class="comment"># dst = cv.dilate(corners_img,None)</span></span><br><span class="line"><span class="comment"># image[dst&gt;0.05*dst.max()] = [255,0,0]</span></span><br><span class="line"><span class="comment"># num = dst &gt; 0.05 * dst.max()</span></span><br><span class="line"><span class="comment"># count = np.sum(num)</span></span><br><span class="line"><span class="comment"># print(count)</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(height):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(width):</span><br><span class="line">        pix = dst[r,c]</span><br><span class="line">        <span class="comment"># 阈值，蓝色标记角点</span></span><br><span class="line">        <span class="keyword">if</span> pix &gt; <span class="number">0.05</span> * dst.max():</span><br><span class="line">            cv.circle(image,(c,r),<span class="number">2</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">print(count)</span><br><span class="line">cv.imwrite(<span class="string">'harris_img1.jpg'</span>,image)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">741</span><br></pre></td></tr></table></figure>
<p>处理后图片如下：</p>
<p><img src="/article/8b3bd9dd/harris_img1.jpg" alt="harris_img1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用点画图，点小一点，好看一丢丢把。。。</span></span><br><span class="line">image[dst&gt;<span class="number">0.05</span>*dst.max()] = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/article/8b3bd9dd/harris_img2.jpg" alt="harris_img1"></p>
<h2 id="2-2-Shi-Tomasi角点检测"><a href="#2-2-Shi-Tomasi角点检测" class="headerlink" title="2.2 Shi-Tomasi角点检测"></a>2.2 Shi-Tomasi角点检测</h2><p>opencv提供了实现Shi-Tomasi 角点检测函数：<strong>cv2.goodFeaturesToTrack()</strong>，下面调用该接口进行Harris特征点检测。</p>
<p>函数：<strong>goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]])</strong></p>
<p>函数功能：流程大体与Harris相似。不同之处在于窗口分数计算公式不同。在检测到的角点中，所有低于质量水平的角点都会被忽略，合格角点按角点质量进行降序排列，保留质量最高的一个角点，将它附近（最小距离之内）的角点都删掉（类似于非极大值抑制），按这样的方式最后得到 N 个最佳角点。</p>
<p>函数参数：</p>
<ul>
<li><strong>image</strong>：输入灰度图像，float32类型</li>
<li><strong>maxCorners</strong>：返回角点的最大数目，值为0表表示不设置最大值限制，返回所有检测到的角点。</li>
<li><strong>qualityLevel</strong>：质量系数（小于1.0的正数，一般在0.01-0.1之间），表示可接受角点的最低质量水平。该系数乘以最好的角点分数（也就是上面较小的那个特征值），作为可接受的最小分数；例如，如果最好的角点分数值为1500且质量系数为0.01，那么所有质量分数小于15的角都将被忽略。</li>
<li><strong>minDistance</strong>：角之间最小欧式距离，忽略小于此距离的点。</li>
<li><strong>corners</strong>：输出角点坐标</li>
<li><strong>mask</strong>：可选的感兴趣区域，指定想要检测角点的区域。</li>
<li><strong>blockSize</strong>：默认为3，角点检测的邻域大小（窗口尺寸）</li>
<li><strong>useHarrisDetector</strong>：用于指定角点检测的方法，如果是true则使用Harris角点检测，false则使用Shi Tomasi算法。默认为False。</li>
<li><strong>k</strong>：默认为0.04，Harris角点检测时使用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">maxCorners = <span class="number">600</span></span><br><span class="line">qualityLevel = <span class="number">0.01</span></span><br><span class="line">minDistance = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'image1.jpg'</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">corners = cv2.goodFeaturesToTrack(gray, maxCorners, qualityLevel, minDistance)</span><br><span class="line">corners = np.int0(corners)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corners:</span><br><span class="line">    x,y = i.ravel()</span><br><span class="line">    cv2.circle(img,(x,y), <span class="number">2</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># img[y,x] = [255,0,0]</span></span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">cv.imwrite(<span class="string">'Shi-Tomasi.jpg'</span>,img)</span><br><span class="line">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">print(count)</span><br></pre></td></tr></table></figure>
<p><img src="Task01-Harris特征点检测器-兴趣点检测//Tomasi.jpg" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Harris和Shi-Tomasi都是基于梯度计算的角点检测方式。</p>
<p>Harris角点检测的性质：</p>
<ul>
<li><p>阈值界定角点数量</p>
</li>
<li><p>Harris角点算子对亮度和对比度的变化不敏感</p>
<p>因为在进行Harris角点检测时，使用了微分算子对图像进行微分运算，而微分运算对图像密度的拉升或收缩和对亮度的抬高或下降不敏感。换言之，对亮度和对比度的仿射变换并不改变Harris响应的极值点出现的位置，但是，由于阈值的选择，可能会影响角点检测的数量。</p>
<p><img src="/article/8b3bd9dd/image1-3.png" alt="image-20200623145505861"></p>
<p>左图表示亮度变化，右图表示对比度变化。</p>
</li>
<li><p>Harris角点检测算子具有旋转不变性</p>
<p>Harris角点检测算子使用的是角点附近的区域灰度二阶矩矩阵。而二阶矩矩阵可以表示成一个椭圆，椭圆的长短轴正是二阶矩矩阵特征值平方根的倒数。当特征椭圆转动时，特征值并不发生变化，所以判断角点响应值RR也不发生变化，由此说明Harris角点检测算子具有旋转不变性。</p>
</li>
<li><p>Harris角点检测算子不具有尺度不变性</p>
<p><img src="/article/8b3bd9dd/image1-1.png" alt="image-20200623003833148"></p>
<p>如上图所示，当图像被缩小时，在检测窗口尺寸不变的前提下，在窗口内所包含图像的内容是完全不同的。左侧的图像可能被检测为边缘或曲线，而右侧的图像则可能被检测为一个角点。</p>
</li>
</ul>
<p>基于梯度的角点检测器的缺点：计算复杂度高、图像中的噪声阻碍梯度计算。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%8B%EF%BC%89/Task01%20Harris%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.md" target="_blank" rel="noopener">Task01 Harris特征点检测器-兴趣点检测</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/83064609" target="_blank" rel="noopener">角点检测：Harris 与 Shi-Tomasi</a></p>
<p><a href="https://www.cnblogs.com/zyly/p/9508131.html" target="_blank" rel="noopener">Harris角点检测原理(赋源码)</a></p>
]]></content>
      <categories>
        <category>图像处理下</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>第7章 文本数据</title>
    <url>/article/88685a55.html</url>
    <content><![CDATA[<p><img src="/article/88685a55/文本数据.png" alt></p>
<h1 id="六、问题与练习"><a href="#六、问题与练习" class="headerlink" title="六、问题与练习"></a>六、问题与练习</h1><h2 id="1-问题"><a href="#1-问题" class="headerlink" title="1.问题"></a>1.问题</h2><p>【问题一】 str对象方法和df/Series对象方法有什么区别?</p>
<ul>
<li><p>str对象方法有很多针对字符串的方法</p>
</li>
<li><p>在replace方法上，二者有较大差异：</p>
<p>1）str.replace针对object类型或string类型，默认操作：正则表达式</p>
<p>​      replace针对任意类型的序列或数据框，正则表达式替换：regex=True。使用字典可以支持      多列替换。</p>
<p>2）str.replace类型赋值参数不能是pd.NA。</p>
<p>3）对于string类型Series，使用replace函数不能使用正则表达式替换。</p>
</li>
</ul>
<p>【问题二】 给出一列string类型，如何判断单元格是否是数值型数据？</p>
<ul>
<li>正则表达式进行匹配。</li>
<li>str.isnumeric有一定的局限性。</li>
</ul>
<p>【问题三】str.split方法的作用是什么？在什么场合下使用？</p>
<ul>
<li>使用分隔符对每个字符串进行分割并返回列表。</li>
<li>可以使用str方法进行元素选择。</li>
</ul>
<p>【问题四】在本章的第二到第四节分别介绍了字符串类型的5类操作，请思考这些操作的应用场景？</p>
<ul>
<li>拆分：</li>
<li>拼接</li>
<li>替换</li>
<li>字符匹配</li>
<li>字符提取</li>
</ul>
<h2 id="2-练习"><a href="#2-练习" class="headerlink" title="2.练习"></a>2.练习</h2><p>【练习一】现有一份关于字符串的数据集，请解决以下问题：</p>
<p>（a）先对字符串编码存储人员信息（在编号后添加ID列），使用如下格式：”xxx(名字)：x国人，性别x，生于x年x月x日“</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/String_data_one.csv'</span>,index_col=<span class="string">'人员编号'</span>, dtype=<span class="string">'string'</span>)</span><br><span class="line">df[<span class="string">'ID'</span>] = df[<span class="string">'姓名'</span>].str.cat([<span class="string">': '</span>+df[<span class="string">'国籍'</span>]+<span class="string">'国人,'</span>,<span class="string">'性别'</span>+df[<span class="string">'性别'</span>]+<span class="string">','</span>,<span class="string">'生于'</span>+df[<span class="string">'出生年'</span>]+<span class="string">'年'</span>,df[<span class="string">'出生月'</span>]+<span class="string">'月'</span>, df[<span class="string">'出生日'</span>] +<span class="string">'日'</span>],na_rep=<span class="string">'*'</span>)</span><br><span class="line">df[<span class="string">'ID'</span>].head()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/88685a55/image-1.png" alt="image-20200627003713531"></p>
<p>（b）将（a）中的人员生日信息部分修改为用中文表示（如一九七四年十月二十三日），其余返回格式不变。</p>
<p>（c）将（b）中的ID列结果拆分为原列表相应的5列，并使用equals检验是否一致。</p>
<p>【练习二】现有一份半虚拟的数据集，第一列包含了新型冠状病毒的一些新闻标题，请解决以下问题：</p>
<p>（a）选出所有关于北京市和上海市新闻标题的所在行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/String_data_two.csv'</span>)</span><br><span class="line">df[<span class="string">'col1'</span>].str.extract(<span class="string">r'(?P&lt;name_1&gt;北京|上海)'</span>).dropna().index</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/88685a55/image-2.png" alt="image-20200626233841173"></p>
<p>（b）求col2的均值。</p>
<p>（c）求col3的均值。</p>
]]></content>
      <categories>
        <category>pandas下</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>第八章-分类数据</title>
    <url>/article/28c12c7e.html</url>
    <content><![CDATA[<p><img src="/article/28c12c7e/分类数据.png" alt></p>
<a id="more"></a>
<h1 id="问题与练习"><a href="#问题与练习" class="headerlink" title="问题与练习"></a>问题与练习</h1><p>【问题一】如何使用union_categoricals方法，它的作用是什么？</p>
<ul>
<li>如果要组合不一定具有相同类别的类别，union_categoricals函数将组合类似列表的类别。新类别将是合并的类别的并集。如下所示：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.api.types <span class="keyword">import</span> union_categoricals</span><br><span class="line">a = pd.Categorical([<span class="string">'b'</span>,<span class="string">'c'</span>])</span><br><span class="line">b = pd.Categorical([<span class="string">'a'</span>,<span class="string">'b'</span>])</span><br><span class="line">union_categoricals([a,b])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/28c12c7e/image-1.png" alt="image-20200627224024855"></p>
<ul>
<li>默认情况下，生成的类别将按照在数据中显示的顺序排列。如果要对类别进行排序，可使用sort_categories=True参数。</li>
<li>union_categoricals也适用于组合相同类别和顺序信息的两个分类。</li>
<li>union_categoricals可以在合并分类时重新编码类别的整数代码。</li>
</ul>
<p>【问题二】利用concat方法将两个序列纵向拼接，它的结果一定是分类变量吗？什么情况下不是？</p>
<ul>
<li>pd.concat对象只能是pd.Series或pd.DataFrame，所以结果是object。</li>
<li>使用union_categoricals拼接两个分类变量可得到分类变量。</li>
</ul>
<p>【问题三】当使用groupby方法或者value_counts方法时，分类变量的统计结果和普通变量有什么区别？</p>
<ul>
<li>分类变量的groupby方法/value_counts方法，统计对象是类别。</li>
<li>普通变量groupby方法/value_counts方法，统计对象是唯一值(不包含NA)。</li>
</ul>
<p>【问题四】下面的代码说明了Series创建分类变量的什么”缺陷”？如何避免？（提示使用Series的copy参数）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cat = pd.Categorical([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>], categories=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">10</span>])</span><br><span class="line">s = pd.Series(cat, name=<span class="string">"cat"</span>)</span><br><span class="line">cat</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">[1, 2, 3, 10]</span><br><span class="line">Categories (5, int64): [1, 2, 3, 4, 10]</span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.iloc[<span class="number">0</span>:<span class="number">2</span>] = <span class="number">10</span></span><br><span class="line">cat</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">[10, 10, 3, 10]</span><br><span class="line">Categories (5, int64): [1, 2, 3, 4, 10]</span><br></pre></td></tr></table></figure>
<p>分类变量在Series改动时也被改动了。<br><strong>使用copy参数避免分类变量被修改。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cat = pd.Categorical([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">10</span>],categories=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">10</span>])</span><br><span class="line">s = pd.Series(cat, name=<span class="string">'cat'</span>, copy=<span class="literal">True</span>)</span><br><span class="line">print(cat)</span><br><span class="line">s.iloc[<span class="number">0</span>:<span class="number">2</span>] = <span class="number">10</span></span><br><span class="line">print(cat)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/28c12c7e/image-2.png" alt="image-20200627230102057"></p>
<p>【练习一】现继续使用第四章中的地震数据集，请解决以下问题：<br>（a）现在将深度分为七个等级：[0.5,10,15,20,30,50,np.inf]，请以深度Ⅰ,Ⅱ,Ⅲ,Ⅳ,Ⅴ,Ⅵ,Ⅶ为索引并按照由浅到深的顺序进行排序。</p>
<p>使用cut方法对列表中的深度划分，并将该列作为索引值。然后按索引排序即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/Earthquake.csv'</span>)</span><br><span class="line">df_result = df.copy()</span><br><span class="line">df_result[<span class="string">'深度'</span>] = pd.cut(df[<span class="string">'深度'</span>],[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">50</span>,np.inf], right=<span class="literal">False</span>, labels=[<span class="string">'Ⅰ'</span>,<span class="string">'Ⅱ'</span>,<span class="string">'Ⅲ'</span>,<span class="string">'Ⅳ'</span>,<span class="string">'Ⅴ'</span>,<span class="string">'Ⅵ'</span>,<span class="string">'Ⅶ'</span>])</span><br><span class="line">df_result = df_result.set_index(<span class="string">'深度'</span>).sort_index()</span><br><span class="line">df_result.head()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/28c12c7e/image-3.png" alt="image-20200627231333013"></p>
<p>（b）在(a)的基础上，将烈度分为4个等级：[0,3,4,5,np.inf]，依次对南部地区的深度和烈度等级建立多级索引排序。</p>
<p>跟(a)很相似，cut方法对深度，烈度进行切分，把index设为[‘深度’，‘烈度’]，然后进行索引排序即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">'烈度'</span>] = pd.cut(df[<span class="string">'烈度'</span>],[<span class="number">0</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,np.inf], right=<span class="literal">False</span>, labels=[<span class="string">'Ⅰ'</span>,<span class="string">'Ⅱ'</span>,<span class="string">'Ⅲ'</span>,<span class="string">'Ⅳ'</span>])</span><br><span class="line">df[<span class="string">'深度'</span>] = pd.cut(df[<span class="string">'深度'</span>],[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">50</span>,np.inf], right=<span class="literal">False</span>, labels=[<span class="string">'Ⅰ'</span>,<span class="string">'Ⅱ'</span>,<span class="string">'Ⅲ'</span>,<span class="string">'Ⅳ'</span>,<span class="string">'Ⅴ'</span>,<span class="string">'Ⅵ'</span>,<span class="string">'Ⅶ'</span>])</span><br><span class="line">df_ds = df.set_index([<span class="string">'深度'</span>,<span class="string">'烈度'</span>])</span><br><span class="line">df_ds.sort_index()</span><br></pre></td></tr></table></figure>
<p>【练习二】 对于分类变量而言，调用第4章中的变形函数会出现一个BUG（目前的版本下还未修复）：例如对于crosstab函数，按照<a href="https://pandas.pydata.org/pandas-docs/version/1.0.0/user_guide/reshaping.html#cross-tabulations" target="_blank" rel="noopener">官方文档的说法</a>，即使没有出现的变量也会在变形后的汇总结果中出现，但事实上并不是这样，比如下面的例子就缺少了原本应该出现的行’c’和列’f’。基于这一问题，请尝试设计my_crosstab函数，在功能上能够返回正确的结果。<br>因为Categories中肯定包含出现的变量。所以将第一个参数作为index，第二个参数作为columns，建立一个DataFrame，然后把出现的变量组合起来，对应位置填入1即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">foo = pd.Categorical([<span class="string">'b'</span>,<span class="string">'a'</span>], categories=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">bar = pd.Categorical([<span class="string">'d'</span>, <span class="string">'e'</span>], categories=[<span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>])</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_crosstab</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    s1 = pd.Series(list(foo.categories), name=<span class="string">'row'</span>)</span><br><span class="line">    s2 = list(bar.categories)</span><br><span class="line">    df = pd.DataFrame(np.zeros((len(s1), len(s2)),int),index=s1, columns=s2)</span><br><span class="line">    index_1 = list(foo)</span><br><span class="line">    index_2 = list(bar)</span><br><span class="line">    <span class="keyword">for</span> loc <span class="keyword">in</span> zip(index_1, index_2):</span><br><span class="line">        df.loc[loc] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line">my_crosstab(foo, bar)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p><img src="/article/28c12c7e/image-4.png" alt="image-20200627232221247"></p>
]]></content>
      <categories>
        <category>pandas下</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
</search>
