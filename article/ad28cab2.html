<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="向前向前向前ε=( o｀ω′)ノ">
  <meta name="author" content="sulimin">
  <meta name="keywords" content="机器学习，数据挖掘，计算机视觉">
  <title>Task03-Haar特征描述算子-人脸监测 - 苏</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="苏" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Sulimin</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-07-02 16:42">
      2020年7月2日 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      38
       分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-post-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-post-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：2020年7月5日 下午
                
              </p>
            
            <article class="markdown-body">
              <h1 id="3-1-算法由来"><a href="#3-1-算法由来" class="headerlink" title="3.1 算法由来"></a>3.1 算法由来</h1><p>&emsp;&emsp;Haar-like特征最早是由Papageorgiou等应用于人脸表示，2001年，Viola和Jones两位大牛发表了今典的《Rapid Object Detection using a Boosted Cascade of Simple Features》和《Robust Real-Time Face Detection》，在AdaBoost算法基础上，使用Haar-like小波特征和积分图方法进行人脸监测，并对AdaBoost训练出的强分类器进行级联。<br>&emsp;&emsp;这两个大咖不是最早提出使用小波特征的，单他们设计了针对人脸监测更有效的特征，可以说是人脸检测史上里程碑式的一笔了，当时这个算法被称为Viola-Jones检测器。又过了一段时间，Rainer Liehart和Jochen Maydt两位大咖把这个检测器进行扩展，最终形成了OpenCV现在的Haar分类器。</p>
<p>&emsp;&emsp;AdaBoost是Freund和Schapire在1995年提出的算法，是对传统Boosting算法的一大提升。Boosting算法的核心思想，是将弱学习方法提升成强学习算法，也就是“三个臭皮匠顶一个诸葛亮”。<a id="more"></a></p>
<font color="blue">Haar分类器 = Haar-like特征 + 积分图方法 + AdaBoost + 级联</font>

<p>Haar分类器算法的要点如下：</p>
<ol>
<li>使用Haar-like特征特征做监测</li>
<li>使用积分图(Integral Image)对Haar-like特征求值进行加速。</li>
<li>使用AdaBoost算法训练区分人脸和非人脸的强分类器。</li>
<li>使用筛选式级联把强分类器级联到一起，提高准确率。</li>
</ol>
<h1 id="3-2-算法理解"><a href="#3-2-算法理解" class="headerlink" title="3.2 算法理解"></a>3.2 算法理解</h1><h2 id="一、Haar-like特征"><a href="#一、Haar-like特征" class="headerlink" title="一、Haar-like特征"></a>一、Haar-like特征</h2><p>&emsp;&emsp;Haar特征分为四类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形。<font color="blue">并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和</font>。Haar特征值反映了图形的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，单矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向(水平、垂直、对角)的结构。</p>
<p><img src="/article/ad28cab2/1328274-20180802215641326-115308739.png" srcset="/img/loading.gif" alt="img"></p>
<p>&emsp;&emsp;图中的A, B和D这类特征，特征数值计算公式为：v=Σ白-Σ黑。图C中，计算公式：v=Σ白-2*Σ黑。将黑色区域像素和乘以2，是为了使两种矩形区域中像素数目一致。我们希望当把矩形放到人脸区域计算出来的特征值和放到非人脸区域计算出来的特征值差别越大越好，这样就可以用来区分人脸和非人脸。<br>&emsp;&emsp;通过改变特征模板的大小和位置，可在图像子窗口中穷举出大量的特征。上图的特征模板称为“特征原型”；特征原型在图像子窗口中扩展（平移伸缩）得到的特征称为“矩形特征”；矩形特征的值称为“特征值”。</p>
<p><img src="/article/ad28cab2/1328274-20180815213149483-1209887019.png" srcset="/img/loading.gif" alt="img"></p>
<p>&emsp;&emsp;上图中两个矩形特征，表示出人脸的某些特征。比如中间一幅表示眼睛区域的颜色比脸颊区域的颜色深，右边一幅表示鼻梁两侧比鼻梁的颜色要深。同样，其他目标，如眼睛等，也可以用一些矩形特征来表示。<font color="blue">使用矩形特征比单纯地使用像素点具有很大的优越性，并且速度更快。</font><br>&emsp;&emsp;矩形特征可位于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化，使得很小的检测窗口含有非常多的矩形特征，如：在24*24像素大小的检测窗口内矩形特征数量可以达到16万个。这样就有两个问题需要解决了：</p>
<p>（1）如何快速计算那么多的特征？—-积分图大显神通；<br>（2）哪些矩形特征才是对分类器分类最有效的？—-如通过AdaBoost算法来训练。</p>
<h2 id="二、Haar-like特征计算-积分图"><a href="#二、Haar-like特征计算-积分图" class="headerlink" title="二、Haar-like特征计算-积分图"></a>二、Haar-like特征计算-积分图</h2><p>&emsp;&emsp;<font color="blue">积分图是只遍历一次图像就可求出图像中所有区域像素和的快速算法</font>，大大提高了图像特征值计算的效率。<br>&emsp;&emsp;积分图的主要思想是将图像从起点开始到各个点形成的矩形区域像素之和作为一个数组的元素提前保存在数组中。当要计算某个区域的像素和时，直接索引数组的元素进行线性计算即可，从而加快了计算速度。<br>&emsp;&emsp;积分图是一种能够描述全局信息的举证表示方法。积分图的构造方式是位置位置（𝑖,𝑗）处的值𝑖𝑖(𝑖,𝑗)是原图像(𝑖,𝑗)左上角方向所有像素𝑓(𝑘,𝑙)的和：</p>
<script type="math/tex; mode=display">
𝑖𝑖(𝑖,𝑗)=\sum_{𝑘≤𝑖,𝑙≤𝑗}{𝑓(𝑘,𝑙)}</script><p>积分图构建算法：<br>1、用𝑠(𝑖,𝑗)表示行方向的累加和，初始化𝑠(𝑖,−1)=0；<br>2、使用𝑖𝑖(𝑖,𝑗)表示一个积分图像，初始化𝑖𝑖(−1,𝑖)=0；<br>3、逐行扫描图像，递归计算每个像素(𝑖,𝑗)行方向的累加和𝑠(𝑖,𝑗)和积分图像𝑖𝑖(𝑖,𝑗)的值：</p>
<script type="math/tex; mode=display">
𝑠(𝑖,𝑗)=𝑠(𝑖,𝑗−1)+𝑓(𝑖,𝑗) \\
𝑖𝑖(𝑖,𝑗)=𝑖𝑖(𝑖−1,𝑗)+𝑠(𝑖,𝑗)</script><p>4、扫描图像一遍，当到达图像右下角像素时，积分图像𝑖𝑖就构建好了。<br>积分图构造好之后，图像中任何矩阵区域像素累加和都可以通过简单运算得到如图所示：</p>
<p><img src="/article/ad28cab2/1328274-20180815205201934-1228753116.png" srcset="/img/loading.gif" alt="img"></p>
<p>设D的四个顶点分别为$\alpha,\beta,\gamma,\delta$，则D的像素和可以表示为：</p>
<script type="math/tex; mode=display">
D_{sum} = ii(\alpha)+ii(\beta)-(ii(\gamma)+ii(\delta))</script><p>Haar-like特征值是两个矩阵像素和的差，同样可以在常数时间内完成。</p>
<h2 id="三、计算Haar特征值"><a href="#三、计算Haar特征值" class="headerlink" title="三、计算Haar特征值"></a>三、计算Haar特征值</h2><p>&emsp;&emsp;由二已知，一个区域的像素值的和，可以由该区域的端点的积分图计算。由前面特征模板的特征值的定义可推出，<font color="blue">矩形特征的特征值由特征端点的积分图计算得到</font>。以A矩形特征为例，如下图，使用积分图计算该特征值：</p>
<p><img src="/article/ad28cab2/1328274-20180816090314814-408684664.png" srcset="/img/loading.gif" alt="img"></p>
<p>区域A的像素值：$𝑖𝑖(5)+𝑖𝑖(1)−𝑖𝑖(2)−𝑖𝑖(4)$</p>
<p>区域B的像素值：$𝑖𝑖(6)+𝑖𝑖(2)−𝑖𝑖(5)−𝑖𝑖(3)$</p>
<p>所以：该矩形特征的特征值为：</p>
<script type="math/tex; mode=display">
𝑖𝑖(5)+𝑖𝑖(1)−𝑖𝑖(2)−𝑖𝑖(4)−[𝑖𝑖(6)+𝑖𝑖(2)−𝑖𝑖(5)−𝑖𝑖(3)] \\\\
=[𝑖𝑖(5)−𝑖𝑖(4)]+[𝑖𝑖(3)−𝑖𝑖(2)]−[𝑖𝑖(2)−𝑖𝑖(1)]−[𝑖𝑖(6)−𝑖𝑖(5)]</script><p>&emsp;&emsp;所以，矩形特征的特征值，只与特征矩形的端点的积分图有关。利用矩形特征的端点的积分图，再进行简单的加减运算，即可得到特征值，如此一来，特征的计算速度大大提高，也提高了目标的检测速度。<br>了解特征值计算后，接下来展示不同特征值的含义。</p>
<p>&emsp;&emsp;下图展示了20X20子窗口里面全部78,460个矩形特征对在全部2,706个人脸样本和4,381个非人脸样本的特征值平均值的分布图。由分布看出，特征的绝大部分的特征值平均值都是分布在0前后的范围内。<br>&emsp;&emsp;出乎意料的是，人脸样本与非人脸样本的分布曲线差别并不大，不过注意到特征值大于或小于某个值后，分布曲线出现了一致性的差别。说明了绝大部分特征对于识别人脸和非人脸的能力是很微小的，但是存在一些特征及相应的阈值，可以有效第区别人脸样本和非人脸样本。<img src="/article/ad28cab2/image-20200704225306093.png" srcset="/img/loading.gif" alt="image-20200704225306093"></p>
<p>&emsp;&emsp;为了更好地说明部分特征对于人脸和非人脸的区分作用，从78,460个矩形特征中随机抽取了两个特征A和B，这两个特征遍历2,706 个人脸样本和4,381 个非人脸样本，计算了每张图像对应的特征值，最后将特征值进行了从小到大的排序，并按照这个新的顺序表绘制了分布图如下所示：</p>
<center class="half">    <img src="/article/ad28cab2/20160921003959958" srcset="/img/loading.gif" width="400"><img src="/article/ad28cab2/20160921004018287" srcset="/img/loading.gif" width="400"></center>

<p>&emsp;&emsp;可以看出，矩形特征A在人脸样本和非人脸样本中的特征值分布相似，所以区分人脸和非人脸的能力很差。下面看矩形特征B在人脸样本和非人脸样本中特征值的分布：</p>
<center class="half">    <img src="/article/ad28cab2/20160921004748821" srcset="/img/loading.gif" width="400"><img src="/article/ad28cab2/20160921004808352" srcset="/img/loading.gif" width="400"></center>

<p>&emsp;&emsp;可以看出，矩形特征B的特征值分布，尤其是0点的位置，在人脸样本和非人脸样本中差别比较大，所以可以更好地实现对人脸分类。<br>&emsp;&emsp;特征 A 和特征 B 的表现大相径庭。<br>&emsp;&emsp;特征 A 对人脸和非人脸样本的特征值为0的点几乎处于相同位置（46.5%，51.5%），且都在所有特征的中间范围 (-5%)。这说明矩形特征 A对于人脸和非人脸几乎没有分辨能力。<br>&emsp;&emsp;特征 B 对非人脸样本的分布，符合我们的预想，特征值为 0的点处于所有特征的中间范围(59.4%)，这说明特征B也“ 看不到” 非人脸的特点。但是对于人脸样本，特征 B 表现了很一致的倾向性，93.4%的特征在 0 点的一侧，与非人脸样本的相差 34%。这说明特征 B 能够相当可靠地分辨人脸和非人脸。<br>&emsp;&emsp;上述的分析说明，确实存在优势的矩形特征，能够在一定的置信范围内区分人脸和非人脸。由于是使用统计的方法计算人脸图像和非人脸图像的差别，因此最后得到的区分阈值，是在某个概率范围内准确地进行区分。<br>上述总结如下：<br>（1）在检测窗口通过平移+缩放可以产生一系列Haar特征，这些特征由于位置和大小不同，分类效果也不同；<br>（2）通过计算Haar特征的特征值，可以有将图像矩阵映射为1维特征值，有效实现了降维。</p>
<h3 id="Haar特征值归一化-也可以采取标准归一化"><a href="#Haar特征值归一化-也可以采取标准归一化" class="headerlink" title="Haar特征值归一化(也可以采取标准归一化)"></a>Haar特征值归一化(也可以采取标准归一化)</h3><p>&emsp;&emsp;从上图中可发现，仅仅在正样本组中12*8大小的Haar特征计算出的特征值变化范围就达到了-2000~+6000，跨度非常大。这种跨度大的特征不利于量化评定特征值，这时候归一化就排上用场了。<font color="blue">对特征值进行归一化，压缩特征值范围。</font><br>&emsp;&emsp;假设当前检测窗口中的图像像素为$i(x,y)$，当前检测窗口为$w\times h$大小(例如上图中20x20大小)。<br>OpenCV采用如下方式归一化：<br>1、计算检测窗口中图像的灰度值和灰度值平方和：<font color="red">(这里的$i^2$怎么用积分图表示？？)</font></p>
<script type="math/tex; mode=display">
sum=\sum{i(x,y)} \\
sq_{sum}=\sum{i^2(x,y)}</script><p>2、计算平均值：</p>
<script type="math/tex; mode=display">
mean = \frac{sum}{w*h}\\
sq_{mean}=\frac{sq_{sum}}{w*h}</script><p>3、计算归一化因子：</p>
<script type="math/tex; mode=display">
varNormFactor=\sqrt{sq_{mean}-mean^2}</script><p>4、归一化特征值：</p>
<script type="math/tex; mode=display">
normValue=\frac{featureValue}{varNormFactor}</script><p>之后使用归一化的特征值𝑛𝑜𝑟𝑚𝑉𝑎𝑙𝑢𝑒与阈值对比。</p>
<h2 id="四、Adaboost级联分类器"><a href="#四、Adaboost级联分类器" class="headerlink" title="四、Adaboost级联分类器"></a>四、Adaboost级联分类器</h2><p>OpenCV中的Adaboost级联分类器的结构，弱分类器-&gt;强分类器-&gt;级联分类器；</p>
<h3 id="1-级联分类器"><a href="#1-级联分类器" class="headerlink" title="1.级联分类器"></a>1.级联分类器</h3><p>Adaboost级联分类器：<br>&emsp;&emsp;级联分类模型是树状结构，每一层—强分类器是树状结构，强分类器中的每一个弱分类器也是树状结构。如下图所示，每一个stage都代表一级强分类器：<br><img src="/article/ad28cab2/1328274-20180816100358784-868305710.png" srcset="/img/loading.gif" alt="img"><br>&emsp;&emsp;当检测窗口通过所有的强分类器时被认为是正样本。每一个强分类器对负样本的判别准确率高，任一级强分类器检测为负样本，就不再继续调用下面的强分类器，直接丢弃，减少了很多的检测时间。<br>&emsp;&emsp;一副图像中待检测的区域中很多是负样本，级联分类器在初期就会抛弃很多负样本的复杂检测，所以级联分类器的速度是非常快的，只有正样本才会送到下一个强分类器再次进行检验，这样就保证了最后输出的正样本的伪正(false positive)的可能性非常低。</p>
<h3 id="2-级联分类器的训练"><a href="#2-级联分类器的训练" class="headerlink" title="2.级联分类器的训练"></a>2.级联分类器的训练</h3><p>1)首先需要训练出m个弱分类器，然后把m个弱分类器按照一定的组合策略，得到一个强分类器，如下图所示：<br>2)重复1步骤n次得到n个强分类器，按照级联的方式组合起来，得到最终的Haar分类器。<br><img src="/article/ad28cab2/1328274-20180816150118683-1847072909.png" srcset="/img/loading.gif" alt="img"></p>
<p>&emsp;&emsp;一个弱分类器是和上图类似的决策树，最基本的弱分类器只包含一个Haar-like特征，即只包含一层决策树(树桩stump)。<br>&emsp;&emsp;以20*20图像为例，78,460个特征，若直接利用AdaBoost训练，78,460个弱分类器组合成强分类器，工作量是极其巨大的。所以必须要有个筛选过程。</p>
<p><font color="blue">首先筛选出T个优秀的最优弱分类器(特征值)，然后把T个最优弱分类器传给AdaBoost进行训练。</font><br><strong>训练最优弱分类器</strong><br>&emsp;&emsp;人脸样本2000张，非人脸样本4000张，这些样本都经过了归一化，大小都是20X20的图像。那么，对于78,460中的任一特征$f_i$，我们计算该特征在这2000人脸样本，4000非人脸样本上的值，得到6000个特征值。将这些特征值排序，然后选取一个最佳的特征值。在该特征值下，对于特征$f_i$而言，样本的加权错误率最低。<br>&emsp;&emsp;在确定了训练子窗口(20x20的图像)的矩形特征数量(78,460)和特征值后，需要对每一个特征$f$，训练一个弱分类器$h(x,f,\rho,\theta)$：</p>
<script type="math/tex; mode=display">
h(x,f,\rho,\theta)=\begin{cases}1,   {\rho f(x)<\rho \theta}\\0,  {other}\end{cases}</script><p>&emsp;&emsp;其中$𝑥$代表一个检测子窗口，$𝑓$为矩形特征，$\theta$为阈值，$\rho$指示不等号的方向。对每个特征$𝑓$，训练一个弱分类器$ℎ(𝑥,𝑓,\rho,\theta)$，就是确定$𝑓$的最优阈值，使得这个弱分类器对所有的训练样本分类误差最小。<br>这里的最优不是指强分类器，只是一个误差相对较低的弱分类器。<br><strong>弱分类器训练的具体步骤：</strong><br>1、对于每个特征$f$，计算所有训练样本的特征值，并将其排序：<br>2、扫描一遍排好序的特征值，对排好序的表中的每个元素，计算下面四个值：<br>计算全部正例的权重和$𝑇^+$；<br>计算全部负例的权重和$T^-$；<br>计算该元素前之前的正例的权重和$𝑆^+$；<br>计算该元素前之前的负例的权重和$𝑆^−$；</p>
<p><img src="/article/ad28cab2/20160921003914442" srcset="/img/loading.gif" alt="这里写图片描述"></p>
<p>3、选取当前元素的特征值$F_{k,j}$和它前面的一个特征值$F_{k,j-1}$之间的数作为阈值，所得到的弱分类器就在当前元素处把样本分开 —— 也就是说这个阈值对应的弱分类器将当前元素前的所有元素分为非人脸（或人脸），而把当前元素后（含）的所有元素分为人脸（或非人脸）。该阈值的分类误差为：</p>
<script type="math/tex; mode=display">
e=\min{(S^+ + (T^- - S^-), S^- + ( T^+ - S^+))}</script><p><strong>公式说明：前一个分类误差计算前提为阈值前为非人脸，后一个分类误差计算前提为阈值前为人脸。</strong><br>&emsp;&emsp;把排序表从头到尾扫描一遍就可以为弱分类器选择使分类误差最小的阈值（最优阈值），即选取了一个最优弱分类器。在本例中，一共有78,460个特征，因此会得到78,460个最优分类器。<br>结合三，可得出以下分析：<br>&emsp;&emsp;阈值$\theta$的含义就清晰可见了。方向指示符$p$ 用以改变不等号的方向。一个弱学习器（一个特征）的要求仅仅是：它能够以稍低于50%的错误率来区分人脸和非人脸图像，因此上面提到只能在某个概率范围内准确地进行区分就已经完全足够。按照这个要求，可以把所有错误率低于50% 的矩形特征都找到（适当地选择阈值，对于固定的训练集，几乎所有的矩形特征都可以满足上述要求）。每轮训练，将选取当轮中的最佳弱分类器（在算法中，迭代$T$次即是选择$T$个最佳弱分类器），最后将每轮得到的最佳弱分类器按照一定方法提升（Boosting）为强分类器。<!--什么意思？？？是先把弱分类器选出来，再Adaboost，那为啥要迭代，直接选前T个不就好了？？？黑人问号脸，啊啊啊啊，是我太蠢，还是讲话太糊,懂了一部分是最惨的--><br>AdaBoost算法的目的是从训练数据中学习一系列弱分类器，然后把这些弱分类器组合成一个强分类器。<br><strong>AdaBoost强分类器的训练步骤：</strong>参考<a href="https://blog.csdn.net/nk_wavelet/article/details/52601567" target="_blank" rel="noopener">AdaBoost人脸监测(3)</a> </p>
<p><font color="red">这里的公式还没有仔细厘清，先无脑抄了，看懂了再把这里删掉</font><br>给定训练数据集$T=\left(x_{i}, y_{i}\right), i=1,2,3, \ldots N$，共$N$个样本，其中样本$x \in X$，实例空间$x \in R^n$，$y_i \in Y=\{-1, +1\}$。$T$为迭代次数。<br><strong>步骤1：</strong>初始化训练数据的权值分布。每个训练数据初始都被赋予相同的权值：$\frac{1}{N}$</p>
<script type="math/tex; mode=display">
D_1 = (w_{11},w_{12},\ldots,w_{1N}), \quad w_{1i}=\frac{1}{N}, \quad i=1,2,\ldots,N.</script><p><strong>步骤2：</strong>进行T轮迭代，用$t=1,2,3, \ldots T$表示迭代的次数。<br>①使用具有权值分布$D_m$的训练数据集测试，得到基本分类器(选取分类误差最低的阈值设计基本分类器)：$h_m(x):X \rightarrow \{−1, +1 \}$<br>②计算$h_m（x）$在训练数据集上的分类误差率：</p>
<script type="math/tex; mode=display">
e_m = P(h_m(x_i)\neq y_i) = \sum_{i=1}^{N}{w_{mi}I(h_m(x_i) \neq y_i)}</script><p>由上述式子可知，$h_m(x)$在训练数据集上的误差$e_m$就是被$h_m(x)$误分类样本的权值之和。</p>
<script type="math/tex; mode=display">
ω_{t,i}=\frac{ω_{t,i}}{\sum\limits_{j=1}^{n}ω_{t,j}}</script><p>②对每个(种)特征$f_j$，训练一个弱分类器$h_j$（如上），每个分类器只使用一种Haar特征进行训练。分类误差为：</p>
<script type="math/tex; mode=display">
ε_j=\sum\limits_{i}ω_i|h_j(x_i)-y_i|</script><p>③从②确定的弱分类器中，找出一个具有最小分类误差的弱分类器$h_t$;<br>④更新每个样本对应的权重:</p>
<script type="math/tex; mode=display">
\omega_{t+1, i}=\omega_{t, i} \beta_{t}^{1-e_{i}}</script><p>这里，如果样本$x_i$被正确分类，则$e_i=0$，否则$e_i=1$，而</p>
<script type="math/tex; mode=display">
\beta_t=\frac{ε_t}{1-ε_t}</script><p>4、最终形成的强分类器组成为：</p>
<script type="math/tex; mode=display">
h(x)=\left\{\begin{array}{cc}
1 & \sum_{t-1}^{T} \alpha_{t} h_{t}(x) \geq 1 / 2 \sum_{t=1}^{T} \alpha_{t} \\
0 & \text { otherwise }
\end{array}\right.</script><p>其中：</p>
<script type="math/tex; mode=display">
\alpha_t=log\frac{1}{\beta_t}</script><p>&emsp;&emsp;在使用Adaboost算法训练分类器之前，需要准备好正、负样本，根据样本特点选择和构造特征集。<br>&emsp;&emsp;由算法的训练过程可知，当弱分类器对样本分类正确，样本的权重会减小；而分类错误时，样本的权重会增加。这样，后面的分类器会加强对错分样本的训练。最后，组合所有的弱分类器形成强分类器，通过比较这些弱分类器投票的加权和与平均投票结果来检测图像。</p>
<h3 id="3-级联分类器的检测"><a href="#3-级联分类器的检测" class="headerlink" title="3.级联分类器的检测"></a>3.级联分类器的检测</h3><p>&emsp;&emsp;整合好了级联分类器，接下来就是高光时刻：检测！<br>&emsp;&emsp;检测是以显示中的一副图片作为输入，然后对图片进行多区域、多尺度的检测。</p>
<ul>
<li>多区域检测是指遍历整张图片。</li>
<li>多尺度检测有两种策略<br>1）搜索窗口的大小不变，不断缩放图片，在这种情况下需要对每个缩放后的图片进行区域特征值的运算，效率较低。<br>2）不断扩大搜索窗口，对图片进行特征值运算，效率较高。<strong>因为1）需要计算大小不同的图片的积分图，而2）只需对原图进行一次积分图即可。不同的搜索窗口的特征值计算在线性时间内即可完成。</strong></li>
</ul>
<p>&emsp;&emsp;无论哪种搜索方法，都会向级联分类器输入大量的子窗口图像，子窗口图像在筛选式级联分类器中依次被每一个节点筛选，丢弃或通过。</p>
<h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>总结Haar分类器的五大训练步骤：</p>
<ol>
<li>准备人脸、非人脸样本集</li>
<li>计算特征值和积分图</li>
<li>筛选出T个优秀的最优弱分类器(特征值)</li>
<li>把T个最优弱分类器传给AdaBoost进行训练，得到一个强分类器</li>
<li>重复3. 4.，将得到的n个强分类器级联成一个Adaboost级联分类器。</li>
</ol>
<p>以20*20窗口为例，有78,460个特征，筛选出T个优秀的最优弱分类器，然后把T个最优弱分类器传给AdaBoost进行训练得到一个强分类器，最后将n个强分类器级联成一个Adaboost级联分类器。</p>
<h2 id="五、分类器的检测"><a href="#五、分类器的检测" class="headerlink" title="五、分类器的检测"></a>五、分类器的检测</h2><p>OpenCV自带了训练器和检测器。如果想从头训练一个分类器检测汽车、飞机等其他物体，可以使用OpenCV构建。细节参考这里：<a href="http://docs.opencv.org/2.4/doc/user_guide/ug_traincascade.html" target="_blank" rel="noopener">Cascade Classifier Training</a>。<br>OpenCV自带的检测器在OpenCV库文件\haarcascades文件\xx.xml文件中。在我的电脑里，具体路径为C:\Users\susu\AppData\Roaming\Python\Python37\site-packages\cv2\data\中。这个文件夹下包含了检测人脸、眼睛、鼻子和嘴等部位的检测器。均需要正面、直立的人体图像。<br>xml文件包含了检测器的相关信息。具体可以参考<a href="https://blog.csdn.net/playezio/article/details/80471000" target="_blank" rel="noopener">haar+adaboost代码讲解(OpenCV)</a>。</p>
<h1 id="3-3-人脸检测-OpenCV简单实现"><a href="#3-3-人脸检测-OpenCV简单实现" class="headerlink" title="3.3 人脸检测(OpenCV简单实现)"></a>3.3 人脸检测(OpenCV简单实现)</h1><h2 id="一、静态图片中的人脸检测"><a href="#一、静态图片中的人脸检测" class="headerlink" title="一、静态图片中的人脸检测"></a>一、静态图片中的人脸检测</h2><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2
<span class="hljs-comment"># 加载图像</span>
img = cv2.imread(<span class="hljs-string">'image2.jpg'</span>, <span class="hljs-number">1</span>)
<span class="hljs-comment"># 创建人脸和人眼的级联分类器，加载.xml分类器文件，即Haar特征的分类器（上一篇使用LBP特征的分类器）</span>
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_frontalface_default.xml'</span>)
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_eye.xml'</span>)
<span class="hljs-comment"># 进行人脸检测，scaleFactor表示图像的压缩率，minNeighbors表示每个人脸矩形的邻近数目</span>
faces = face_cascade.detectMultiScale(img, scaleFactor=<span class="hljs-number">1.3</span>, minNeighbors=<span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> (x, y, w, h) <span class="hljs-keyword">in</span> faces:
    <span class="hljs-comment"># 使用矩形框出人脸</span>
    img = cv2.rectangle(img, (x, y), (x+w, y+h), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>)
    face_area = img[y:y+h, x:x+w]
    <span class="hljs-comment"># 在人脸上检测人眼</span>
    eyes = eye_cascade.detectMultiScale(face_area)
    <span class="hljs-comment"># 使用矩形框出人眼</span>
    <span class="hljs-keyword">for</span> (ex, ey, ew, eh) <span class="hljs-keyword">in</span> eyes:
        cv2.rectangle(face_area, (ex, ey), (ex+ew, ey+eh), (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)
cv2.imshow(<span class="hljs-string">'img'</span>, img)
cv2.waitKey(<span class="hljs-number">0</span>)
cv2.destroyAllWindows()
cv2.imwrite(<span class="hljs-string">'output.jpg'</span>, img)</code></pre>
<h2 id="二、实时人脸监测"><a href="#二、实时人脸监测" class="headerlink" title="二、实时人脸监测"></a>二、实时人脸监测</h2><pre><code class="hljs python"><span class="hljs-comment"># 调用电脑摄像头进行实时人脸+眼睛识别</span>
<span class="hljs-keyword">import</span> cv2

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_frontalface_default.xml'</span>)
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_eye.xml'</span>)
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_smile.xml'</span>)
<span class="hljs-comment"># 调用摄像头</span>
cap = cv2.VideoCapture(<span class="hljs-number">0</span>)
cv2.namedWindow(<span class="hljs-string">'Dynamic'</span>)
<span class="hljs-keyword">while</span>(<span class="hljs-literal">True</span>):
    <span class="hljs-comment"># 获取摄像头拍摄到的画面</span>
    ret, frame = cap.read()
    <span class="hljs-comment"># ret为True表明图片读取成功。</span>
    faces = face_cascade.detectMultiScale(frame, <span class="hljs-number">1.3</span>, <span class="hljs-number">2</span>)
    img = frame
    <span class="hljs-keyword">for</span> (x, y, w, h) <span class="hljs-keyword">in</span> faces:
        <span class="hljs-comment"># 画出人脸框，蓝色，画笔宽度</span>
        img = cv2.rectangle(img, (x, y), (x+w, y+h), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>)
        <span class="hljs-comment"># 框选出人脸区域，在人脸区域而不是全图中进行人眼检测，节省计算资源</span>
        face_area = img[y:y+h, x:x+w]
        eyes = eye_cascade.detectMultiScale(face_area, <span class="hljs-number">1.3</span>, <span class="hljs-number">10</span>)
        <span class="hljs-comment"># 画出人眼框，绿色，画笔宽度为1</span>
        <span class="hljs-keyword">for</span> (ex, ey, ew, eh) <span class="hljs-keyword">in</span> eyes:
            eye_area = cv2.rectangle(face_area, (ex, ey), (ex+ew, ey+eh), (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)
        smile = smile_cascade.detectMultiScale(face_area, scaleFactor=<span class="hljs-number">1.16</span>, minNeighbors=<span class="hljs-number">65</span>, minSize=(<span class="hljs-number">25</span>, <span class="hljs-number">25</span>), flags=cv2.CASCADE_SCALE_IMAGE)
        <span class="hljs-keyword">for</span> (ex, ey, ew, eh) <span class="hljs-keyword">in</span> smile:
            cv2.rectangle(face_area, (ex, ey, ex+ew, ey+eh), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">1</span>)
            cv2.putText(img, <span class="hljs-string">'Smile'</span>, (x, y<span class="hljs-number">-7</span>), <span class="hljs-number">3</span>, <span class="hljs-number">1.2</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">2</span>, cv2.LINE_AA)
    cv2.imshow(<span class="hljs-string">'frame2'</span>, img)
    <span class="hljs-comment"># 按下q键退出</span>
    <span class="hljs-keyword">if</span> cv2.waitKey(<span class="hljs-number">5</span>) &amp; <span class="hljs-number">0xFF</span> == ord(<span class="hljs-string">'q'</span>):
        <span class="hljs-keyword">break</span>
cap.release()
cv2.destroyAllWindows()</code></pre>
<p>简单分析上面的代码:<br>&emsp;&emsp;创建一个级联分类器对象，加载xml检测器，进行人脸监测。</p>
<pre><code class="hljs python">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+<span class="hljs-string">'haarcascade_frontalface_default.xml'</span>)</code></pre>
<p>&emsp;&emsp;将人脸图像放入监测。<strong>不同于LBP检测器，这里彩色的图像也是可以的。</strong></p>
<pre><code class="hljs python">detectMultiScale(image[,scaleFactor[,minNeighbors[,flags,[minSize,[maxSize]]]]])</code></pre>
<p>1）image：待检测的输入图像<br>2）scaleFactor：每一个图像的尺度参数。默认值为1.1。scaleFactor参数控制两个不同大小窗口扫描的间距。参数过大，可能会错过正确的人脸区域。<br>3）minNeighbors：每一个级联矩形应该保留的邻近个数，默认为3.minNeighbors控制与检测率。默认值为3，表明至少有3次重叠监测，认为人脸确实存在。<br>4）minSize：目标最小尺寸<br>5）maxSize：目标最大尺寸</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/zyly/p/9410563.html" target="_blank" rel="noopener">人脸监测之Haar分类器</a><br><a href="https://blog.csdn.net/liulina603/article/details/8617281" target="_blank" rel="noopener">Haar特征与积分图(推荐)</a><br><a href="https://blog.csdn.net/nk_wavelet/article/details/52601567" target="_blank" rel="noopener">AdaBoost人脸检测介绍(3)</a></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B8%8B/">图像处理下</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/article/3b406ffc.html">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">LSTM_Elmo</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/article/67aeaf8.html">
                        <span class="hidden-mobile">pandas下综合练习</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "gIlJLkkEOolcxea5daBOIYB5-gzGzoHsz",
          app_key: "Xwqmsb7cDIWaQB2GG2fCnSHf",
          placeholder: "ヾﾉ≧∀≦)o 来呀！吐槽一番吧！",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: true,
          recordIP: true,
          serverURLs: "",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer>
  (function () {
    // 查询存储的记录
    function getRecord(Counter, target) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({target})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {target, time: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    }

    // 发起自增请求
    function increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    }

    // 构建自增请求体
    function buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "time": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    }

    // 校验是否为有效的 UV
    function validUV() {
      var key = 'LeanCloud_UV_Flag';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    }

    function addCount(Counter) {
      var enableIncr = 'true' === 'true' && window.location.hostname !== 'localhost';
      var getterArr = [];
      var incrArr = [];

      // 请求 PV 并自增
      var pvCtn = document.querySelector('#leancloud-site-pv-container');
      if (pvCtn || enableIncr) {
        var pvGetter = getRecord(Counter, 'site-pv').then((record) => {
          incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-pv');
          if (ele) {
            ele.innerText = record.time + 1;
            if (pvCtn) {
              pvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#leancloud-site-uv-container');
      if (uvCtn || enableIncr) {
        var uvGetter = getRecord(Counter, 'site-uv').then((record) => {
          var vuv = validUV();
          vuv && incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-uv');
          if (ele) {
            ele.innerText = record.time + (vuv ? 1 : 0);
            if (uvCtn) {
              uvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(uvGetter);
      }

      // 如果是文章，请求文章的浏览数，并自增
      if ('true' === 'true') {
        var viewCtn = document.querySelector('#leancloud-post-views-container');
        if (viewCtn || enableIncr) {
          var target = decodeURI('/article/ad28cab2.html');
          var viewGetter = getRecord(Counter, target).then((record) => {
            incrArr.push(buildIncrement(record.objectId))
            if (viewCtn) {
              var ele = document.querySelector('#leancloud-post-views');
              if (ele) {
                ele.innerText = (record.time || 0) + 1;
                viewCtn.style.display = 'inline';
              }
            }
          });
          getterArr.push(viewGetter);
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && increment(Counter, incrArr);
        })
      }
    }

    var app_id = 'gIlJLkkEOolcxea5daBOIYB5-gzGzoHsz'
    var app_key = 'Xwqmsb7cDIWaQB2GG2fCnSHf'
    var server_url = ''

    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': app_id,
            'X-LC-Key': app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };

      addCount(Counter);
    }

    var api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${ app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(resp => resp.json())
        .then(({api_server}) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>






  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Task03-Haar特征描述算子-人脸监测&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 50,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  



  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  











  

  

  

  

  

  





<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":1},"log":false});</script></body>
</html>
