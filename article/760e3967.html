<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=EB Garamond:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sulimin-nb.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/search.xml"};
  </script>

  <meta name="description" content="HOG（Histogram of Oriented Gradients）HOG特征在对象检测与模式匹配中是一种常见的特征提取技术（深度学习之前），是基于本地像素块进行特征直方图提取的一种算法，对象局部的变形与光照影响有很好的稳定性，最初是用HOG特征来来识别人像，通过HOG特征提取+SVM训练，可以得到很好的效果，OpenCV已经有相应的接口。 HOG特征实在2005年CVPR的会议发表，在图像手">
<meta property="og:type" content="article">
<meta property="og:title" content="Task04-HOG特征描述算子-行人检测">
<meta property="og:url" content="https://sulimin-nb.github.io/article/760e3967.html">
<meta property="og:site_name" content="苏">
<meta property="og:description" content="HOG（Histogram of Oriented Gradients）HOG特征在对象检测与模式匹配中是一种常见的特征提取技术（深度学习之前），是基于本地像素块进行特征直方图提取的一种算法，对象局部的变形与光照影响有很好的稳定性，最初是用HOG特征来来识别人像，通过HOG特征提取+SVM训练，可以得到很好的效果，OpenCV已经有相应的接口。 HOG特征实在2005年CVPR的会议发表，在图像手">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/1328274-20180917143312309-1232187669.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/v2-2ccc671e60031942dca8a129410a0383_720w.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/image-1.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/0_5_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/1_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/1_5_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/gradient-kernels.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/20160511100108955">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/x_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/y_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/mag_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/angle_hog.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/hog-cells.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/20200613153022928.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/hog-histogram-1.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMzA1NjcxMy1mMDgzNzBkZGVmMmVhYzE1LnBuZw">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/20200613160337781.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/20200613161947892.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/aHR0cHM6Ly9waWM0LnpoaW1nLmNvbS92Mi0yMzI0MTc3NDIwYzBhNzlkNDhkODQ0YjVlMTI0ZjFmM19iLndlYnA">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/1328274-20180924221334307-1701938273.png">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/v2-2ccc671e60031942dca8a129410a0383_720w.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/hog-detector.jpg">
<meta property="og:image" content="https://sulimin-nb.github.io/article/760e3967/edge_hog.jpg">
<meta property="article:published_time" content="2020-07-06T02:03:41.000Z">
<meta property="article:modified_time" content="2020-07-07T06:06:05.723Z">
<meta property="article:author" content="sulimin">
<meta property="article:tag" content="图像处理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sulimin-nb.github.io/article/760e3967/1328274-20180917143312309-1232187669.png">

<link rel="canonical" href="https://sulimin-nb.github.io/article/760e3967.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Task04-HOG特征描述算子-行人检测 | 苏</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="苏" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">苏</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sulimin-nb.github.io/article/760e3967.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/su1.JPG">
      <meta itemprop="name" content="sulimin">
      <meta itemprop="description" content="向前向前向前ε=( o｀ω′)ノ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="苏">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Task04-HOG特征描述算子-行人检测
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-06 10:03:41" itemprop="dateCreated datePublished" datetime="2020-07-06T10:03:41+08:00">2020-07-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-07 14:06:05" itemprop="dateModified" datetime="2020-07-07T14:06:05+08:00">2020-07-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">图像处理下</span></a>
                </span>
            </span>

          
            <span id="/article/760e3967.html" class="post-meta-item leancloud_visitors" data-flag-title="Task04-HOG特征描述算子-行人检测" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/article/760e3967.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/article/760e3967.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>16k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>HOG（Histogram of Oriented Gradients）HOG特征在对象检测与模式匹配中是一种常见的特征提取技术（深度学习之前），是基于本地像素块进行特征直方图提取的一种算法，对象局部的变形与光照影响有很好的稳定性，最初是用HOG特征来来识别人像，通过HOG特征提取+SVM训练，可以得到很好的效果，OpenCV已经有相应的接口。</p>
<p>HOG特征实在2005年CVPR的会议发表，在图像手工特征提取方面具有里程碑式的意义，当时在行人检测领域获得了极大成功。</p>
<h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><h2 id="1-HOG特征描述符"><a href="#1-HOG特征描述符" class="headerlink" title="1. HOG特征描述符"></a>1. HOG特征描述符</h2><h3 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h3><p>&emsp;&emsp;局部目标的外表和形状可以被局部梯度的分布很好的描述，即使我们不知道对应的梯度和边缘的位置。(本质：梯度的统计信息，梯度主要存在于边缘edge或角落corner的地方)<!--局部目标的外表和形状可以被局部梯度或边缘方向的分布很好的描述，即使我们不知道对应的梯度和边缘的位置。(本质：梯度的统计信息，梯度主要存在于边缘edge或角落corner的地方)--></p>
<h3 id="宏观"><a href="#宏观" class="headerlink" title="宏观"></a>宏观</h3><p>&emsp;&emsp;特征描述符就是通过提取图像的有用信息，并且丢弃无关信息来简化图像的表示。</p>
<p>&emsp;&emsp;HOG特征描述符可以将3通道的彩色图像转换成一定长度的特征向量。</p>
<p>&emsp;&emsp;那么我们就需要定义什么是“有用的”，什么是“无关的”。这里的“有用”，是指对于什么目的有用，显然特征向量对于观察图像是没有用的，但是它对于像图像识别和目标检测这样的任务非常有用。当将这些特征向量输入到类似支持向量机（SVM）这样的图像分类算法中时，会得到较好的结果。</p>
<p>&emsp;&emsp;那什么样的“特征”对分类任务是有用，比如我们想检测出马路上的车道线，那么我们可以通过边缘检测来找到这些车道线，在这种情况下，边缘信息就是“有用的”，而颜色信息是无关的。</p>
<p>&emsp;&emsp;方向梯度直方图(HOG)特征描述符常和线性支持向量机(SVM)配合使用，用于训练高精度的目标分类器。</p>
<h3 id="微观（硬核）"><a href="#微观（硬核）" class="headerlink" title="微观（硬核）"></a>微观（硬核）</h3><p>在HOG特征描述符中，梯度方向的分布，也就是梯度方向的直方图被视作特征。图像的梯度(x和y导数)非常有用，因为边缘和拐角(强度突变的区域)周围的梯度幅度很大，并且边缘和拐角比平坦区域包含更多关于物体形状的信息。</p>
<p>HOG特征是一种图像局部特征，基本思路是将图像划分为很多小的连通区域，即细胞单元Cell，然后对Cell的<strong>梯度幅值和方向</strong>进行投票统计，形成基于梯度特性的直方图。把直方图在图像更大的范围内(又名区间或者Block)进行归一化。<strong>归一化的块描述符叫做HOG描述子feature descriptor。</strong>将检测窗口中的所有块的HOG描述子组合成最终的特征向量。然后使用SVM分类器进行目标和非目标的二分类（检测）。</p>
<p>HOG+SVM的工作流程如下：</p>
<p><img src="/article/760e3967/1328274-20180917143312309-1232187669.png" alt="img"></p>
<p>首先对输入的图片进行预处理，然后计算像素点的梯度特性，包括梯度幅值和梯度方向。然后投票统计形成梯度直方图，然后对blocks进行normalize，最后收集到检测窗口的HOG feature(一行多维的vector)放入SVM里进行监督学习，实现行人的检测。接下来对上述HOG的主要步骤进行学习。（车轱辘话又来了一遍┗|｀O′|┛ 嗷~~）</p>
<p><font color="red">检测窗口在整个图像的所有位置和尺度进行扫描，并对输出的金字塔进行非极大值抑制来检测目标</font>（检测窗口的大小一般为128x64）</p>
<h2 id="2-HOG特征的原理"><a href="#2-HOG特征的原理" class="headerlink" title="2. HOG特征的原理"></a>2. HOG特征的原理</h2><p>接下来让我们进入到计算图像的HOG特征描述符的具体步骤。<br>以下面这张图片为例（宽高为100x200）:</p>
<p><img src="/article/760e3967/v2-2ccc671e60031942dca8a129410a0383_720w.jpg" alt="img"></p>
<h3 id="图形预处理"><a href="#图形预处理" class="headerlink" title="图形预处理"></a>图形预处理</h3><p>预处理包括灰度化和Gamma变换。</p>
<p>灰度处理是可选操作，因为灰度图像和彩色图像都可以用于计算梯度图。对于彩色图像，先对三通道颜色值分别计算梯度，然后取梯度值最大的那个作为该像素的梯度。</p>
<p>然后进行伽马矫正，调节图像对比度，减少光照对图像的影响（包括光照不均和局部阴影），使过曝或者欠曝的图像恢复正常，更接近人眼看到的图像。更详细的内容参考<a href="https://www.cnblogs.com/qiqibaby/p/5325193.html" target="_blank" rel="noopener">图像处理之gamma矫正</a>。</p>
<p>Gamma矫正公式：$f(I) = I^{\gamma}$，其中$I$表示图像，$\gamma$表示幂指数。($\gamma$越大，图像越暗；为1时，表示没有变化。)<br>如图，当$\gamma$取不同的值时对应的输入输出曲线( $\gamma$=1时输入输出保持一致) ：<br>1） 当$\gamma$&lt;1时，输入图像的低灰度值区域动态范围变大，进而图像低灰度值区域对比度得以增强；在高灰度值区域，动态范围变小，进而图像高灰度值区域对比度得以降低。 最终，图像整体的灰度变亮。</p>
<p>2） 当$\gamma$&gt;1时，输入图像的低灰度值区域动态范围变小，进而图像低灰度值区域对比度得以降低；在高灰度值区域，动态范围变大，进而图像高灰度值区域对比度得以增强。 最终，图像整体的灰度变暗。</p>
<p><img src="/article/760e3967/image-1.jpg" alt="在这里插入图片描述"></p>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv2.imread(<span class="string">'*.png'</span>, <span class="number">0</span>)</span><br><span class="line">img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)</span><br><span class="line">img2 = np.power(img/float(np.max(img)),<span class="number">1</span>/<span class="number">2.2</span>)</span><br><span class="line">plt.imshow(img2)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>放图，左图是$\gamma=0.5$，中图是$\gamma=1$，右图是$\gamma=1.5$：</p>
<center class="half">    <img src="/article/760e3967/0_5_hog.jpg" width="200" hight="400"><img src="/article/760e3967/1_hog.jpg" width="200" hight="400"><img src="/article/760e3967/1_5_hog.jpg" width="200" hight="400"></center>

<p>作者在他的博士论文里有提到，对于涉及大量的类内颜色变化，如猫，狗和马等动物，没标准化的RGB图效果更好，而牛，羊的图做gamma颜色校正后效果更好。是否用gamma校正分情况把。(●ˇ∀ˇ●)</p>
<h3 id="计算图像梯度"><a href="#计算图像梯度" class="headerlink" title="计算图像梯度"></a>计算图像梯度</h3><p>为了得到梯度直方图，那么首先需要计算图像水平方向和垂直方向梯度。可以通过使用以下内核过滤图像实现，分别用于计算水平梯度和垂直梯度。</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
d_x = I(x+1, y) - I(x-1,y) \\
d_y = I(x, y+1) - I(x,y-1)
\end{aligned}
\end{equation}</script><p><img src="/article/760e3967/gradient-kernels.jpg" alt="Gradient Kernels"></p>
<p>一般使用特定的卷积核对图像滤波实现，可选用的卷积模板有：sobel算子、Prewitt算子、Roberts模板等等。<br> 可以使用内核大小为1的sobel算子获取相同结果，OpenCV也是如此。<br>利用sobel水平和垂直算子与输入图像卷积计算$dx$、$dy$：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
Sobel_{X} &= \begin{bmatrix}1 \\ 0 \\ -1\end{bmatrix} *
             \begin{bmatrix}1 & 2 &  1\end{bmatrix} 
           =  \begin{bmatrix}1 & 2 & 1\\
                             0 & 0 & 0\\
                             -1 & -2 & -1\end{bmatrix} \\
Sobel_{Y} &= \begin{bmatrix}1 \\ 2 \\  1\end{bmatrix} *
             \begin{bmatrix}1 & 0 & -1\end{bmatrix} 
           =  \begin{bmatrix}1 & 0 & -1\\
                             2 & 0 & -2\\
                             1 & 0 & -1\end{bmatrix} \\
\end{aligned}
\end{equation}</script><script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
d_x = f(x, y)*Sobel_x(x,y) \\
d_y = f(x, y)*Sobel_y(x,y)
\end{aligned}
\end{equation}</script><p>进一步得到图像梯度的幅值：$M(x,y) = \sqrt{d^{2}_{x}(x,y)+d^{2}_{y}(x,y)}$<br>（简化计算，幅值也可以做近似：$M(x,y) = |d_{x}(x,y)|+|d_{y}(x,y)|$）<br>图像梯度的方向：$\theta_{M} = \arctan(d_y/d_x)$</p>
<p>这里需要注意的是：梯度方向和图像边缘方向是互相正交的。</p>
<p><img src="/article/760e3967/20160511100108955" alt="在这里插入图片描述"></p>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mport cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read image</span></span><br><span class="line">img = cv2.imread(<span class="string">'*.jpg'</span>)</span><br><span class="line">img = np.float32(img) / <span class="number">255.0</span>  <span class="comment"># 归一化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算x和y方向的梯度</span></span><br><span class="line">gx = cv2.Sobel(img, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>, ksize=<span class="number">1</span>)</span><br><span class="line">gy = cv2.Sobel(img, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>, ksize=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算合梯度的幅值和方向（角度）</span></span><br><span class="line">mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>下图展示了梯度：</p>
<center class="half">    <img src="/article/760e3967/x_hog.jpg" width="150" hight="300"><img src="/article/760e3967/y_hog.jpg" width="150" hight="300"><img src="/article/760e3967/mag_hog.jpg" width="150" hight="300"><img src="/article/760e3967/angle_hog.jpg" width="150" hight="300"></center>

<p>第一个图：x-梯度的绝对值，第二个图：y梯度的绝对值 ，第三个图：梯度的幅值，第四个图：角度。<br>注意到，x-梯度在垂直线触发，y-梯度在水平线触发。梯度的幅值在有密集的剧烈改变时触发。当区域很平缓时，梯度没有明显变化。梯度图除去了很多不必要的信息（例如有颜色的背景），强调凸显线条。当你看到梯度图像，很容易想到这张图片有一个人。<br>在每个像素点，梯度有一个幅值和方向。对于有颜色的图像，计算三通道的梯度（如上图所示）。一个像素点的梯度的幅值是三通道中梯度幅值最大的值，角度也是最大梯度对应的角度。</p>
<h3 id="计算梯度直方图"><a href="#计算梯度直方图" class="headerlink" title="计算梯度直方图"></a>计算梯度直方图</h3><p>&emsp;&emsp; 此时，每一个像素点具有两个值：梯度幅值和梯度方向。<br>&emsp;&emsp; 在这一步中，图像被分成若干个8×8的Cell，如下图所示，例如我们将图像resize至64x128的大小，那么这幅图像就被划分为8x16个8x8的Cell单元，并为每个8×8的Cell计算梯度直方图。当然，Cell的划分也可以是其他值：16x16，8x16等，根据具体的场景确定。</p>
<p><img src="/article/760e3967/hog-cells.png" alt="8x8 Cells of HOG"></p>
<p>计算梯度直方图之前，先了解一下为什么要把图像分为若干个Cell?<br>这是因为如果对一整张梯度图逐像素计算，其中的有效特征是非常稀疏的，不但运算量大，而且会受到一些噪声干扰。使用特征描述符便提供了紧凑的表示。一个8x8的图像块包含8x8x3=192个像素值。一个8x8的Cell包含了8x8x2 = 128个值（每个像素包括梯度的大小和方向）。128个值将由9-bin的直方图（存储9个值的向量，想想坐标应该就明白了）。同时，计算Cell上的梯度直方图更具鲁棒性。逐像素计算梯度会产生噪音，直方图表示对噪音更不敏感。</p>
<p>&emsp;&emsp; 好，回到主题。<br>&emsp;&emsp; 在HOG中，每个8x8的Cell的梯度直方图本质是一个由9个数值组成的向量， 对应于0、20、40、60…160的梯度方向(角度)。那么原本Cell中8x8x2 = 128个值就由长度为9的向量来表示，用这种梯度直方图的表示方法，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。<br>如下图所示，左图是衣服64x128的图像，被划分为8x16个8x8的Cell；中间的图像表示一个Cell中的梯度矢量，箭头朝向代表梯度方向，箭头长度代表梯度大小。<br>右图是 8×8 的Cell中表示梯度的原始数值，注意角度的范围介于0到180度之间，而不是0到360度， 这被称为“无符号”梯度，因为两个完全相反的方向被认为是相同的。0$^\circ$和180$^\circ$是相同的。（经验表明这样处理对于行人检测效果更好。）</p>
<p><img src="/article/760e3967/20200613153022928.png" alt="在这里插入图片描述"></p>
<p>接下来，计算Cell中像素的梯度直方图，将0-180度分成9等份，称为9个bins，分别是0，20，40…160。然后对每个bin中梯度的贡献进行统计：</p>
<p><img src="/article/760e3967/hog-histogram-1.png" alt="Histogram computation in HOG"></p>
<p>&emsp;&emsp;这里采用加权投票统计，比如上面方向图中蓝圈包围的像素，角度为80度，这个像素对应的幅值为2，所以在直方图80度对应的bin加上2。红圈包围的像素，角度为10度，介于0度和20度之间，其幅值为4，那么这个梯度值就被按比例分给0度和20度对应的bin，也就是各加上2。</p>
<p><img src="/article/760e3967/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMzA1NjcxMy1mMDgzNzBkZGVmMmVhYzE1LnBuZw" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;再比如：（如上图所示）某像素的梯度幅值为13.6，方向为36，36度两侧的角度bin分别为20度和40度，那么按一定加权比例分别在20度和40度对应的bin加上梯度值，加权公式为：<br>20度对应的bin：(（40-36）/20) x13.6，<strong>分母的20表示20等份，其中4份给20度对应的bin</strong>；<br>40度对应的bin：(（36-20）/20) x13.6，<strong>分母的20表示20等份,其中16份给20度对应的bin</strong>；<br>&emsp;&emsp;还有一个细节需要注意，如果某个像素的梯度角度大于160度，也就是在160度到180度之间，那么把这个像素对应的梯度值按比例分给0度和160度对应的bin。如左下图绿色圆圈中的角度为165度，幅值为85，则按照同样的加权方式将85分别加到0度和160度对应的bin中。</p>
<p><img src="/article/760e3967/20200613160337781.png" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;对整个Cell进行投票统计，最终得到9-bin直方图：</p>
<p><img src="/article/760e3967/20200613161947892.png" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;可以看到直方图中，0度和160附近有很大的权重，说明了大多数像素的梯度向上或者向下，也就是这个Cell是个横向边缘。</p>
<h3 id="Block归一化"><a href="#Block归一化" class="headerlink" title="Block归一化"></a>Block归一化</h3><p>&emsp;&emsp;HOG特征将8×8的一个局部区域作为一个Cell，再以2×2个Cell作为一组，称为一个block，也就是说一个block表示16x16的区域。<br>&emsp;&emsp;由于每个Cell有9个值，一个block（2×2个Cell）则有36个值，HOG是通过滑动窗口的方式来得到block的，如下图所示：</p>
<p><img src="/article/760e3967/aHR0cHM6Ly9waWM0LnpoaW1nLmNvbS92Mi0yMzI0MTc3NDIwYzBhNzlkNDhkODQ0YjVlMTI0ZjFmM19iLndlYnA" alt="在这里插入图片描述"></p>
<p>为什么需要分Block呢？<br>我们已经为图像的8×8单元构造了基于梯度的直方图，但是图像的梯度对整体光照很敏感。这意味着对于特定的图像，图像的某些部分与其他部分相比会非常明亮。虽然不能从图像中完全消除，但是可以通过使用16×16个块来对梯度进行归一化来减少这种光照变化的影响。比如通过将所有像素值除以2来使图像变暗，那么梯度幅值将减小一半，因此直方图中的值也将减小一半。 </p>
<p>&emsp;&emsp;接下来对Block进行归一化。（再再再一次强调，归一化的目的是为了降低光照/迁移的影响）：<br>&emsp;&emsp;归一化的方法有很多：L1-norm、L2-norm、max/min等等，一般选择L2-norm。</p>
<script type="math/tex; mode=display">
v←\frac{v}{\sqrt{\|v\|_2^2+\xi^2}} \quad (\xi是一个很小的数，主要是为了防止分母为0)；</script><p>&emsp;&emsp;例如对于一个[128，64，32]的三维向量来说，模长是$\sqrt{128^2+64^2+32^2}=146.64$，这叫做向量的L2范数。将这个向量的每个元素除以146.64就得到了归一化向量 [0.87, 0.43, 0.22]。<br>&emsp;&emsp;现在有一个新向量，是第一个向量的2倍 [128x2, 64x2, 32x2]，也就是 <code>[256, 128, 64]</code>，我们将这个向量进行归一化，你可以看到归一化后的结果与第一个向量归一化后的结果相同。所以，对向量进行归一化可以消除整体光照的影响。<br>&emsp;&emsp;知道了如何归一化，现在来对block的梯度直方图进行归一化（注意不是Cell），一个block有4个直方图，将这4个直方图拼接成长度为36的向量，然后对这个向量进行归一化。<br>&emsp;&emsp;因为使用的是滑动窗口，滑动步长为8个像素，一个Cell大小，每滑动一次，就在这个窗口上进行归一化计算得到长度为36的向量，并重复这个过程。如上图所示。</p>
<h3 id="获得HOG描述子"><a href="#获得HOG描述子" class="headerlink" title="获得HOG描述子"></a>获得HOG描述子</h3><p>每一个16x16大小的block将会得到一个长度为36x1的特征向量，并进行归一化。 那会得到多大的特征向量呢？<br>对于上图被划分8 x16个Cell ，每个block有2x2个Cell的话，那么Cell的个数为：(8-1)x(16-1)=105。<br>每个16x16 block由36x1维向量，合并所有105个block的特征，最终得到由36 x105=3780维向量表示的特征描述符。<br>获得HOG特征向量，就可以用来可视化和分类了。对于多维的HOG特征，SVM就可以排上用场了。</p>
<p>介绍以下Dalal等人的训练方法：</p>
<ol>
<li>提取正负样本的HOG特征；</li>
<li>用正负样本训练一个初始的分类器，然后由分类器生产检测器；</li>
<li>然后用初始分类器在负样本原图上进行行人检测，检测出来的矩形区域自然都是分类错误的负样本，这就是所谓的难例(hard examples)；</li>
<li>提取难例的HOG特征并结合第一步中的特征，重新训练，生成最终的检测器 ；</li>
</ol>
<p>这种二次训练的处理过程显著提高了每个检测器的表现，一般可以使得每个窗口的误报率(FPPW False Positives Per Window)下降5%。</p>
<h3 id="使用HOG特征数据"><a href="#使用HOG特征数据" class="headerlink" title="使用HOG特征数据"></a>使用HOG特征数据</h3><p>HOG特征本身是不支持旋转不变性与多尺度检测的，但是通过构建高斯金字塔实现多尺度的开窗检测就会得到不同分辨率的多尺度检测支持，如下图所示。详细内容可参考<a href="https://www.cnblogs.com/ronny/p/3886013.html" target="_blank" rel="noopener">尺度空间理论</a></p>
<p><img src="/article/760e3967/1328274-20180924221334307-1701938273.png" alt="img"></p>
<p>OpenCV中HOG多尺度对象检测API如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">virtual void cv::HOGDescriptor::detectMultiScale(</span><br><span class="line">    InputArray  img,</span><br><span class="line">    std::vector&lt; Rect &gt; &amp;   foundLocations,</span><br><span class="line">    double  hitThreshold = <span class="number">0</span>,</span><br><span class="line">    Size    winStride = Size(),</span><br><span class="line">    Size    padding = Size(),</span><br><span class="line">    double  scale = <span class="number">1.05</span>,</span><br><span class="line">    double  finalThreshold = <span class="number">2.0</span>,</span><br><span class="line">    bool    useMeanshiftGrouping = false </span><br><span class="line">)</span><br><span class="line">Img-表示输入图像</span><br><span class="line">foundLocations-表示发现对象矩形框</span><br><span class="line">hitThreshold-表示SVM距离度量，默认<span class="number">0</span>表示，表示特征与SVM分类超平面之间</span><br><span class="line">winStride-表示窗口步长</span><br><span class="line">padding-表示填充</span><br><span class="line">scale-表示尺度空间</span><br><span class="line">finalThreshold-最终阈值，默认为<span class="number">2.0</span></span><br><span class="line">useMeanshiftGrouping-不建议使用，速度太慢拉</span><br></pre></td></tr></table></figure>
<p>在<a href="https://sulimin-nb.github.io/article/ad28cab2.html">人脸检测之Haar分类器</a>这一节我们利用haar特征和级联分类器Adaboost检测人脸时我们使用过detectMultiScale()函数，级联分类器对象尝试在输入图像的不同尺度下检测对象，该函数有一个比较重要的参数scaleFactor(一般设置为1.3)，表示一个比率：即在每层金字塔中所获得的图像与上一层图像的比率，scaleFactor越小，金字塔的层数就越多，计算就越慢，计算量也会更大，但是计算结果相对更精确。</p>
<h1 id="基于OpenCV的简单实现"><a href="#基于OpenCV的简单实现" class="headerlink" title="基于OpenCV的简单实现"></a>基于OpenCV的简单实现</h1><h2 id="行人检测"><a href="#行人检测" class="headerlink" title="行人检测"></a>行人检测</h2><p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    src = cv.imread(<span class="string">"*.jpg"</span>)</span><br><span class="line">    cv.imshow(<span class="string">"input"</span>, src)</span><br><span class="line">    </span><br><span class="line">    hog = cv.HOGDescriptor()</span><br><span class="line">    hog.setSVMDetector(cv.HOGDescriptor_getDefaultPeopleDetector())</span><br><span class="line">    <span class="comment"># Detect people in the image</span></span><br><span class="line">    (rects, weights) = hog.detectMultiScale(src,</span><br><span class="line">                                            winStride=(<span class="number">2</span>,<span class="number">4</span>),</span><br><span class="line">                                            padding=(<span class="number">8</span>, <span class="number">8</span>),</span><br><span class="line">                                            scale=<span class="number">1.2</span>,</span><br><span class="line">                                            useMeanshiftGrouping=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> (x, y, w, h) <span class="keyword">in</span> rects:</span><br><span class="line">        cv.rectangle(src, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    cv.imshow(<span class="string">"hog-detector"</span>, src)</span><br><span class="line">    cv.imwrite(<span class="string">"hog-detector.jpg"</span>,src)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line">    cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>待检测图片：</p>
<p><img src="/article/760e3967/v2-2ccc671e60031942dca8a129410a0383_720w.jpg" alt="v2-2ccc671e60031942dca8a129410a0383_720w"></p>
<p>检测图片(有点不完美，调参调不动了，先酱~)：</p>
<p><img src="/article/760e3967/hog-detector.jpg" alt="hog-detector"></p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p><strong>feature.log函数：</strong></p>
<ul>
<li><code>image</code>：可以是灰度图或者彩色图；</li>
<li><code>orientations</code>：就是把180度分成几份，也就是bin的数量；</li>
<li><code>pixels_per_Cell</code>：一个Cell里包含的像素个数；</li>
<li><code>Cells_per_block</code>：一个block包含的Cell个数；</li>
<li><code>visualize</code>：是否返回一个hog图像用于显示，下面会显示这张图；</li>
</ul>
<p>为了显示效果，把Cell的尺寸改为(16, 16)，对于每一个Cell，画出它归一化后的梯度直方图。如下图所示，我们可以很明显的看出一个人的轮廓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> feature, exposure</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">'hog.jpg'</span>)</span><br><span class="line">fd, hog_image = feature.hog(image, orientations=<span class="number">9</span>, pixels_per_Cell=(<span class="number">16</span>, <span class="number">16</span>),</span><br><span class="line">                    Cells_per_block=(<span class="number">2</span>, <span class="number">2</span>), visualize=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Rescale histogram for better display</span></span><br><span class="line">hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(<span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line">cv2.imshow(<span class="string">'img'</span>, image)</span><br><span class="line">cv2.imshow(<span class="string">'hog'</span>, hog_image_rescaled)</span><br><span class="line">hog_image_rescaled = <span class="number">255.0</span> * hog_image_rescaled</span><br><span class="line">cv2.imwrite(<span class="string">'edge_hog.jpg'</span>, hog_image_rescaled)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)==ord(<span class="string">'q'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/article/760e3967/edge_hog.jpg" alt="edge_hog"></p>
<h2 id="手动实现HOG特征"><a href="#手动实现HOG特征" class="headerlink" title="手动实现HOG特征"></a>手动实现HOG特征</h2><p>虽然opencv已经实现了HOG算法，但是手动实现的目的是为了加深我们对HOG的理解。参考了博客<a href="https://www.cnblogs.com/zyly/p/9651261.html" target="_blank" rel="noopener">基于传统图像处理的目标检测与识别</a><br>代码主要包括以下步骤：</p>
<ol>
<li>图像灰度化，归一化处理；</li>
<li>首先计算图像每一个像素点的梯度幅值和角度；</li>
<li>计算输入图像的每个Cell单元的梯度直方图(注意，我们在实现梯度直方图的时候，使用到的是双线性插值，这和上面介绍的理论略微有区别)，形成每个Cell的descriptor，比如输入图像为128×64 可以得到16×8个Cell，每个Cell由9个bin组成；</li>
<li>将2×2个Cell组成一个block，一个block内所有Cell的特征串联起来得到该block的HOG特征descriptor，并进行归一化处理，将图像内所有block的HOG特征descriptor串联起来得到该图像的HOG特征descriptor，这就是最终分类的特征向量；</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#代码来源GitHub:https://github.com/PENGZhaoqing/Hog-feature</span></span><br><span class="line"><span class="comment">#https://blog.csdn.net/ppp8300885/article/details/71078555</span></span><br><span class="line"><span class="comment">#https://www.leiphone.com/news/201708/ZKsGd2JRKr766wEd.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hog_descriptor</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    HOG描述符的实现</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, img, Cell_size=<span class="number">8</span>, bin_size=<span class="number">9</span>)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        构造函数</span></span><br><span class="line"><span class="string">            默认参数，一个block由2x2个Cell组成，步长为1个Cell大小 </span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">            img：输入图像(更准确的说是检测窗口)，这里要求为灰度图像  对于行人检测图像大小一般为128x64 即是输入图像上的一小块裁切区域</span></span><br><span class="line"><span class="string">            Cell_size：细胞单元的大小 如8，表示8x8个像素</span></span><br><span class="line"><span class="string">            bin_size：直方图的bin个数</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.img = img</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        采用Gamma校正法对输入图像进行颜色空间的标准化（归一化），目的是调节图像的对比度，降低图像局部</span></span><br><span class="line"><span class="string">        的阴影和光照变化所造成的影响，同时可以抑制噪音。采用的gamma值为0.5。 f(I)=I^γ</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.img = np.sqrt(img*<span class="number">1.0</span> / float(np.max(img)))</span><br><span class="line">        self.img = self.img * <span class="number">255</span></span><br><span class="line">        <span class="comment">#print('img',self.img.dtype)   #float64</span></span><br><span class="line">        <span class="comment">#参数初始化</span></span><br><span class="line">        self.Cell_size = Cell_size</span><br><span class="line">        self.bin_size = bin_size</span><br><span class="line">        self.angle_unit = <span class="number">180</span> / self.bin_size  <span class="comment">#这里采用180°</span></span><br><span class="line">        <span class="keyword">assert</span> type(self.bin_size) == int, <span class="string">"bin_size should be integer,"</span></span><br><span class="line">        <span class="keyword">assert</span> type(self.Cell_size) == int, <span class="string">"Cell_size should be integer,"</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">180</span> % self.bin_size == <span class="number">0</span>, <span class="string">"bin_size should be divisible by 180"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        计算图像的HOG描述符，以及HOG-image特征图</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        height, width = self.img.shape</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        1、计算图像每一个像素点的梯度幅值和角度</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        gradient_magnitude, gradient_angle = self.global_gradient()</span><br><span class="line">        gradient_magnitude = abs(gradient_magnitude)</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        2、计算输入图像的每个Cell单元的梯度直方图，形成每个Cell的descriptor 比如输入图像为128x64 可以得到16x8个Cell，每个Cell由9个bin组成</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        Cell_gradient_vector = np.zeros((int(height / self.Cell_size), int(width / self.Cell_size), self.bin_size))</span><br><span class="line">        <span class="comment">#遍历每一行、每一列</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(Cell_gradient_vector.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(Cell_gradient_vector.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="comment">#计算第[i][j]个Cell的特征向量</span></span><br><span class="line">                Cell_magnitude = gradient_magnitude[i * self.Cell_size:(i + <span class="number">1</span>) * self.Cell_size,</span><br><span class="line">                                 j * self.Cell_size:(j + <span class="number">1</span>) * self.Cell_size]</span><br><span class="line">                Cell_angle = gradient_angle[i * self.Cell_size:(i + <span class="number">1</span>) * self.Cell_size,</span><br><span class="line">                             j * self.Cell_size:(j + <span class="number">1</span>) * self.Cell_size]</span><br><span class="line">                Cell_gradient_vector[i][j] = self.Cell_gradient(Cell_magnitude, Cell_angle)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#将得到的每个Cell的梯度方向直方图绘出，得到特征图</span></span><br><span class="line">        hog_image = self.render_gradient(np.zeros([height, width]), Cell_gradient_vector)</span><br><span class="line">        </span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        3、将2x2个Cell组成一个block，一个block内所有Cell的特征串联起来得到该block的HOG特征descriptor</span></span><br><span class="line"><span class="string">           将图像image内所有block的HOG特征descriptor串联起来得到该image（检测目标）的HOG特征descriptor，</span></span><br><span class="line"><span class="string">           这就是最终分类的特征向量</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        hog_vector = []</span><br><span class="line">        <span class="comment">#默认步长为一个Cell大小，一个block由2x2个Cell组成，遍历每一个block</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(Cell_gradient_vector.shape[<span class="number">0</span>] - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(Cell_gradient_vector.shape[<span class="number">1</span>] - <span class="number">1</span>):</span><br><span class="line">                <span class="comment">#提取第[i][j]个block的特征向量</span></span><br><span class="line">                block_vector = []</span><br><span class="line">                block_vector.extend(Cell_gradient_vector[i][j])</span><br><span class="line">                block_vector.extend(Cell_gradient_vector[i][j + <span class="number">1</span>])</span><br><span class="line">                block_vector.extend(Cell_gradient_vector[i + <span class="number">1</span>][j])</span><br><span class="line">                block_vector.extend(Cell_gradient_vector[i + <span class="number">1</span>][j + <span class="number">1</span>])</span><br><span class="line">                <span class="string">'''块内归一化梯度直方图，去除光照、阴影等变化，增加鲁棒性'''</span></span><br><span class="line">                <span class="comment">#计算l2范数</span></span><br><span class="line">                mag = <span class="keyword">lambda</span> vector: math.sqrt(sum(i ** <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> vector))   </span><br><span class="line">                magnitude = mag(block_vector) + <span class="number">1e-5</span></span><br><span class="line">                <span class="comment">#归一化</span></span><br><span class="line">                <span class="keyword">if</span> magnitude != <span class="number">0</span>:</span><br><span class="line">                    normalize = <span class="keyword">lambda</span> block_vector, magnitude: [element / magnitude <span class="keyword">for</span> element <span class="keyword">in</span> block_vector]</span><br><span class="line">                    block_vector = normalize(block_vector, magnitude)</span><br><span class="line">                hog_vector.append(block_vector)           </span><br><span class="line">        <span class="keyword">return</span> np.asarray(hog_vector), hog_image</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">global_gradient</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        分别计算图像沿x轴和y轴的梯度</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, <span class="number">1</span>, <span class="number">0</span>, ksize=<span class="number">5</span>)</span><br><span class="line">        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, <span class="number">0</span>, <span class="number">1</span>, ksize=<span class="number">5</span>)</span><br><span class="line">        <span class="comment">#计算梯度幅值 这个计算的是0.5*gradient_values_x + 0.5*gradient_values_y</span></span><br><span class="line">        <span class="comment">#gradient_magnitude = cv2.addWeighted(gradient_values_x, 0.5, gradient_values_y, 0.5, 0)</span></span><br><span class="line">        <span class="comment">#计算梯度方向</span></span><br><span class="line">        <span class="comment">#gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=True)</span></span><br><span class="line">        gradient_magnitude, gradient_angle = cv2.cartToPolar(gradient_values_x,gradient_values_y,angleInDegrees=<span class="literal">True</span>)        </span><br><span class="line">        <span class="comment">#角度大于180°的，减去180度</span></span><br><span class="line">        gradient_angle[gradient_angle&gt;<span class="number">180.0</span>] -= <span class="number">180</span> </span><br><span class="line">        <span class="comment">#print('gradient',gradient_magnitude.shape,gradient_angle.shape,np.min(gradient_angle),np.max(gradient_angle))</span></span><br><span class="line">        <span class="keyword">return</span> gradient_magnitude, gradient_angle</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Cell_gradient</span><span class="params">(self, Cell_magnitude, Cell_angle)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        为每个细胞单元构建梯度方向直方图</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">            Cell_magnitude：Cell中每个像素点的梯度幅值</span></span><br><span class="line"><span class="string">            Cell_angle：Cell中每个像素点的梯度方向</span></span><br><span class="line"><span class="string">        return：</span></span><br><span class="line"><span class="string">            返回该Cell对应的梯度直方图，长度为bin_size</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        orientation_centers = [<span class="number">0</span>] * self.bin_size</span><br><span class="line">        <span class="comment">#遍历Cell中的每一个像素点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(Cell_magnitude.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(Cell_magnitude.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="comment">#梯度幅值</span></span><br><span class="line">                gradient_strength = Cell_magnitude[i][j]</span><br><span class="line">                <span class="comment">#梯度方向</span></span><br><span class="line">                gradient_angle = Cell_angle[i][j]</span><br><span class="line">                <span class="comment">#双线性插值</span></span><br><span class="line">                min_angle, max_angle, weight = self.get_closest_bins(gradient_angle)</span><br><span class="line">                orientation_centers[min_angle] += (gradient_strength * (<span class="number">1</span> - weight))</span><br><span class="line">                orientation_centers[max_angle] += (gradient_strength *weight)</span><br><span class="line">        <span class="keyword">return</span> orientation_centers</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_closest_bins</span><span class="params">(self, gradient_angle)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        计算梯度方向gradient_angle位于哪一个bin中，这里采用的计算方式为双线性插值</span></span><br><span class="line"><span class="string">        具体参考：https://www.leiphone.com/news/201708/ZKsGd2JRKr766wEd.html</span></span><br><span class="line"><span class="string">        例如：当我们把180°划分为9个bin的时候，分别对应对应0,20,40,...160这些角度。</span></span><br><span class="line"><span class="string">              角度是10，副值是4，因为角度10介于0-20度的中间(正好一半)，所以把幅值</span></span><br><span class="line"><span class="string">              一分为二地放到0和20两个bin里面去。</span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">            gradient_angle:角度</span></span><br><span class="line"><span class="string">        return：</span></span><br><span class="line"><span class="string">            start,end,weight：起始bin索引，终止bin的索引，end索引对应bin所占权重</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        idx = int(gradient_angle / self.angle_unit)</span><br><span class="line">        mod = gradient_angle % self.angle_unit</span><br><span class="line">        <span class="keyword">return</span> idx % self.bin_size, (idx + <span class="number">1</span>) % self.bin_size, mod / self.angle_unit</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">render_gradient</span><span class="params">(self, image, Cell_gradient)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        将得到的每个Cell的梯度方向直方图绘出，得到特征图</span></span><br><span class="line"><span class="string">        args：</span></span><br><span class="line"><span class="string">            image：画布,和输入图像一样大 [h,w]</span></span><br><span class="line"><span class="string">            Cell_gradient：输入图像的每个Cell单元的梯度直方图,形状为[h/Cell_size,w/Cell_size,bin_size]</span></span><br><span class="line"><span class="string">        return：</span></span><br><span class="line"><span class="string">            image：特征图</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        Cell_width = self.Cell_size / <span class="number">2</span></span><br><span class="line">        max_mag = np.array(Cell_gradient).max()</span><br><span class="line">        <span class="comment">#遍历每一个Cell</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(Cell_gradient.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> range(Cell_gradient.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="comment">#获取第[i][j]个Cell的梯度直方图</span></span><br><span class="line">                Cell_grad = Cell_gradient[x][y]</span><br><span class="line">                <span class="comment">#归一化</span></span><br><span class="line">                Cell_grad /= max_mag</span><br><span class="line">                angle = <span class="number">0</span></span><br><span class="line">                angle_gap = self.angle_unit</span><br><span class="line">                <span class="comment">#遍历每一个bin区间</span></span><br><span class="line">                <span class="keyword">for</span> magnitude <span class="keyword">in</span> Cell_grad:</span><br><span class="line">                    <span class="comment">#转换为弧度</span></span><br><span class="line">                    angle_radian = math.radians(angle)</span><br><span class="line">                    <span class="comment">#计算起始坐标和终点坐标，长度为幅值(归一化),幅值越大、绘制的线条越长、越亮</span></span><br><span class="line">                    x1 = int(x * self.Cell_size + Cell_width + magnitude * Cell_width * math.cos(angle_radian))</span><br><span class="line">                    y1 = int(y * self.Cell_size + Cell_width + magnitude * Cell_width * math.sin(angle_radian))</span><br><span class="line">                    x2 = int(x * self.Cell_size + Cell_width - magnitude * Cell_width * math.cos(angle_radian))</span><br><span class="line">                    y2 = int(y * self.Cell_size + Cell_width - magnitude * Cell_width * math.sin(angle_radian))</span><br><span class="line">                    cv2.line(image, (y1, x1), (y2, x2), int(<span class="number">255</span> * math.sqrt(magnitude)))</span><br><span class="line">                    angle += angle_gap</span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#加载图像</span></span><br><span class="line">    img = cv2.imread(<span class="string">'./image/person.jpg'</span>)        </span><br><span class="line">    width = <span class="number">64</span></span><br><span class="line">    height = <span class="number">128</span></span><br><span class="line">    img_copy = img[<span class="number">320</span>:<span class="number">320</span>+height,<span class="number">570</span>:<span class="number">570</span>+width][:,:,::<span class="number">-1</span>]    </span><br><span class="line">    gray_copy = cv2.cvtColor(img_copy,cv2.COLOR_BGR2GRAY)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#显示原图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">6.4</span>,<span class="number">2.0</span>*<span class="number">3.2</span>))</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    plt.imshow(img_copy)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#HOG特征提取</span></span><br><span class="line">    hog = Hog_descriptor(gray_copy, Cell_size=<span class="number">8</span>, bin_size=<span class="number">9</span>)    </span><br><span class="line">    hog_vector, hog_image = hog.extract()</span><br><span class="line">    print(<span class="string">'hog_vector'</span>,hog_vector.shape)</span><br><span class="line">    print(<span class="string">'hog_image'</span>,hog_image.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#绘制特征图</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    plt.imshow(hog_image, cmap=plt.cm.gray)    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>HOG算法具有以下优点：                            </p>
<ul>
<li>核心思想是所检测的局部物体外形能够被梯度或边缘方向的分布所描述，HOG能较好地捕捉局部形状信息，对几何和光学变化都有很好的不变性；             </li>
<li>HOG是在密集采样的图像块中求取的，在计算得到的HOG特征向量中隐含了该块与检测窗口之间的空间位置关系。                           </li>
</ul>
<p>HOG算法具有以下缺点：                 </p>
<ul>
<li>特征描述子获取过程复杂，维数较高，导致实时性差；                </li>
<li>很难处理遮挡问题，人体姿势动作幅度过大或物体方向改变也不易检测（这个问题后来在<a href="http://blog.csdn.net/masibuaa/article/details/17924671" target="_blank" rel="noopener">DPM</a>中采用可变形部件模型的方法得到了改善）；                  </li>
<li>跟SIFT相比，HOG没有选取主方向，也没有旋转梯度方向直方图，因而本身不具有旋转不变性（较大的方向变化），其旋转不变性是通过采用不同旋转方向的训练样本来实现的；</li>
<li>跟SIFT相比，HOG本身不具有尺度不变性，其尺度不变性是通过缩放检测窗口图像的大小来实现的；</li>
<li>此外，由于梯度的性质，HOG对噪点相当敏感，在实际应用中，在block和Cell划分之后，对于得到各个区域，有时候还会做一次高斯平滑去除噪点。               </li>
</ul>
<p><em>Q : How do you eat an elephant ?</em><br><em>A : One bite at a time!</em></p>
<p>参考链接：</p>
<p><a href="https://www.learnopencv.com/histogram-of-oriented-gradients/" target="_blank" rel="noopener">Histogram of Oriented Gradients(强烈推荐)</a><br><a href="https://cloud.tencent.com/developer/article/1419615" target="_blank" rel="noopener">HOG特征详解与行人检测</a><br><a href="https://www.cnblogs.com/zyly/p/9651261.html" target="_blank" rel="noopener">基于传统图像处理的目标检测与识别(很全面)</a><br><a href="https://zhuanlan.zhihu.com/p/85829145" target="_blank" rel="noopener">一文讲解方向梯度直方图HOG</a></p>

    </div>

    
    
    
	
    
      <div>
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      </div>
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag"><i class="fa fa-tag"></i> 图像处理</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/article/553b1469.html" rel="prev" title="leetcode50">
      <i class="fa fa-chevron-left"></i> leetcode50
    </a></div>
      <div class="post-nav-item">
    <a href="/article/69d6fed9.html" rel="next" title="leetcode78">
      leetcode78 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#算法实现"><span class="nav-text">算法实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-HOG特征描述符"><span class="nav-text">1. HOG特征描述符</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主要思想"><span class="nav-text">主要思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#宏观"><span class="nav-text">宏观</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#微观（硬核）"><span class="nav-text">微观（硬核）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-HOG特征的原理"><span class="nav-text">2. HOG特征的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#图形预处理"><span class="nav-text">图形预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算图像梯度"><span class="nav-text">计算图像梯度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算梯度直方图"><span class="nav-text">计算梯度直方图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Block归一化"><span class="nav-text">Block归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获得HOG描述子"><span class="nav-text">获得HOG描述子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用HOG特征数据"><span class="nav-text">使用HOG特征数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基于OpenCV的简单实现"><span class="nav-text">基于OpenCV的简单实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#行人检测"><span class="nav-text">行人检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可视化"><span class="nav-text">可视化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#手动实现HOG特征"><span class="nav-text">手动实现HOG特征</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="sulimin"
      src="/images/su1.JPG">
  <p class="site-author-name" itemprop="name">sulimin</p>
  <div class="site-description" itemprop="description">向前向前向前ε=( o｀ω′)ノ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/sulimin-nb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;sulimin-nb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:15210376096@163.com" title="E-Mail → mailto:15210376096@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sulimin</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">站点共71k字</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">阅读需1:04</span>
</div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'gIlJLkkEOolcxea5daBOIYB5-gzGzoHsz',
      appKey     : 'Xwqmsb7cDIWaQB2GG2fCnSHf',
      placeholder: "ヾﾉ≧∀≦)o 来呀！吐槽一番吧！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });

  }, window.Valine);
});
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":1},"log":false});</script></body>
</html>
<script type="text/javascript" src="/js/love-click.js"></script>